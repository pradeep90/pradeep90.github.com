<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel="icon" type="image/png" href="./images/favicon-32x32.png" sizes="32x32" />
	<link rel="icon" type="image/png" href="./images/favicon-16x16.png" sizes="16x16" />
        <title>Holding your Own Joystick - SPK's Rationality Essays</title>
        <link rel="stylesheet" type="text/css" href="./css/default.css" />
        <link rel="stylesheet" type="text/css" href="./css/highlight.css" />

	<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script> -->
	<!-- <script type="text/javascript" src="/js/header-links.js"></script> -->
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

	<link href="atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed" />

	<!-- Google Analytics stuff -->
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-51321929-1', 'pradeep90.github.io');
	  ga('send', 'pageview');

	</script>

	<script type="text/javascript" src="https://fast.fonts.net/jsapi/f7f47a40-b25b-44ee-9f9c-cfdfc8bb2741.js"></script>
    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="./">SPK's Rationality Essays</a>
            </div>
            <div id="navigation">
                <a href="./">Home</a>
                <a href="./notes.html">Notes</a>
                <!-- <a href="/about.html">About</a> -->
                <a href="./archive.html">Archive</a>
		<a href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed">RSS</a>
            </div>
        </div>

        <div id="content">
          <h1 id="post-title">Holding your Own Joystick</h1>

            <!-- <center><img src="https://fbcdn-sphotos-d-a.akamaihd.net/hphotos-ak-prn1/t31.0-8/p600x600/10257116_10202295769100492_2438594605053717342_o.jpg" height="400" width="300" class="sujeet-pic" alt="Sujeet pic" /></center> -->

<h1 id="getting-your-own-joystick">Getting your Own Joystick</h1>
<p>We saw in <a href="./what-creates-meaning.md">What makes us say our Life has Meaning?</a> that what makes people have clear decisions, and, in that sense, makes them feel like their life has “meaning”, is that they have many constraints. This implies that lack of constraints leads to you having less clear decisions. If you don’t have money enough to eat out, your path is clear - eat at home; if you have lots of money to go out, you don’t quite know where to eat - you have dozens of restaurants to choose from.</p>
<p>What’s funny about this state of relative independence, of having fewer constraints than usual on your life, of having enough money and other resources to choose from a variety of options, is that you are in charge of your happiness.</p>
<p>You’re like some robot that was being controlled by humans using a joystick, walking around, picking things up from one spot and putting them down in another spot, making beep-boop-beep sounds. All of a sudden, by some strange combination of circumstances, the robot’s joystick drops into its own hands. It’s now standing there, blinking at the joystick. What the hell is it “supposed” to do?</p>
<h1 id="usually-in-the-hands-of-others">Usually in the Hands of Others</h1>
<p>First, note that the joystick doesn’t solely determine the robot’s future. The environment matters. If the robot crashes into a wall or if a boulder falls on it, it will get mangled up.</p>
<p>So, given the environment, what “should” the robot do? “Should” here doesn’t refer to anything. What <em>will</em> the robot do? (Sit around and write essays on “meaning”, apparently, at least in the case of one robot.)</p>
<p>Human joysticks are usually controlled by others. If you are poor and have to work a soul-crushing job, or if you don’t have any friends or lovers, or if you can’t get any tasty food, then you will suffer proportionately. On the flip side, even though you’re stuck at a job, maybe you happen to get praise; even though you’re stuck with roommates you didn’t pick, maybe they are nice to you when it’s their birthday; even though you were forced to eat at the cheapest restaurant near you, maybe it turns out to have tasty food. But, either way, you don’t have much choice in the matter. You would have done the same things regardless of how they turned out.</p>
<p>When you get money, when you have options in friends and lovers, when you have options in food (and of course other important things in life), it is as if, for a time, you hold your own joystick. Yes, the environment still matters - you could get hit by a car tomorrow - but at least you can choose some parts of your life. What you choose to do with your time, who you choose to hang out with, what you choose to eat - all of these will affect your present and future experiences.</p>
<h1 id="no-test-drives">No Test Drives</h1>
<p>The cruel part of the above thought experiment is that the robot holding its own joystick doesn’t get any test drives, no practice sessions, nothing. If we stipulate that its battery will last seventy hours, then that is all the time it has. It can spend a few hours understanding how the joystick works and then spend the rest of the hours using the joystick to do what it “wants”, whatever that means, or it can skip the experimentation and start right away, pressing buttons and hoping things work out. Oh, and any press of the buttons could destroy the robot - it doesn’t know.</p>
<p>The robot, which may already be thirty-two hours old, may take another ten hours to understand what to do, and, at the end of the ten hours, find out that it’s too late, that what it wants to do needed to have started ten hours earlier. Robot life is not fair.</p>
<h1 id="how-to-reward-yourself">How to Reward Yourself?</h1>
<p>The robot can surround itself with things it “likes” or things it “dislikes”. Earlier, it didn’t have a choice. Its surroundings were what they were; it had no say in the matter. Now, all of a sudden, it has a say.</p>
<p>Why not spend all its resources on getting joy after joy? It likes fixing and improving its robot parts; it likes playing with certain other robots, especially inserting its plugs into their sockets; it likes watching robot movies. Why not just do these things over and over till its (non-rechargeable) battery runs out?</p>
<p>Whose permission does it need? What is it waiting for before it uses up these joys? After all, it doesn’t get any “points” for dying with the most joys unused.</p>
<p>But other robots will give it weird looks. “Why are you giving up on life?”, it fears they will ask. After all, most of the other robots seem to be done other things.</p>
<p>Why not achieve some great robotic achievement? Isn’t that the “purpose” of robotic life? You have one non-rechargeable battery, and this is what you waste it on? Plugs in sockets, robot movies, and part-fixing? Is that the sum of your robot life, my young robot? Why not do something great, like Paul Grahbot or Eliezer Yudbotsky or Bill Botes? What would other bots say if they saw that you were doing nothing special with your bot-life?</p>
<p>When it speaks to other bots, they talk about how they’re growing in their bot-careers and how they’re doing much better than it and getting praise that it is not. That makes it worry about how it’s not doing any of those things. “Why not just stop hanging out with such bots?” But isn’t that running away from your bot-problems? Isn’t that “bot-cowardly”?</p>
<h1 id="permission">Permission</h1>
<p>Maybe it should just stop thinking so much about the “purpose” of its bot-life and just hunker down and do what everyone else is doing. After all, who is this humble bot to come up with a novel solution to a problem faced by literally billions of bots through bot-history? Where does it get off on thinking it might try something different?</p>
<p>But those other bots had constraints it didn’t. For the first time in history, perhaps (or not; who cares?), it lacks constraints that had bound other bots. Should it just ignore those facts and just go about business as usual?</p>
<p>WHOSE PERMISSION DOES IT NEED?!!</p>
<p>Whose permission would be good enough for it to take off? Whose blessings would make it set off on its path without any misgivings?</p>
<p>Others may have a lot more bot-wealth, a lot more bot-experience, and maybe even a lot more bot-joy (even though it doubts it). But only this bot is responsible for the seventy hours or so of battery-life that it calls its own. The buck stops here. This is its <strong>only</strong> battery-life. If, at the end of its battery-life, it looks back and regrets everything, it cannot blame or punish the other bots. It would have had <strong>one</strong> battery-life and it would have wasted it.</p>
<p>Since it can’t hold other bots responsible in case they wasted its life, why is it waiting for their permission? Those other bots have little incentive to get their advice right. They don’t get paid more if their advice “works”, whatever that means, and they don’t get fined if their advice hurts. Actually, that’s not strictly true. The bot’s family-bots and friend-bots will lose its friendship if they give it bad advice. But, still, the only one who pays the ultimate price - its one and only non-rechargeable battery-life - is the bot itself. So, it “should” be the one to decide how it spends that battery-life.</p>
<h1 id="you-have-to-make-a-move">You Have to Make a Move</h1>
<p>“It looks like your bot-actions are decided mainly by the people you hang out with. So, why not hang out only with bots that match your ‘goals’?”, suggested the friend-bot.</p>
<p>“But isn’t that running away? Forget about being ‘cowardly’. What if I’m wrong?”</p>
<p>Looks like that is the main reason why the bot is hesitating to do its own thing. What if it is wrong? It is playing blackjack with its own battery-life. It could lose the only battery-life it has. And it <strong>has</strong> to play. It can’t get out of the casino.</p>
<p>Aha. That was what the bot was missing. It was thinking day and night about the “best” way to stake its battery-life, and was failing to come up with any actions it wouldn’t regret. But it forgot the biggest constraint of them all - you <strong>have</strong> to play!</p>
<p>Whatever it does is a move. Taking the time to write essays about the “best” way to play - that’s a move; it uses up non-zero amounts of battery-life. Watching bot-YouTube all day - that’s a move. Destroying its battery in despair - even that’s a move. You cannot escape the game.</p>
<p>This means that a great strategy it discovers at the ripe old age of forty hours, when its robot joints are creaky and it can’t move as swiftly as it used to when it was a strapping twenty-hour old, may be worth less than a mediocre strategy it discovers right now at thirty-two hours of age, simply because it has more time to execute the strategy.</p>
<p>So, its aim is not to find the best strategy of all time. Its aim is to find the best strategy for its particular constraints at this particular time - it has a certain amount of resources, a certain amount of knowledge about the world, and a very particular set of skills. And it needs to do this <strong>fast</strong>.</p>
<h1 id="hesitating-to-make-an-irreversible-change">Hesitating to make an Irreversible Change</h1>
<p>The bot now knows that time is running out and it has to make a move. It also knows that the way to change its own behavior is by changing its immediate environment. It knows that it won’t feel as bad anymore if it stays away from bots that brag about salaries or about “great bot-startup achievements” or about “great bot-romances”.</p>
<p>But that seems like a terrible “risk”. What if it’s wrong? It’s like taking the left freeway at a freeway intersection (or something). There may be no turning back. By the time you turn around and get back to your old spot, your battery may run out. There is no turning back of bot-time.</p>
<p>This is perhaps the highest-stake gamble of all time! You are staking your only life. What if you get it “wrong”?</p>
<p>Ah. “Wrong” is not observable in advance. You can’t tell, today, what is a “wrong” move. It is something you can only find out in the future, after you’ve seen the consequence of that move. Even in cases where someone else knows how a move will turn out, the bot cannot search through all known bot-knowledge to find it in time. Remember, everything is a move; even searching takes up precious battery-time.</p>
<p>Still, an irreversible change (and all changes are irreversible, since you cannot turn back time) seems “risky”. On what authority is the bot making such a monumental change? How dare it make a decision about the rest of its forty-odd hours of battery-life?</p>
<blockquote>
<p>I went to the woods because I wished to live deliberately, to front only the essential facts of life, and see if I could not learn what it had to teach, and not, when I came to die, discover that I had not lived.</p>
<p>– <a href="https://genius.com/8223724">Henry David Bot-Thoreau</a></p>
</blockquote>
<p>What if the bot could isolate himself from conversations with bots who talked about other kinds of goals? “Should” it do so?</p>
<p>The bot is not making a move either way. So, it knows the causes of its worries - conversations with other bots. The only thing left to do is stop those conversations. What are the causes of that? What would be sufficient to make it move? What has made it take irreversible decisions in the past?</p>
<h1 id="opportunity-cost-external-achievements">Opportunity Cost: External Achievements</h1>
<p>What if the bot could have achieved “great things” if it had stuck to the conventional path?</p>
<p>Alright. Let’s break down those “great things”. It’s not magic. It’s not something never done by any bot in the history of bot-kind. What are the dimensions along which you can do “great things”? What is the upper bound on the opportunity cost?</p>
<p>The bot could get billions (or maybe millions) of bot-dollars by working on stuff. The bot could have years of happy moments with friends and lovers (actually, the bot could have more of these on its proposed path). The bot could learn lots of new skills and reach new heights of skill. The bot could discover new hypotheses about various systems.</p>
<p>None of these sound particularly tempting to the bot. You are, it reasons, rich to the extent you can afford your goals. And it has pretty cheap tastes, so it doesn’t need a lot of money.</p>
<p>But it is worried it might miss out on some “magic” that might result from these things, some ineffable feeling you experience when working as hard as you can on something and “growing stronger”, some changes in attitude and thinking that come from facing down challenges. Maybe a life with those “magical” strengths is more fun than a life without. What if these things make you a “better” bot than you would be otherwise?</p>
<h1 id="opportunity-cost-internal-growth">Opportunity Cost: Internal “Growth”</h1>
<p>Alright, so the bot has shifted the goalpost from external achievements, which the bot admits are nice but inessential, to internal achievements. Let’s break those down too.</p>
<p>The bot knows of bots who have attained “great things” in the external world - billionaire startup founders, social butterflies, “influencers”, and artists. Does it also know of bots who have achieved “great things” in the internal world?</p>
<p>Who are these bots it is trying to emulate? Or is it going after something hitherto unseen?</p>
<p>If you had lots of money, maybe you could start a business (in what? Or does that not matter?) and have lots of fun that way? Maybe that tickles a different part of the bot’s circuitry than fun had through other means.</p>
<p>After tackling a lot of challenges, the bot may not fear any future challenges. That may allow it to achieve greater and greater things. But that’s again an external achievement, paying out eventually in millions or billions of bot-dollars, and the bot has already said it doesn’t find that too exciting.</p>
<p>Maybe you’ll get lots of praise and respect everywhere you go. That’s not something the bot can manufacture on its own. Maybe that makes it worth it? Instead of looking at the cause (lots of praise and respect), look at the putative effect (happiness or pride). Are the bots who have got a lot of praise and respect living very happily? The bot hasn’t seen that to be true.</p>
<p>The bot may think that bots who achieve “great things” have more “meaning”, something unlike happiness, something unobservable, something that it fears it will miss out on. For one, maybe working as hard as you can gets you into a “flow state”. But the bot could get that in other ways too, such as bot video games. Why does that feeling have to be tied to its career?</p>
<p>What about “meaning”? What if bots who work hard all day long for years on end have more “meaning”?</p>
<p>Break it down. How much “meaning” do these bots have? How do they spend their time? For how many hours do they feel this “meaning” every day? If we postulate that any time spent on video or news apps is a waste, then bots waste hours every day.</p>
<p>If the bot knows what feelings it is after, it can find more efficient ways of getting those same feelings.</p>
<h1 id="running-away-from-reality">Running Away from Reality?</h1>
<p>If the bot removes people who have undesired ambitions from its environment, isn’t it running away from reality? Isn’t it good to accept all possible feedback at all times? After all, if the bot were “really good”, it would be able to handle feedback from anyone.</p>
<blockquote>
<p>How much does it matter what message a city sends? Empirically, the answer seems to be: a lot. You might think that if you had enough strength of mind to do great things, you’d be able to transcend your environment. Where you live should make at most a couple percent difference. But if you look at the historical evidence, it seems to matter more than that. Most people who did great things were clumped together in a few places where that sort of thing was done at the time.</p>
<p>You can see how powerful cities are from something I wrote about earlier: the case of the Milanese Leonardo. Practically every fifteenth century Italian painter you’ve heard of was from Florence, even though Milan was just as big. People in Florence weren’t genetically different, so you have to assume there was someone born in Milan with as much natural ability as Leonardo. What happened to him?</p>
<p>If even someone with the same natural ability as Leonardo couldn’t beat the force of environment, do you suppose you can?</p>
<p>I don’t. I’m fairly stubborn, but I wouldn’t try to fight this force. I’d rather use it. So I’ve thought a lot about where to live.</p>
<p>– Paul Graham, <a href="http://www.paulgraham.com/cities.html">Cities and Ambition</a></p>
</blockquote>
<p>A bot can’t be good at everything. It has to choose. But if it hangs out with people, it can’t help but feel bad if they do better than it at something. So, the more varied the people it hangs out with, the more it will find something it is not good at, and the worse it will feel. Better to filter who you hang out with.</p>

<div class="info">Created: March  3, 2023</div>
<div class="info">Last modified: March  3, 2023</div>
<div class="info">Status: in-progress</div>
<div class="info"><b>Tags</b>: joystick</div>

<br />
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'spkrationalitytrainingground'; // required: replace example with your forum shortname
    var disqus_identifier = '/holding-your-own-joystick.html';
    var disqus_title = 'Holding your Own Joystick';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
	var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<script type="text/javascript" src="https://fast.fonts.net/jsapi/f7f47a40-b25b-44ee-9f9c-cfdfc8bb2741.js"></script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
