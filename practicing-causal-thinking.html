<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel="icon" type="image/png" href="./images/favicon-32x32.png" sizes="32x32" />
	<link rel="icon" type="image/png" href="./images/favicon-16x16.png" sizes="16x16" />
        <title>Practicing Causal Thinking - SPK's Rationality Essays</title>
        <link rel="stylesheet" type="text/css" href="./css/default.css" />
        <link rel="stylesheet" type="text/css" href="./css/highlight.css" />

	<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script> -->
	<!-- <script type="text/javascript" src="/js/header-links.js"></script> -->
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

	<link href="atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed" />

	<!-- Google Analytics stuff -->
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-51321929-1', 'pradeep90.github.io');
	  ga('send', 'pageview');

	</script>

    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="./">Rationality Essays</a>
            </div>
            <div id="navigation">
                <a href="./">Home</a>
                <a href="./notes.html">Notes</a>
                <!-- <a href="/about.html">About</a> -->
                <a href="./archive.html">Archive</a>
		<a href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed">RSS</a>
            </div>
        </div>

        <div id="content">
          <h1 id="post-title">Practicing Causal Thinking</h1>

            <!-- <center><img src="https://fbcdn-sphotos-d-a.akamaihd.net/hphotos-ak-prn1/t31.0-8/p600x600/10257116_10202295769100492_2438594605053717342_o.jpg" height="400" width="300" class="sujeet-pic" alt="Sujeet pic" /></center> -->

<h1 id="aim-algorithm-and-skill">Aim: Algorithm and Skill</h1>
<p>I want to start with very crude version 1 of a causal thinking algorithm and then iterate on it till it’s really good. Simultaneously, I want to burn the steps of the algorithm into my mind as skills via deliberate practice.</p>
<h1 id="bare-minimum-of-the-scientific-method">Bare Minimum of the Scientific Method</h1>
<p>What is the minimum you need to solve problems?</p>
<p>You need to be able to translate the real-world situations into good variables (for some definition of “good”). Then, you need to work with the (hopefully empirical) data expressed using those variables (viz. correlations and interventions) and come up with a correct causal model and make the necessary inferences. Then, you need to translate that back to the real world. Of course, you need to be thinking in terms of decisions and value of information the whole time.</p>
<p>What are the problems to which I can apply this algorithm? What problems can it solve? What can’t it solve yet? Why not?</p>
<p>For example, boundary violations cause resentment in you, and boundary conformance causes calmness and lack of worry. So, if you see worry, you should be able to infer that you’ve broken a boundary somewhere.</p>
<p>So, for each problem, recall or obtain the causal models that pertain to it (like the theory of boundaries for the problem above, cognitive psychology for memory, or exemplars for when you’re stuck on a problem) and then use them to make the right inferences. Also, identify the decision you’re trying to make (how to spend the next one hour, how to remember this idea more often, or which example to think about in order to progress on this problem).</p>
<h1 id="going-beyond-the-minimum">Going Beyond the Minimum</h1>
<p>You need to memorize the object-level inferences of the causal model so that you can deploy them at speed. Seeing resentment should instantly flag a boundary violation.</p>
<h1 id="chunk-it-up">Chunk It Up</h1>
<p>Identify <em>when</em> you will need each of the skills below and train yourself on that particular cue. For example, whenever you ask what caused an event, you need to look at the most local causes. However, that is precisely where I forget to use it. I remember that locality of causality is great whenever I talk about causality in the abstract, but fail to apply it when I need it most. So, train yourself to remember locality of causality whenever you want to discover the causes, especially when you’re reading something. In other words, store the skill routine on the cue of the decision it helps you make.</p>
<h1 id="key-skills">Key Skills</h1>
<p>Meta: Specify the cue situation and the response, i.e., the “where” and the “what”.</p>
<p>Think only in terms of causal models. And decisions. And value of information. And exemplars. And cues.</p>
<p>Taboo - explain ideas in terms of canonical primitives like probability theory, decision theory, economics, etc. Like boundaries in terms of property rights.</p>
<p>Empiricism - focus on the empirical evidence.</p>
<p>Ask for differing predictions between alternative hypotheses.</p>
<p>Start from the evidence list. Don’t pull hypotheses out of thin air.</p>
<p>PB, of course.</p>
<p>Resentment -&gt; boundary violation. Ask: whose property is it?</p>
<p>Cue-oriented thinking: For every situation, ask what cues do I perceive here? What should I actually perceive? What are my possible actions? What is my best action? Example: If you feel stressed by an uncomfortable situation the next day and feel out of control, it’s because you haven’t stored the correct response on particular cue of “stress and feeling of control”. Similarly if you feel put down by an acquaintance - you haven’t stored the best way of handling that situation.</p>
<h1 id="satisfying-work">Satisfying Work</h1>
<p>Aim: No unemployment, just like there’s no unemployment in the world of Warcraft. Always have some satisfying work to do. You shouldn’t have to guess about what to do or make some complex decisions. Just reach into the bag, pick up a task, and do it! Always have some next actions you can execute.</p>
<p>Come up with three exemplars for every concept or category you hold. Like for the concept of treason, the category of the best songs by your favourite musician, or the concept of an all-out war. I suppose it would help to know the other useful categories in that space (like ho-hum songs by your favourite musician). This should help you figure out discriminating features.</p>
<p>Measurement: #exemplars used today (+1) - your mind is starving for exemplars, remember.</p>
<p>Make a list of tests where you know you will fail. (Like the unit tests that are red. Red, green, refactor.) Knowing what you don’t know - for which decisions will you make poor choices, etc.</p>
<p>Make a list of decisions you might make in the future. You want valuable information <em>about</em> these decisions. example: how to exercise, how long to sleep, what business to start, what research to do, what books to read (?), etc.</p>
<h1 id="practice-notes">Practice notes</h1>
<p>Practice a LOT (2500 times, not 25 times).</p>
<h1 id="simple-test">Simple Test</h1>
<p>Use only causal models when learning or solving problems. Do <em>not</em> use the alternative ways of thinking: intuition (“it was the butler!”), vague black-box hypotheses (examples?), or correlations (“obesity is associated with a risk of heart disease”).</p>
<p>So, notice when you <em>don’t</em> think causally, and then think causally instead.</p>
<p>This is when you’re solving problems. When learning, make sure you try to extract a causal model from the textbook or journal paper or whatever resource you’re studying. If you don’t have a causal model at the end, you haven’t really learned anything. (Or you could learn exemplars, which are crucial too. They help you get the variables that make up your model.)</p>
<h1 id="chunks">Chunks</h1>
<p>Operationalize: Get variables from the resources. For example, in the SSC post on Toxoplasma, he’s talking about signalling and controversies and popularity and usefulness.</p>
<p>Extract: Get the causal model involving those variables. How does Scott connect usefulness, controversy, and popularity?</p>
<p>Learn: Get the evidence and formulate alternative hypotheses (causal models). Perhaps popularity is caused by other stuff.</p>
<p>Differing prediction: Look at the differing predictions between the models. Check some controversial messages that <em>didn’t</em> go viral.</p>
<p>Test: Look at the variable that differs. Virality above.</p>
<p>Anticipation-constraints: What else could be a direct cause? What else can cause virality?</p>
<h1 id="make-reusable-causal-models">Make Reusable Causal Models</h1>
<p>One problem with my causality practice so far: I’ve been analyzing the causal links in PG essays and Seligman chapters, but I haven’t set them up to be used elsewhere. They have literally no VoI. If I want to know something about “what to do before a startup”, I’ll read PG’s essay once again instead of referring to my causal model. In other words, my causal model isn’t reusable (or even usable).</p>
<p>Write them in a format where you can use them elsewhere. Store them in your memory on appropriate cues. Collect them in a place where you will come back. Otherwise, they have no value. Seligman’s chapter about panic attacks is pretty much useless to me. So, I didn’t bother trying to make my notes reusable.</p>
<p>In short, it was all use-and-throw work so far. Time to make something more lasting. For example, my notes on Seligman’s chapters or all my PG work so far or even Willpower, which is one of the most personally useful pieces of information I have. I didn’t <em>do</em> anything with those notes. If you want to practice learning, then actually do what you will actually do when you’re learning. Use your notes. For example, make causal models out of Eliezer’s sequences, PG’s essays, the Willpower book, Gamification, Boundaries, etc. Show that they have VoI. Design them so that you can actually use them in your life.</p>
<p>Perhaps I should write an essay on them. Remember, I’m going to have to release them sometime, in some format. What format is better than an essay?</p>
<h1 id="decision-oriented-thinking-tell-me-what-to-do">Decision-Oriented Thinking: Tell Me What To Do</h1>
<p>Organize your causal models (essays, notes, thoughts) by decisions. What is the upshot? What should I do in situation X?</p>
<p>This might be best served by modelling those variables involved in your decisions. For example, if you want to know whether to be mean or not as a startup founder, then find out what being mean causes.</p>
<h1 id="release-the-scientific-method">Release the scientific method</h1>
<p>Show how you can solve one simple problem from start to end (for <em>a</em> given decision). For example, should I do cardio for 20 minutes everyday or 40 minutes everyday? What is the tradeoff? Should I force myself to eat fewer calories? Should I try to work (and think and practice) for 8 hours everyday or just 5 or even less? Should I buy a new set of calipers? Should I focus on causal thinking or memory? Should I try to take on one big project (like photography or maybe something else) or do lots of smaller things like PG essays and textbooks?</p>
<p>Note: As predicted by my good friend Mr. Exemplar, I get a flood of ideas once I decide to focus on a clear, concrete example (“one decision like cardio for 20 minutes vs 40”) instead of the vague “decisions”.</p>
<h1 id="practical-problems">Practical Problems</h1>
<p>One skill in solving problems using causal thinking is backward inference. For example, the general wisdom is that if you have to read a book twice, you didn’t do a good job the first time around. They say reading a book well causes you to understand it so well that you won’t have any questions left needing an answer.</p>
<p>You should be able to do this everywhere. Like, feeling resentful towards someone is evidence that you have let them violate your boundaries. Another example: if you’re stuck on a problem, you must not have any exemplars in your mind to trigger on (or you must not be paying attention to the right cues).</p>
<p>I suspect that backward inference is harder than forward inference. The question “what will happen if your boundaries are violated?” is easy to answer - you will feel resentful towards the violator. But what if you’re feeling resentful right now? It feels hard to go back to the cause.</p>
<p>Further, I suspect that this is because, in our mind, we encode causal models in the forward direction, but fail to do so in the backward direction. “Boundary violation” causes “resentment” is straightforward - it’s what you do when you study the area. But to go from “resentment” to “boundary violation” takes some doing. You have to encode it explicitly.</p>
<p>So, for every variable, you must know its direct causes. Maybe that’s too general. Maybe you should know what happens for every possible outcome of that variable - if you’re feeling relaxed and in control, you must not have any boundary violations; if you’re feeling resentful, you must have boundary violations.</p>
<h1 id="general-thoughts">General Thoughts</h1>
<p>One way even a randomized controlled trial can go wrong: side causes. If you manipulate A and look at B, you may deduce that A is a causal ancestor of B. However, you can’t say that whenever A is set to a value, B will always change the way it did. It could have another direct cause apart from A. I’m not a medical guy, but maybe doing an RCT on patients who are <em>old</em> may not allow you to infer the correct behaviour for the same intervention on patients who are <em>young</em> - their age could be a significant factor. (I don’t know of a short name for this concept. Note that this isn’t anything wrong with the RCT itself, it’s our unjustified inferences.)</p>
<p>Another example: you do an A/B test on your clothing website where, during the same time of the day, people are randomly either shown a t-shirt in blue or a t-shirt in red, and you measure how many of them bought it. If the red shirt sold more than the blue one, you can’t infer that red shirts will always sell more, even though you did a randomized controlled trial. That’s because there could be other factors - like it was Valentine’s Day and so people bought red more. In a couple of months, it might be the cricket World Cup and people in India would want to support their team in blue and so would buy the blue t-shirt over the red one. Or it could be that the customers you got on the day of the experiment weren’t like your usual customers, and your usual customers like blue more.</p>
<h1 id="abstract-based-on-decisions">Abstract based on decisions?</h1>
<p>Is it that the details of one decision are conditionally independent of the details of other decisions given the decision choice?</p>
<p>You could treat each decision as an autonomous mechanism and refer to it whenever you want to make that particular decision.</p>
<p>Queries are hidden decision requests. When you ask about the stats on dog bites, what you really want to know is whether to go out for a walk near that park where dogs keep barking at you. For example, in a journal paper on cognitive psychology experiment, you could refer to some other psychology results. However, instead of depending on the causal model they present, you could just ask directly for the decision you care about.</p>
<p>In short, I imagine this like building a function by composing other functions. You want to recommend a choice for a decision. You then use recommendations for other decisions to make your recommendation, just like calling other functions within your function.</p>
<p>The key point is that you treat each decision as a single independent source, like a programming service. You don’t care how it makes its recommendation. You just call it, and it gives you the answer.</p>
<hr />
<p>Let’s drill down to the math. If you knew just the possible choices, and your probability estimate and value of each outcome, then you could make the right choice without knowing anything else.</p>
<p>And, no, you can’t just provide the probability estimates and ask somebody else to fill in the value preferences later. The value equations fundamentally define the value of information. It’s why you don’t represent your laptop at the level of atoms - it’s not worth it.</p>
<p>So, if you’re a general who want to transport hundreds of thousands of soldiers from one end of a country to another, you need to specify your risk tolerance. If you cannot risk a train breakdown or a long delay, then you would probably instruct your delegates to not strain the system too much - maybe allow time for the engines to cool down or whatever, don’t pack too many soldiers in, and so on. However, if you’re ok with a few breakdowns but need soldiers immediately, then you can order them to take liberties with the system and maximize the number of soldiers per train. (I was watching a World War I documentary this week)</p>
<p>Therefore, <code>decision :: values of outcomes, probability estimates -&gt; choice</code></p>
<p>What is my decision here? I want to build simple, independent mechanisms that will do one task well and that I can use in several places. So, my question is: what should those mechanisms look like?</p>
<p>Initially, I thought that each mechanism should be a causal model. Get some evidence for some variables and use it to build a causal model of those variables. However, this doesn’t scale because of the risk-tolerance factor above. Sometimes, you need a very precise answer and other times you can get away with sloppiness.</p>
<p>So, you can’t go with a one-size-fits-all causal model. You need something more. You need a causal model that can account for different value functions.</p>
<p>In essence, you will ask this black box about a decision with different value functions and it will spit out the correct recommendation. How would you design such a black box? Well, it depends on the range of value functions you expect to encounter. If you get asked “which house do I buy” by a guy with a $100k budget and a guy with a $20 million dollar budget, you will need widely different causal models. In the first case, you can get by with simple variables like size, condition, proximity to railway station or bus stand, etc. Whether the house is in a “beautiful locality” or not will not matter much to the first buyer - he won’t be willing to pay extra for it. For the latter, however, things like the class of the locality, the famous people living nearby, the quality of private schools, etc. all enter the picture.</p>
<p>I suspect you need a whole lot more valuable information in the latter situation. Rather, in the first case, you needed only a little more information before further information was too costly to be worth it. In the second case, because you were dealing with such a large sum and different choices gave vastly different values (just one loud, tacky neighbour would ruin even a classy mansion), you could gather a lot of information before it became too costly to go forward.</p>
<p>So, there’s the cost of gathering information. If your decision suddenly matters a lot more to you - if different choices lead to different values - then you need to actually pay to go and get more information (maybe by spending time researching on the web or meeting people or running experiments).</p>
<p>But if you’ve already gathered the information, you can store it and just use it the next time somebody asks you the same question (what programmers call “memoization”). So, we can do that for the most frequently asked questions.</p>
<p>So, there’s the decision, with its different choices, and the expected value of different levels of information - perfect or partial information. (I’m not fully clear about this.)</p>
<p>Later, every time you need to know about this decision, you consult only this black box, with the required inputs. This part of your life is handled, once and for all.</p>
<p>Of course, when you get new information, you need to update the black box. Or maybe you just look at the value of information calculation inside it and see if getting new information has become cheap enough that it’s worth it now.</p>
<h1 id="tests">Tests</h1>
<p>Why not test your ideas about decision-oriented thinking, causality, categories, and information theory by writing a basic AI? If you believe that causality and decision-oriented thinking are the <em>optimal</em> ways of solving problems, then show it. Work your way up simple AI problems and solve them optimally (maximizing the entropy of the message at each stage and so on).</p>
<h1 id="weekly-report---march-14---20-2016">Weekly Report - March 14 - 20, 2016</h1>
<p>Didn’t use the #reaches counter at all, so my growth rate for this week is zero. I wrote a thousand words on abstracting ideas with decisions as the interface. Didn’t do much practice for the rest of the week.</p>
<p>Total hours of practice: <strong>21</strong> hours in 7 days.</p>
<h2 id="ideas-generated-this-week">Ideas generated this week</h2>
<p>Don’t talk about valuable information without the decisions you care about;</p>
<p>Why we go into (particular) fantasies - because each medium make the other aspects of life seem boring and ridiculous. editing = remove all the boring bits. Monopoly vs competitive market meme-makers (cult vs ads).</p>
<p>When summarizing, make an initial one just to force you to release.</p>
<p>Summarized the Talent Code chapters on deliberate practice: sweet spot = important cues where your answer is not strong or not correct; so, practice <em>only</em> with desirable difficulties; unique predictions of myelin theory - the more you fire, the better you get, the older you are, the harder it is, and breaks diminish your skill.</p>
<p>Chunk = hierarchy of linked memories that you’re able to abstract or decompose or both. Holy Shit Effect = being able to abstract a “complex” situation and respond with a “complex”, coordinated solution. How situation-response might work - abstract situation, trigger on the high-level cue, decompose the high-level memory into actions, and check using feedback.</p>
<p>Nature vs nurture: we think “genetic component” in variations means that there’s no point in doing anything. No. If you practice or have better nutrition or whatever, you <em>will</em> get better absolute results.</p>
<p>Modularity of your chunks means you can adapt to situations and fix errors. How to get modular chunks? Build alternative chunks for each variable by slowing it down and strengthen the cue for “alternatives”.</p>
<p>How to guarantee you’ll only think about X? Make that the <em>only</em> cue you see. Your thoughts are caused by internal and external cues; so, to control you memeplex, control the external cues that reach you. Make the important cues (like empiricism, causality, etc.) be the only ones that enter your mind. Similarly, if you want to think an important thought right now, then remove crap cues right now and leave just the one right cue. Internet bombards you with attractive cues, btw, thus making you think thoughts you don’t really want (reddit, Youtube, etc.).</p>
<p>Your cue-response is not “good enough” -&gt; change your model vs not. (Suresh Raina not needing to improve his technique in the IPL, Kohli changing his stance after the England series) All you use in your model is valuable information. So only seek valuable areas where you can fail. Also, I think we build models by ignoring variables that are conditionally independent of the expected value given the other variables.</p>
<h1 id="weekly-plan---march-20-2016">Weekly Plan - March 20, 2016</h1>
<p>Read for an hour each day. This week: summarize the rest of Talent Code; summarize the apprentice section of Mastery; summarize the practice instructions in Talent is Overrated.</p>
<p>Have fun for around three hours each day.</p>
<p>Take one hour everyday to run drills and create new ones based on old important ideas.</p>
<p>Write an AAR in the evening.</p>
<p>Practice domain-independent causal decision-oriented thinking for five hours everyday. Three hours of intense practice and two hours of light work.</p>
<p>The question now remains: which cues and which responses should I practice?</p>
<p>Remember, I don’t want to answer that question now for all eternity. I just want to know what to practice this week. So, here’s a list: for now, just summarize the books you read.</p>
<p>As for work, gather three exemplars each for important concepts. Also, collect important cues and skill responses for next week (like for empiricism and taboo).</p>
<h1 id="weekly-report---march-21---27-2016">Weekly Report - March 21 - 27, 2016</h1>
<p>Total hours of practice: <strong>30</strong> hours in 7 days.</p>
<p>What I did most of the days: I spent a good first session in the afternoon summarizing and coming up with ideas. Then, the evening was a complete waste - I don’t think I’ve ever worked between 5pm and 10pm this week, due to binge eating, video-watching, and random surfing. I spent hours overnight thinking peacefully about important ideas. I had <em>zero</em> distractions then, and I couldn’t bring myself to turn on the laptop or watch videos (I’d feel guilty about doing that). However, I don’t want to ruin my body by working such late hours. I want to switch to a daytime schedule.</p>
<h2 id="ideas">Ideas</h2>
<p>Refine categories when the same action doesn’t work well for all its memories. Refine actions when you can do better for a whole category.</p>
<p>Why is there a space-time tradeoff for algorithms? Because we need a certain amount of information from the algorithm (it roughly picks out one function a -&gt; b out of all possible functions from a to b). You can get information by retrieving information from memory at some memory cost or you can retrieve information from the processor at some time cost. So, memory usage and processor time are negatively correlated even in the best case.</p>
<p>Taboo “skill”. Talk only of cues and responses. Talk about the limited cue-response chunks people have based on their limited experience - like Dhoni with technique or Raina with short balls.</p>
<p>Do I need to be worried about not knowing how to make progress in deliberate practice (the way I was earlier)? No. Why? Because “get chunks and practice them” -&gt; satisfying work.</p>
<p>Deliberate practice: You need to build the correct associations at every level of abstraction, not just at top-level cues (“spin -&gt; sweep”). How high performers remember more (chained chunks vs scattered details), perceive more (discriminating cues), and know more (thanks to valuable information from the past).</p>
<p>“I keep forgetting about important ideas”. No. You keep forgetting them on specific situation cues. example: everyday -&gt; 10k by 30; but I forget.</p>
<p>“Put a boundary around something” = decide minimum and maximum resources to be invested. Not doing enough is also a boundary violation (not calling a friend, etc.).</p>
<p>Corollary of boundaries: Say “yes” to what needs to be done, even if you don’t feel like doing it or feel vulnerability. Example: go exercise everyday, write essays everyday - no matter what.</p>
<p>Brene says this is what takes courage - to do things anyway even if they make you feel vulnerable.</p>
<p>Why we fail to benefit from great techniques? We fail to bind abstract cues and responses to concrete details - we don’t trigger the abstract idea (resentment) on concrete cues (feeling like shit), and we don’t decompose the high-level response into concrete actions (do “deliberate practice”).</p>
<p>Trouble? Identify the exact concrete cues on which you failed to retrieve the right memory. Example: “others are all spending their time productively” should trigger the cue “shame”.</p>
<p>To make new inferences you haven’t explicitly stored, you need to think with concrete exemplars so that you can abstract on their rich details. Example: did the falling tree make a sound? Exemplars are not optional. You cannot abstract or decompose without them. “punch” -&gt; “concussion”, but what exactly will happen? Will he be able to state the current year?</p>
<p>How to make your beliefs falsifiable? Get exemplars to help you abstract the concept on concrete cues. You should be able to tell whether reality is one way or another, never undecided.</p>
<p>akrasia = no link between abstract concepts and concrete reality. Situation cues don’t trigger the right concepts (like breathe deeply when facing a temptation) and concepts don’t trigger the right actions.</p>
<p>Key question: Is it a problem of uncertainty or memory? if the former, I have to get information; if the latter, I have to practice. Don’t try to fix a practice issue with more information. Example: boundaries, worthiness, personal finance, etc. You know what to do, now burn it in.</p>
<p>Notice when you’re not working at peak cognitive capacity and raise the challenge level. Add unnecessary obstacles that make you work on weak cues - speed, techniques you don’t use (causal model, locality of causality, decision-oriented thinking), etc.</p>
<p>Why is a painting or program never done? Because the valuable information worth getting depends on the cost of information and thus the amount of time or money you’re willing to invest.</p>
<p>Why didn’t I aspire to godhood earlier? Because I got valuable information (80/20 Principle, Mysterious Answers to Mysterious Questions, taboo) and <em>still</em> didn’t get value. Now I know the limiting reagent - practice. So shoot for Super Saiyan!</p>
<p>Paradox of choice: Why not maximize? Because the expected value of perfect information isn’t worth the opportunity cost. The best t-shirt in the shop isn’t worth a whole lot more than the one in your hand.</p>
<p>Skill: Where to spend your time in the moment? On choices that are worth the opportunity cost, mostly high-level choices like cover drive vs late cut. Remember, you don’t want to make the best low level choice, you want to make the best <em>sequence</em> of choices.</p>
<p>Chunk discovery is separate from practice. The uncertainty-reduction all happens in chunk discovery aka causal modelling. “Practice” is simply about burning in the chunks we’ve already discovered. A computer doesn’t need to “practice”, but we do.</p>
<p><strong>Warning</strong>: You CANNOT talk about a “model” without the decisions it informs. Else, you’d be working at the level of atoms. So, “how to fix a complex-looking problem?” Well, what are your choices?</p>
<p>How to remove mystery? Explain the concept in terms of cues and actions you <em>fully understand</em>. Mystery or confusion = you’re unable to make the right choice when faced with the decision situation. example: magic pouch - how to use it without words, how to make it bigger; intelligence - how to impart it to a computer.</p>
<p>What is an explanation (for humans)? Be able to <em>recognize</em> the high-level decision you face and <em>respond</em> with your best high-level choice. That’s all. If you can make the best choices for all the situations you face, you no longer have a mystery around them.</p>
<p>Category theory: type-chasing is how you recognize decisions and come up with your responses. You abstract your concrete problem statement into types (monoid) and then use your internal hoogle to find or design some functions that might do the trick (<code>&lt;&gt;</code>).</p>
<h1 id="weekly-plan---march-28---april-03-2016">Weekly Plan - March 28 - April 03, 2016</h1>
<p>Talk in terms of the decisions you need to make on certain cues.</p>
<p>Remove the distractions. Meaning what? Dinner only before 7:30pm. Work from 7:30pm to 10:30pm. Turn off the internet when working.</p>
<p>Make a budget for each day. How many hours remain? What do you plan to do during those hours?</p>
<p>Read a book for an hour each day. Use books as entertainment instead of videos or blog posts.</p>
<p>Summarize for half the time of the day. Make sure to include locality of causality and decision-oriented thinking in your model.</p>
<p>Review and add flashcards for an hour.</p>
<p>For half an hour everyday, design your practice - get chunks. On what cues do you assign the concept deep work? What does it really entail? Collect other skill chunks, like thinking of alternative hypotheses, differing predictions, etc. Look at mental model of concepts and your reference card for ideas on what to practice.</p>
<p>Satisfying work: Gather three exemplars each for important concepts (like differing predictions, categories, deliberate practice). Also, collect important cues and skill responses for next week (like for empiricism and taboo).</p>
<p>Write an AAR at the end of the day.</p>
<h2 id="questions-i-want-to-answer">Questions I want to answer</h2>
<p>Given your abstract cue and abstract response framework, how do we judge whether some information is valuable or not? (Look at how you refine categories and actions)</p>
<p>What is the only type of information that makes us change our model? How do rewards strengthen associations? (Look at The Power of Habit).</p>
<p>Update on your new-found understanding of decision-oriented thinking. How does this affect your earlier division of thinking into learning, research, and problem-solving? Do they make sense now? Chart at least one 5-year path to causal thinking mastery.</p>
<h1 id="next-week">Next Week</h1>
<p>Write essays for an hour each day.</p>
<p>Read and summarize some of The Sequences.</p>
<p>Add some more gamification. Also, look at your mental model of concepts and your reference card for more ideas for improvement.</p>
<p>I need to make a budget for each day - assign property rights to my goals. Otherwise, it’s hard to make decisions.</p>
<p>Have time for making drills out of important journal ideas.</p>
<p>Compile a list of tests (in ascending order of difficulty) - all the situations for which you don’t yet have a satisfactory response.</p>
<h1 id="weekly-report-guidelines">Weekly Report Guidelines</h1>
<p>Compile it from your daily AARs.</p>
<p>Look at your org agenda.</p>
<h1 id="weekly-plan-guidelines">Weekly Plan Guidelines</h1>
<p>Have satisfying work everyday too. Like accumulating exemplars or releasing projects a little just to keep them going (like meditation or starting from a list of evidence or booking predictions on PB).</p>
<p>Specify your daily boundaries. For example, you won’t let your meals exceed 30 minutes. Or, you will definitely book at least one prediction on PB.</p>

<div class="info">Created: February 15, 2016</div>
<div class="info">Last modified: March 29, 2016</div>
<div class="info">Status: in-progress</div>
<div class="info"><b>Tags</b>: causality</div>

<br />
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'spkrationalitytrainingground'; // required: replace example with your forum shortname
    var disqus_identifier = '/practicing-causal-thinking.html';
    var disqus_title = 'Practicing Causal Thinking';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
	var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
