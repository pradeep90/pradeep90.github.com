<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel="icon" type="image/png" href="./images/favicon-32x32.png" sizes="32x32" />
	<link rel="icon" type="image/png" href="./images/favicon-16x16.png" sizes="16x16" />
        <title>Practicing Causal Thinking - SPK's Rationality Essays</title>
        <link rel="stylesheet" type="text/css" href="./css/default.css" />
        <link rel="stylesheet" type="text/css" href="./css/highlight.css" />

	<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script> -->
	<!-- <script type="text/javascript" src="/js/header-links.js"></script> -->
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

	<link href="atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed" />

	<!-- Google Analytics stuff -->
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-51321929-1', 'pradeep90.github.io');
	  ga('send', 'pageview');

	</script>

    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="./">Rationality Essays</a>
            </div>
            <div id="navigation">
                <a href="./">Home</a>
                <a href="./notes.html">Notes</a>
                <!-- <a href="/about.html">About</a> -->
                <a href="./archive.html">Archive</a>
		<a href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed">RSS</a>
            </div>
        </div>

        <div id="content">
          <h1 id="post-title">Practicing Causal Thinking</h1>

            <!-- <center><img src="https://fbcdn-sphotos-d-a.akamaihd.net/hphotos-ak-prn1/t31.0-8/p600x600/10257116_10202295769100492_2438594605053717342_o.jpg" height="400" width="300" class="sujeet-pic" alt="Sujeet pic" /></center> -->

<h1 id="aim-algorithm-and-skill">Aim: Algorithm and Skill</h1>
<p>I want to start with very crude version 1 of a causal thinking algorithm and then iterate on it till it’s really good. Simultaneously, I want to burn the steps of the algorithm into my mind as skills via deliberate practice.</p>
<h1 id="bare-minimum-of-the-scientific-method">Bare Minimum of the Scientific Method</h1>
<p>What is the minimum you need to solve problems?</p>
<p>You need to be able to translate the real-world situations into good variables (for some definition of “good”). Then, you need to work with the (hopefully empirical) data expressed using those variables (viz. correlations and interventions) and come up with a correct causal model and make the necessary inferences. Then, you need to translate that back to the real world. Of course, you need to be thinking in terms of decisions and value of information the whole time.</p>
<p>What are the problems to which I can apply this algorithm? What problems can it solve? What can’t it solve yet? Why not?</p>
<p>For example, boundary violations cause resentment in you, and boundary conformance causes calmness and lack of worry. So, if you see worry, you should be able to infer that you’ve broken a boundary somewhere.</p>
<p>So, for each problem, recall or obtain the causal models that pertain to it (like the theory of boundaries for the problem above, cognitive psychology for memory, or exemplars for when you’re stuck on a problem) and then use them to make the right inferences. Also, identify the decision you’re trying to make (how to spend the next one hour, how to remember this idea more often, or which example to think about in order to progress on this problem).</p>
<h1 id="going-beyond-the-minimum">Going Beyond the Minimum</h1>
<p>You need to memorize the object-level inferences of the causal model so that you can deploy them at speed. Seeing resentment should instantly flag a boundary violation.</p>
<h1 id="chunk-it-up">Chunk It Up</h1>
<p>Identify <em>when</em> you will need each of the skills below and train yourself on that particular cue. For example, whenever you ask what caused an event, you need to look at the most local causes. However, that is precisely where I forget to use it. I remember that locality of causality is great whenever I talk about causality in the abstract, but fail to apply it when I need it most. So, train yourself to remember locality of causality whenever you want to discover the causes, especially when you’re reading something. In other words, store the skill routine on the cue of the decision it helps you make.</p>
<h1 id="key-skills">Key Skills</h1>
<p>Meta: Specify the cue situation and the response, i.e., the “where” and the “what”.</p>
<p>Think only in terms of causal models. And decisions. And value of information. And exemplars. And cues.</p>
<p>Taboo - explain ideas in terms of canonical primitives like probability theory, decision theory, economics, etc. Like boundaries in terms of property rights.</p>
<p>Empiricism - focus on the empirical evidence.</p>
<p>Ask for differing predictions between alternative hypotheses.</p>
<p>Start from the evidence list. Don’t pull hypotheses out of thin air.</p>
<p>PB, of course.</p>
<p>Resentment -&gt; boundary violation. Ask: whose property is it?</p>
<h1 id="satisfying-work">Satisfying Work</h1>
<p>Aim: No unemployment, just like there’s no unemployment in the world of Warcraft. Always have some satisfying work to do. You shouldn’t have to guess about what to do or make some complex decisions. Just reach into the bag, pick up a task, and do it! Always have some next actions you can execute.</p>
<p>Come up with three exemplars for every concept or category you hold. Like for the concept of treason, the category of the best songs by your favourite musician, or the concept of an all-out war. I suppose it would help to know the other useful categories in that space (like ho-hum songs by your favourite musician). This should help you figure out discriminating features.</p>
<p>Measurement: #exemplars used today (+1) - your mind is starving for exemplars, remember.</p>
<p>Make a list of tests where you know you will fail. (Like the unit tests that are red. Red, green, refactor.) Knowing what you don’t know - for which decisions will you make poor choices, etc.</p>
<p>Make a list of decisions you might make in the future. You want valuable information <em>about</em> these decisions. example: how to exercise, how long to sleep, what business to start, what research to do, what books to read (?), etc.</p>
<h1 id="practice-notes">Practice notes</h1>
<p>Practice a LOT (2500 times, not 25 times).</p>
<h1 id="simple-test">Simple Test</h1>
<p>Use only causal models when learning or solving problems. Do <em>not</em> use the alternative ways of thinking: intuition (“it was the butler!”), vague black-box hypotheses (examples?), or correlations (“obesity is associated with a risk of heart disease”).</p>
<p>So, notice when you <em>don’t</em> think causally, and then think causally instead.</p>
<p>This is when you’re solving problems. When learning, make sure you try to extract a causal model from the textbook or journal paper or whatever resource you’re studying. If you don’t have a causal model at the end, you haven’t really learned anything. (Or you could learn exemplars, which are crucial too. They help you get the variables that make up your model.)</p>
<h1 id="chunks">Chunks</h1>
<p>Operationalize: Get variables from the resources. For example, in the SSC post on Toxoplasma, he’s talking about signalling and controversies and popularity and usefulness.</p>
<p>Extract: Get the causal model involving those variables. How does Scott connect usefulness, controversy, and popularity?</p>
<p>Learn: Get the evidence and formulate alternative hypotheses (causal models). Perhaps popularity is caused by other stuff.</p>
<p>Differing prediction: Look at the differing predictions between the models. Check some controversial messages that <em>didn’t</em> go viral.</p>
<p>Test: Look at the variable that differs. Virality above.</p>
<p>Anticipation-constraints: What else could be a direct cause? What else can cause virality?</p>
<h1 id="make-reusable-causal-models">Make Reusable Causal Models</h1>
<p>One problem with my causality practice so far: I’ve been analyzing the causal links in PG essays and Seligman chapters, but I haven’t set them up to be used elsewhere. They have literally no VoI. If I want to know something about “what to do before a startup”, I’ll read PG’s essay once again instead of referring to my causal model. In other words, my causal model isn’t reusable (or even usable).</p>
<p>Write them in a format where you can use them elsewhere. Store them in your memory on appropriate cues. Collect them in a place where you will come back. Otherwise, they have no value. Seligman’s chapter about panic attacks is pretty much useless to me. So, I didn’t bother trying to make my notes reusable.</p>
<p>In short, it was all use-and-throw work so far. Time to make something more lasting. For example, my notes on Seligman’s chapters or all my PG work so far or even Willpower, which is one of the most personally useful pieces of information I have. I didn’t <em>do</em> anything with those notes. If you want to practice learning, then actually do what you will actually do when you’re learning. Use your notes. For example, make causal models out of Eliezer’s sequences, PG’s essays, the Willpower book, Gamification, Boundaries, etc. Show that they have VoI. Design them so that you can actually use them in your life.</p>
<p>Perhaps I should write an essay on them. Remember, I’m going to have to release them sometime, in some format. What format is better than an essay?</p>
<h1 id="decision-oriented-thinking-tell-me-what-to-do">Decision-Oriented Thinking: Tell Me What To Do</h1>
<p>Organize your causal models (essays, notes, thoughts) by decisions. What is the upshot? What should I do in situation X?</p>
<p>This might be best served by modelling those variables involved in your decisions. For example, if you want to know whether to be mean or not as a startup founder, then find out what being mean causes.</p>
<h1 id="release-the-scientific-method">Release the scientific method</h1>
<p>Show how you can solve one simple problem from start to end (for <em>a</em> given decision). For example, should I do cardio for 20 minutes everyday or 40 minutes everyday? What is the tradeoff? Should I force myself to eat fewer calories? Should I try to work (and think and practice) for 8 hours everyday or just 5 or even less? Should I buy a new set of calipers? Should I focus on causal thinking or memory? Should I try to take on one big project (like photography or maybe something else) or do lots of smaller things like PG essays and textbooks?</p>
<p>Note: As predicted by my good friend Mr. Exemplar, I get a flood of ideas once I decide to focus on a clear, concrete example (“one decision like cardio for 20 minutes vs 40”) instead of the vague “decisions”.</p>
<h1 id="practical-problems">Practical Problems</h1>
<p>One skill in solving problems using causal thinking is backward inference. For example, the general wisdom is that if you have to read a book twice, you didn’t do a good job the first time around. They say reading a book well causes you to understand it so well that you won’t have any questions left needing an answer.</p>
<p>You should be able to do this everywhere. Like, feeling resentful towards someone is evidence that you have let them violate your boundaries. Another example: if you’re stuck on a problem, you must not have any exemplars in your mind to trigger on (or you must not be paying attention to the right cues).</p>
<p>I suspect that backward inference is harder than forward inference. The question “what will happen if your boundaries are violated?” is easy to answer - you will feel resentful towards the violator. But what if you’re feeling resentful right now? It feels hard to go back to the cause.</p>
<p>Further, I suspect that this is because, in our mind, we encode causal models in the forward direction, but fail to do so in the backward direction. “Boundary violation” causes “resentment” is straightforward - it’s what you do when you study the area. But to go from “resentment” to “boundary violation” takes some doing. You have to encode it explicitly.</p>
<p>So, for every variable, you must know its direct causes. Maybe that’s too general. Maybe you should know what happens for every possible outcome of that variable - if you’re feeling relaxed and in control, you must not have any boundary violations; if you’re feeling resentful, you must have boundary violations.</p>
<h1 id="general-thoughts">General Thoughts</h1>
<p>One way even a randomized controlled trial can go wrong: side causes. If you manipulate A and look at B, you may deduce that A is a causal ancestor of B. However, you can’t say that whenever A is set to a value, B will always change the way it did. It could have another direct cause apart from A. I’m not a medical guy, but maybe doing an RCT on patients who are <em>old</em> may not allow you to infer the correct behaviour for the same intervention on patients who are <em>young</em> - their age could be a significant factor. (I don’t know of a short name for this concept. Note that this isn’t anything wrong with the RCT itself, it’s our unjustified inferences.)</p>
<p>Another example: you do an A/B test on your clothing website where, during the same time of the day, people are randomly either shown a t-shirt in blue or a t-shirt in red, and you measure how many of them bought it. If the red shirt sold more than the blue one, you can’t infer that red shirts will always sell more, even though you did a randomized controlled trial. That’s because there could be other factors - like it was Valentine’s Day and so people bought red more. In a couple of months, it might be the cricket World Cup and people in India would want to support their team in blue and so would buy the blue t-shirt over the red one. Or it could be that the customers you got on the day of the experiment weren’t like your usual customers, and your usual customers like blue more.</p>
<h1 id="abstract-based-on-decisions">Abstract based on decisions?</h1>
<p>Is it that the details of one decision are conditionally independent of the details of other decisions given the decision choice?</p>
<p>You could treat each decision as an autonomous mechanism and refer to it whenever you want to make that particular decision.</p>
<p>Queries are hidden decision requests. When you ask about the stats on dog bites, what you really want to know is whether to go out for a walk near that park where dogs keep barking at you. For example, in a journal paper on cognitive psychology experiment, you could refer to some other psychology results. However, instead of depending on the causal model they present, you could just ask directly for the decision you care about.</p>
<p>In short, I imagine this like building a function by composing other functions. You want to recommend a choice for a decision. You then use recommendations for other decisions to make your recommendation, just like calling other functions within your function.</p>
<p>The key point is that you treat each decision as a single independent source, like a programming service. You don’t care how it makes its recommendation. You just call it, and it gives you the answer.</p>
<hr />
<p>Let’s drill down to the math. If you knew just the possible choices, and your probability estimate and value of each outcome, then you could make the right choice without knowing anything else.</p>
<p>And, no, you can’t just provide the probability estimates and ask somebody else to fill in the value preferences later. The value equations fundamentally define the value of information. It’s why you don’t represent your laptop at the level of atoms - it’s not worth it.</p>
<p>So, if you’re a general who want to transport hundreds of thousands of soldiers from one end of a country to another, you need to specify your risk tolerance. If you cannot risk a train breakdown or a long delay, then you would probably instruct your delegates to not strain the system too much - maybe allow time for the engines to cool down or whatever, don’t pack too many soldiers in, and so on. However, if you’re ok with a few breakdowns but need soldiers immediately, then you can order them to take liberties with the system and maximize the number of soldiers per train. (I was watching a World War I documentary this week)</p>
<p>Therefore, <code>decision :: values of outcomes, probability estimates -&gt; choice</code></p>
<p>What is my decision here? I want to build simple, independent mechanisms that will do one task well and that I can use in several places. So, my question is: what should those mechanisms look like?</p>
<p>Initially, I thought that each mechanism should be a causal model. Get some evidence for some variables and use it to build a causal model of those variables. However, this doesn’t scale because of the risk-tolerance factor above. Sometimes, you need a very precise answer and other times you can get away with sloppiness.</p>
<p>So, you can’t go with a one-size-fits-all causal model. You need something more. You need a causal model that can account for different value functions.</p>
<p>In essence, you will ask this black box about a decision with different value functions and it will spit out the correct recommendation. How would you design such a black box? Well, it depends on the range of value functions you expect to encounter. If you get asked “which house do I buy” by a guy with a $100k budget and a guy with a $20 million dollar budget, you will need widely different causal models. In the first case, you can get by with simple variables like size, condition, proximity to railway station or bus stand, etc. Whether the house is in a “beautiful locality” or not will not matter much to the first buyer - he won’t be willing to pay extra for it. For the latter, however, things like the class of the locality, the famous people living nearby, the quality of private schools, etc. all enter the picture.</p>
<p>I suspect you need a whole lot more valuable information in the latter situation. Rather, in the first case, you needed only a little more information before further information was too costly to be worth it. In the second case, because you were dealing with such a large sum and different choices gave vastly different values (just one loud, tacky neighbour would ruin even a classy mansion), you could gather a lot of information before it became too costly to go forward.</p>
<p>So, there’s the cost of gathering information. If your decision suddenly matters a lot more to you - if different choices lead to different values - then you need to actually pay to go and get more information (maybe by spending time researching on the web or meeting people or running experiments).</p>
<p>But if you’ve already gathered the information, you can store it and just use it the next time somebody asks you the same question (what programmers call “memoization”). So, we can do that for the most frequently asked questions.</p>
<p>So, there’s the decision, with its different choices, and the expected value of different levels of information - perfect or partial information. (I’m not fully clear about this.)</p>
<p>Later, every time you need to know about this decision, you consult only this black box, with the required inputs. This part of your life is handled, once and for all.</p>
<p>Of course, when you get new information, you need to update the black box. Or maybe you just look at the value of information calculation inside it and see if getting new information has become cheap enough that it’s worth it now.</p>
<h1 id="tests">Tests</h1>
<p>Why not test your ideas about decision-oriented thinking, causality, categories, and information theory by writing a basic AI? If you believe that causality and decision-oriented thinking are the <em>optimal</em> ways of solving problems, then show it. Work your way up simple AI problems and solve them optimally (maximizing the entropy of the message at each stage and so on).</p>
<h1 id="weekly-report---march-14---20-2016">Weekly Report - March 14 - 20, 2016</h1>
<p>Didn’t use the #reaches counter at all, so my growth rate for this week is zero. I wrote a thousand words on abstracting ideas with decisions as the interface. Didn’t do much practice for the rest of the week.</p>
<p>Total hours of practice: <strong>21</strong> hours in 7 days.</p>
<h2 id="ideas-generated-this-week">Ideas generated this week</h2>
<p>Don’t talk about valuable information without the decisions you care about; why we go into (particular) fantasies - because each medium make the other aspects of life seem boring and ridiculous. editing = remove all the boring bits. Monopoly vs competitive market meme-makers (cult vs ads).</p>
<p>When summarizing, make an initial one just to force you to release.</p>
<p>Summarized the Talent Code chapters on deliberate practice: sweet spot = important cues where your answer is not strong or not correct; so, practice <em>only</em> with desirable difficulties; unique predictions of myelin theory - the more you fire, the better you get, the older you are, the harder it is, and breaks diminish your skill.</p>
<p>Chunk = hierarchy of linked memories that you’re able to abstract or decompose or both. Holy Shit Effect = being able to abstract a “complex” situation and respond with a “complex”, coordinated solution. How situation-response might work - abstract situation, trigger on the high-level cue, decompose the high-level memory into actions, and check using feedback.</p>
<p>Nature vs nurture: we think “genetic component” in variations means that there’s no point in doing anything. No. If you practice or have better nutrition or whatever, you <em>will</em> get better absolute results.</p>
<p>Modularity of your chunks means you can adapt to situations and fix errors. How to get modular chunks? Build alternative chunks for each variable by slowing it down and strengthen the cue for “alternatives”.</p>
<p>How to guarantee you’ll only think about X? Make that the <em>only</em> cue you see. Your thoughts are caused by internal and external cues; so, to control you memeplex, control the external cues that reach you. Make the important cues (like empiricism, causality, etc.) be the only ones that enter your mind. Similarly, if you want to think an important thought right now, then remove crap cues right now and leave just the one right cue. Internet bombards you with attractive cues, btw, thus making you think thoughts you don’t really want (reddit, Youtube, etc.).</p>
<p>Your cue-response is not “good enough” -&gt; change your model vs not. (Suresh Raina not needing to improve his technique in the IPL, Kohli changing his stance after the England series) All you use in your model is valuable information. So only seek valuable areas where you can fail. Also, I think we build models by ignoring variables that are conditionally independent of the expected value given the other variables.</p>
<h1 id="weekly-plan---march-20-2016">Weekly Plan - March 20, 2016</h1>
<p>Read for an hour each day. This week: summarize the rest of Talent Code; summarize the apprentice section of Mastery; summarize the practice instructions in Talent is Overrated.</p>
<p>Have fun for around three hours each day.</p>
<p>Take one hour everyday to run drills and create new ones based on old important ideas.</p>
<p>Write an AAR in the evening.</p>
<p>Practice domain-independent causal decision-oriented thinking for five hours everyday. Three hours of intense practice and two hours of light work.</p>
<p>The question now remains: which cues and which responses should I practice?</p>
<p>Remember, I don’t want to answer that question now for all eternity. I just want to know what to practice this week. So, here’s a list: for now, just summarize the books you read.</p>
<p>As for work, gather three exemplars each for important concepts. Also, collect important cues and skill responses for next week (like for empiricism and taboo).</p>
<h1 id="next-week">Next Week</h1>
<p>Write essays for an hour each day.</p>
<p>Read and summarize some of The Sequences.</p>
<p>Add some more gamification. Also, look at your mental model of concepts and your reference card for more ideas for improvement.</p>
<p>I need to make a budget for each day - assign property rights to my goals. Otherwise, it’s hard to make decisions.</p>

<div class="info">Created: February 15, 2016</div>
<div class="info">Last modified: March 24, 2016</div>
<div class="info">Status: in-progress</div>
<div class="info"><b>Tags</b>: causality</div>

<br />
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'spkrationalitytrainingground'; // required: replace example with your forum shortname
    var disqus_identifier = '/practicing-causal-thinking.html';
    var disqus_title = 'Practicing Causal Thinking';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
	var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
