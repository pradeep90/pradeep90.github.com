<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel="icon" type="image/png" href="./images/favicon-32x32.png" sizes="32x32" />
	<link rel="icon" type="image/png" href="./images/favicon-16x16.png" sizes="16x16" />
        <title>One-Button Change - SPK's Rationality Essays</title>
        <link rel="stylesheet" type="text/css" href="./css/default.css" />
        <link rel="stylesheet" type="text/css" href="./css/highlight.css" />

	<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script> -->
	<!-- <script type="text/javascript" src="/js/header-links.js"></script> -->
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

	<link href="atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed" />

	<!-- Google Analytics stuff -->
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-51321929-1', 'pradeep90.github.io');
	  ga('send', 'pageview');

	</script>

    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="./">Rationality Essays</a>
            </div>
            <div id="navigation">
                <a href="./">Home</a>
                <a href="./notes.html">Notes</a>
                <!-- <a href="/about.html">About</a> -->
                <a href="./archive.html">Archive</a>
		<a href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed">RSS</a>
            </div>
        </div>

        <div id="content">
          <h1 id="post-title">One-Button Change</h1>

            <!-- <center><img src="https://fbcdn-sphotos-d-a.akamaihd.net/hphotos-ak-prn1/t31.0-8/p600x600/10257116_10202295769100492_2438594605053717342_o.jpg" height="400" width="300" class="sujeet-pic" alt="Sujeet pic" /></center> -->

<h1 id="one-change-at-a-time">One Change at a Time (??)</h1>
<p>Hypothesis: We get evidence about our program by running it on some input or by type-checking it.</p>
<p>Hypothesis: We can process evidence about one variable at a time. Beyond that, we get confused.</p>
<p>(Yes, we can get lucky with multiple changes, but that won’t pay off on average.)</p>
<p><strong>Hypothesis</strong>: One key factor in programming efficiently - aka processing evidence about our program - is to make one high-level change at a time before you get evidence.</p>
<p>This means that you should be able to choose between your two design choices, say process scheduler A and process scheduler B with just one small change. No changing variable assignments in three different places, not hasty commenting of 15 lines of code, no tweaking of multiple configuration files - just one button press.</p>
<p>(Why would this weird condition help write programs faster? We’ll see.)</p>
<h1 id="how-to-program-with-one-button-changes">How to Program with One-Button Changes (??)</h1>
<p>How will this affect the way you code?</p>
<p>For one, you can’t change multiple lines of code within some other function. Because then, if you wanted to roll back those changes, you would have to edit multiple lines.</p>
<p><strong>Corollary</strong>: Any change you make must be encapsulated within a new function before you run the program.</p>
<p>Now, what if you wanted to switch from scheduler A to scheduler B? Sure, A is within a function that you can comment out (or in a class method that you can change at runtime via polymorphism). But B could be a bunch of lines of code strewn across your project. So, to switch to B, you would have to uncomment all those lines. Not allowed.</p>
<p><strong>Corollary</strong>: Any alternatives must be easily switchable (when you run the program).</p>
<p>In OOP, you would do this via interfaces or inheritance, where you simply switch the class that is implementing the interface, and the caller code is none the wiser. In functional programming, you simply switch to another value of the same type or type class.</p>
<p>What happens when you’re starting out with a new feature, like pipes in an operating system (completely hypothetical example; not related to my coursework at all)? If you press the button, you will switch to your neatly encapsulated function or class that implements pipes. But what if you want to go back to a pipe-less operating system, just to check for correctness or performance? You may not be able to, if you have pipe initialization and destruction code lying around, and if processes have information about pipes they may own.</p>
<p><strong>Corollary</strong>: You must have a default alternative for every choice (when you run the program).</p>
<p>For example, if you implemented pipes, your default would be the non-piped version. (Again, you should be able to switch between these two in one button-press.) If you implemented a new time-share scheduler for the operating system, you must encapsulate the original scheduler as a default alternative.</p>
<p>Likewise, if you’re setting out on a “complex” change, you should have a default stub of it that does nothing.</p>
<h1 id="empty-inside">Empty Inside</h1>
<p>Question: What if you’re not creating alternatives, like two types of schedulers, but rather just one algorithm, like pipes for an operating system?</p>
<p>Question: What kind of change are you making at each point? What was the program like earlier and what is it like after the change?</p>
<p><strong>Hypothesis</strong>: You should have a default stub that has the <em>same type</em> as your final code, but doesn’t affect the behaviour of the system. Then, you should have a one-button change that allows you to switch to the final code.</p>
<p><strong>Corollary</strong>: Your unit test for a feature should <em>fail</em> when you switch to the default implementation and <em>pass</em> when you switch to the feature-filled implementation. As usual, it should be a one-button change.</p>
<p><strong>Hypothesis</strong>: Add unit tests (or assert contracts) for everything that your new feature changes.</p>
<p>Hypothesis: Having a one-button change between feature and no-feature allows you to roll it back quickly to see what was caused by the feature itself as opposed to the earlier code.</p>
<p>For example, my test for pipe deletion passed even though my <code>pipdelete</code> function was empty! I’d mixed up types in other places, which meant that my desired pipes were not getting initialized in the first place. So, the test passed whether or not I implemented my <code>pipdelete</code> feature. Good to know. Otherwise, I’d be scratching my head wondering which of my seven changes in different parts of the system had caused the bug.</p>
<h1 id="upshot">Upshot</h1>
<p>What do all those straitjackets get you? I’m not fully sure. We’ll find out the usual way: good ol’ fashioned experimentation.</p>
<p><strong>Hypothesis</strong>: Single, easily-reversible change -&gt; any behaviour that is in the program with the feature on and not in the program with the feature off must be caused (at least partly) by the feature.</p>
<p>Contrast that to shotgun change, where you aren’t sure which change broke your code.</p>
<p>Hypothesis: First-class objects -&gt; make it easier to switch.</p>
<p>For example, a value or function or object of the same type.</p>
<p>Question: Do you really need to rollback that often? Yes, you will want to toggle a new feature while implementing it. But after implementing A, B, and C in sequence, will you need to check out AB’C? Or will you treat the existing program as correct and indivisible?</p>
<p><strong>Observation</strong>: Will need to rollback if you think of a test or find a bug after the implementation.</p>
<p>Hypothesis: Hard to come up with good tests or properties in advance.</p>
<p>Hypothesis: If you come up with a test or property in the future, you need to toggle back through your features to see when it stops passing.</p>
<h1 id="multiple-possible-causes-are-hard-to-reason-about">Multiple Possible Causes are Hard to Reason About</h1>
<h2 id="intermediate-states-are-hard-to-reason-about">Intermediate States are Hard to Reason about</h2>
<p>Observation: Suppose you had to do a number of things to reset a system. You could miss a step or two and land up with “weird” behaviour.</p>
<p><strong>Hypothesis</strong>: Multiple changes when trying to go to a desired state -&gt; could leave the system in a state that is “hard to reason about”.</p>
<p>For example, you need electricity, intact wires, a working bulb, and a switch in the ON state to make a light bulb glow. If however, there’s a problem with the bulb or if you forgot to pay your electricity bills, the bulb won’t glow. But you don’t know exactly what caused the problem.</p>
<h2 id="minimize-number-of-possible-causes">Minimize Number of Possible Causes</h2>
<p>Observation: The problem is that you can’t <em>identify</em> the possible causes. You become highly uncertain.</p>
<p><strong>Hypothesis</strong>: “Processing evidence” = figuring out which states of the system could have caused the given output.</p>
<p>This is what Bayes theorem talks about.</p>
<p><strong>Hypothesis</strong>: Humans can’t handle a bunch of possible causes leading to the same output.</p>
<p>(That’s why they lump them in the same category.)</p>
<p>Hypothesis: Humans like to toggle one variable at a time because they can’t handle it if one of several things could have caused the output.</p>
<p>Observation: When there’s a lot of stuff that we’ve changed about a system and the output is not anything we can normally explain, we consider the system “messy” or “chaotic”.</p>
<p><strong>Hypothesis</strong>: “Chaotic mess” = can’t tell which state caused the given output (because there are too many of them).</p>
<p>Classic example: when I changed a bunch of scheduler code and couldn’t tell where the bug was.</p>
<p><strong>Hypothesis</strong>: Aim of category design = <em>minimize</em> the number of possible causes of any outcome.</p>
<p>For example, test if there’s electricity at the bulb socket. Then, try to plug in the bulb. If there was no electricity initially, then the earlier part of the system is broken. If there is electricity and if the bulb works, then there’s no problem. If it doesn’t, then we know that the bulb is what is broken.</p>
<h2 id="debugging">Debugging</h2>
<p>Hypothesis: Aim of programming: Fix undesirable output.</p>
<p>Fixing undesirable output would involve figuring out its cause and then changing it. The problem arises when you can’t figure out the cause of some undesirable behaviour.</p>
<p><strong>Hypothesis</strong>: Debugging = figuring out the <em>cause</em> of some undesirable behaviour.</p>
<p><strong>Hypothesis</strong>: We spent a lot of time, maybe most of our time, in debugging.</p>
<p>Observation: Why do I feel low in confidence sometimes? Don’t quite know. Is it mostly because I haven’t exercised or because I’m not focusing on the topics I care about or don’t have a “great” social life? Don’t know. I’m not able to do backward inference on my social performance.</p>
<h2 id="break-the-output-into-pieces">Break the Output into Pieces</h2>
<p>Hypothesis: To find out the cause of some output, break it into pieces according to known causes and thus narrow down the culprits.</p>
<p>For example, if you know that the output list was mapped from some input list, then an error in the 5th element must have been due to the 5th element of the input list.</p>
<h2 id="backward-inference">Backward Inference</h2>
<p><strong>Hypothesis</strong>: This is backward inference.</p>
<p>And it’s hardest when you have made a lot of changes before observing some understandable output. For example, when working on my OS assignment, I changed the scheduling code in a lot of places and then ran my test case. The OS hung after the initial output. Why? I had no clue.</p>
<p>Observation: This is what House does. He look at symptoms and infers the diseases that could have caused them. (Fictional evidence, but representative of doctors who do, in fact, diagnose patients.)</p>
<p>Laymen or even his fellow doctors are often puzzled by the same observations. (Fictional evidence.)</p>
<p>Observation: Mystery-solving (a la Hercule Poirot or Sherlock) is all about backward inference.</p>
<h2 id="strong-evidence">Strong Evidence</h2>
<p>Hypothesis: Strong evidence = something that tells you the cause is in <em>this</em> part of the system, not that one.</p>
<p>This is what we desire. We want to narrow down the suspects.</p>
<p><strong>Hypothesis</strong>: If you can switch easily (and reliably) between two alternatives, you can observe the difference in output, and thus figure out where the cause lies.</p>
<p>Question: What if you could run the program only once? How could you design your program to minimize the number of possible causes?</p>
<p><strong>Question</strong>: What sort of test cases should you design so that you get discerning output?</p>
<h2 id="how-do-we-build-a-system-forward-backward-inference">How do we Build a System? Forward + Backward Inference</h2>
<p><strong>Hypothesis</strong>: We want our system to have some target property. So, we change some variables in the hope of hitting the target property. Then, we observe the actual output and infer which variables we should have changed differently. And so it goes.</p>
<p>It’s forward inference to compute the actual output (which the computer automates for us, in the case of programming) and backward inference to figure out which variables we need to change further.</p>
<p>Hypothesis: The problem, of course, is when you have a lot of other variables in between.</p>
<p>For example, I just wanted to change the scheduling algorithm of the XINU OS. It was a simple enough conceptual change, but because my change affected a lot of other variables (like whether interrupts were disabled or enabled, polled I/O vs blocking I/O, null pointer errors, etc.) I couldn’t tell exactly which of my changes had caused what.</p>
<h2 id="unit-tests-minimize-number-of-causes">Unit Tests minimize Number of Causes</h2>
<p>Hypothesis: Unit tests minimize number of causes because their output depends only on one function or class.</p>
<h1 id="big-functions-are-hard-to-reason-about-too">Big Functions are Hard to Reason about too</h1>
<p>Observation: Bunch of journal notes and essays. Don’t know exactly what they contain or what they advise for some problem I face. Clearly, a “chaotic mess”.</p>
<p>Observation: Unfamiliar function - can’t tell what it does.</p>
<p>Observation: If I have a variable that I can change to switch the scheduler from a time-share scheduling algorithm to a proportional-share algorithm, then I can kind of tell the difference in behaviour between the two.</p>
<p>Observation: But if I have three hundred lines of code spread over four files that are different between time-share and proportional-share scheduling algorithms, I find it much harder to predict the differences in behaviour.</p>
<p><strong>Hypothesis</strong>: Lots of possible input states and thus lots of possible output states -&gt; hard to infer forward or backward.</p>
<p>Why? Not quite sure. But if it’s an arbitrary function, then you have a lot of input-output mappings to remember. You’re liable to give up.</p>
<h1 id="restricting-yourself-to-one-button-changes-simplifies-your-model">Restricting yourself to One-Button Changes simplifies your Model</h1>
<p>Hypothesis: One-button change between alternatives -&gt; simpler type signature (A vs B -&gt; X vs Y).</p>
<p>Corollary: You won’t be able to make low-level predictions about, say, the exact priority of each process at each point of time, but you would be able to predict the high-level properties (such as, I/O-bound processes will go first in a time-share scheduler).</p>
<p>Corollary: One-button change between small set of high-level alternatives -&gt; <strong>cannot</strong> choose some arbitrary intermediate state.</p>
<p>Corollary: So, the output will always be that corresponding to one of the high-level alternatives. Much easier to infer forward or backward.</p>
<p><strong>Hypothesis</strong>: Allow yourself only one-button changes vs can change anything anywhere -&gt; far simpler model of the system vs lots of possible inputs and lots of possible outputs.</p>
<p>You’re restricting your set of possible interventions. Because you know you haven’t changed anything else anywhere, the only possible inputs are those defined by your high-level categories.</p>
<p>Hypothesis: Allow yourself only one-button changes -&gt; fewer possible interventions and thus fewer possible input states.</p>
<p><strong>Hypothesis</strong>: Number of possible interventions -&gt; number of categories.</p>
<p><strong>Hypothesis</strong>: Number of categories -&gt; number of possible input-output mappings -&gt; number of possible causes for any output and number of possible outputs for any cause.</p>
<h1 id="tests">Tests</h1>
<p>Observation: I have one test for each condition mentioned in the spec.</p>
<p>For example, “In any case, if the arguments are invalid, the pipe was already connected to other processes, or the state of the pipe does not permit connection, the system call returns SYSERR.” I have a test for each of them.</p>
<p><strong>Observation</strong>: Red-green saves my ass. I keep forgetting to add my new test case to the test list, and so it seems like the test has passed. Only when I make it <em>fail</em> do I realize my mistake.</p>
<p><strong>Hypothesis</strong>: To be sure that some output property is caused by your feature, toggle it and see whether the property toggles too.</p>
<p><strong>Observation</strong>: Tests bring out bugs that I would never have inferred.</p>
<p>For example, deleting a pipe caused a pipe to be in a non-active state when calling disconnect on the writer. Who knew?</p>
<p><strong>Hypothesis</strong>: How to write tests - look at the interface alone and analyze the different possible inputs.</p>
<p>For example, <code>pipe_disconnect_reader</code> cares only about the different states of the pipe (free, used, connected, writer disconnected, etc.), not about the rest of the system.</p>
<h1 id="handle-all-possible-high-level-inputs">Handle all possible High-level Inputs</h1>
<p><strong>Hypothesis</strong>: To be confident that you’ve written your function correctly, handle all the high-level categories of your input.</p>
<p>Corollary: Errors crop up when you omit some cases.</p>
<p>The most obvious case is forgetting to check for NULL. Another case is to handle all possible states of your input argument, like a pipe that is not connected to anything or a pipe that has been freed.</p>
<p>Corollary: Static type-checking helps you by making sure you handle all the possible input values, especially in the case of sum types like in Haskell.</p>
<p><strong>Corollary</strong>: You must yourself know what must happen for each input configuration.</p>
<p><strong>Lesson</strong>: Write your code one branch at a time. Write a unit test up-front to make sure you’re actually adding a feature.</p>
<p>You should change code only within one of the possible input categories. If you want to do something for input A, you must do something (maybe a dummy default action) for inputs B and C.</p>
<p>Corollary: That way, at each point, you can tell which value was caused by the branch for A and which one by the branch for B.</p>
<h2 id="what-is-the-next-unit-test">What is the Next Unit Test?</h2>
<p>Hypothesis: If you’re stuck, ask yourself what is the next unit test you want to pass.</p>
<h1 id="work-needed-is-proportional-to-number-of-test-cases">Work Needed is proportional to number of Test Cases</h1>
<p>Corollary: The total work you need to do depends on the number of branches you need to implement and the time it takes you to code and test each branch.</p>
<p>Observation: I didn’t even <em>know</em> how many branches I had to deal with. I couldn’t see them in my head when I thought about the problem of “implementing pipes for XINU”.</p>
<p>Corollary: Number of branches you had to implement = number of test cases.</p>
<p>So, use the test cases to determine the total work you had to do.</p>
<p>Corollary: Number of test cases is determined by the number of branches you need to implement. Make sure you have that many.</p>
<p>Hypothesis: If we assume that the time needed to make one unit test pass is constant, then the estimated time for the whole project should be proportional to the number of branches in each function (i.e., the number of test cases).</p>
<p>We can use that to estimate time needed.</p>
<h2 id="planning-fallacy">Planning Fallacy?</h2>
<p>Observation: I underestimated the number of test cases I would need to implement. Sometimes, I was so unsure that I needed to have unit tests for smaller things like adding a semaphore to my pipe entry, because I’d not used it before.</p>
<p>Observation: I didn’t even know what output I wanted from some function.</p>
<h1 id="callers-define-your-contract">Callers define your Contract</h1>
<p>Observation: Hard to change the behaviour of <code>pipe_set</code> without knowing how and where it’s been used. I don’t want to break its “contract”.</p>
<p>Hypothesis: If you had unit tests (and an assertion-based contract), you could just use that as your contract and change whatever you wanted as long as you didn’t break it.</p>
<h1 id="why-you-need-to-roll-back-sometimes">Why you Need to Roll Back Sometimes</h1>
<p>Observation: Error when trying to create a semaphore. No clue why.</p>
<p>Experiment: Didn’t change anything in the lower-level functions. Just toggled the high-level tests to see which combination broke it.</p>
<p>For example, I knew that running the 20 tests gave the error. Running 0 tests didn’t give the error. Running the first 10 didn’t either. Turned out running two particular tests together gave the error. Cool. That narrowed it down. (I was able to find out that I was initializing too many semaphores and thus running out.)</p>
<p>Imagine if I’d tried this without the high-level functions and had made changes here and there. I would have been overwhelmed within a few minutes. Guess how I know that? Because that’s what I started out doing. Only after half an hour or so did I wise up.</p>
<p><strong>Hypothesis</strong>: Need to roll back and toggle features when you have errors across functions.</p>
<p>Unit tests catch errors that are within a single function. For errors across functions, you need high-level toggling.</p>
<h1 id="backward-inference-1">Backward Inference</h1>
<p><strong>Hypothesis</strong>: This is how you do backward inference. You narrow down some combination of high-level causes and test them till you find one whose effect matches the observed output. After, that you narrow it down at the next level, thus keeping the “complexity” or number of possible causes limited at all times.</p>
<p>Observation: The key was that turning on all the high-level causes on gave you a positive answer (error) and turning them all off gave you a negative answer (no error). So, you could tell that the error must begin with some combination of causes between zero and everything.</p>
<h1 id="which-input-configuration-did-i-fail-to-handle">Which Input Configuration did I Fail To Handle?</h1>
<p>Observation: Notice that I didn’t exactly break any of my older unit tests. What I broke was the underlying code (<code>pipinit</code>), which was exacerbated by the fact that I ran so many tests and ended up creating too many semaphores.</p>
<p>Observation: I added a new property to the program (semaphores), which caused problems.</p>
<p>Observation: I failed to ensure the property that the program used only a limited set of semaphores.</p>
<p>Question: Where could I have checked for that property?</p>
<p>Well, the number of semaphores created would be proportional to the number of times <code>pipinit</code> was called, which I assumed was just once during system initialization. Turned out that <code>pipdelete</code> also called <code>pipinit</code>. As did my test setup function (when trying to reset all pipes).</p>
<p>Observation: It’s simple. I should have handled the case where <code>semcreate</code> returns SYSERR. That’s all. That’s how stupid my mistake was. Cost me a full hour spent scratching my head.</p>
<p><strong>Hypothesis</strong>: Bug -&gt; ask “which input configuration did I fail to handle?”.</p>
<p>Observation: This would never have happened in Haskell. It would have given me a <code>Maybe Semaphore</code>, whose <code>Nothing</code> case I would be forced to handle.</p>
<p>Lesson: In particular, look closely at the input type you’re getting.</p>
<p>For example, in <code>pipe_disconnect_writer</code>, instead of worrying about all the possible states that the rest of the system can be in, I should look at just the input pipe. It can be in a free, used, or connected state. If I handle all three cases faithfully, I’ve done my job. Nothing else to worry about.</p>
<p>Observation: The reader process could be in a waiting state when somebody disconnects it. So, I have to handle the different process states too.</p>
<p>Observation: I don’t know what to do in the various cases there.</p>
<h1 id="look-at-properties-of-your-own-input-not-of-other-functions">Look at Properties of your own Input, not of Other Functions</h1>
<p>Observation: Have to look at callers of <code>pipe_disconnect_writer</code> because I’m not sure if there can ever be a case where the reader disconnects first and leaves writer calling disconnect later.</p>
<p>Actually, I don’t have to. I can see that <code>pipe_disconnect_reader</code> always leaves writer disconnected. If the pipe to reader was in the PIPE_CONNECTED state, it would disconnect writer. Else, writer would have already been disconnected. Inference!</p>
<p>Hypothesis: I suspect I could avoid writer having to look through reader’s code by checking the invariants on pipe itself.</p>
<p>Pipe doesn’t even have a state for “reader disconnected but writer not yet disconnected”. That’s it. End of story.</p>
<p><strong>Hypothesis</strong>: A function shouldn’t need to look at the innards of other functions to decide what to do. It should just look at its inputs, their properties, and its own desired output properties.</p>
<h1 id="processing-evidence">Processing Evidence</h1>
<p>Question: What kinds of observations do I have to process?</p>
<p>For example, let’s consider each operation of the kind “ABCD -&gt; X and ABC’D’ -&gt; X implies that C and D probably don’t cause X” to be a single cognitive step. (I think we process that kind of stuff really quickly.)</p>
<p>Question: So, how many such operations do I have to run (for a given number of branches)?</p>
<h1 id="lost-track">Lost Track</h1>
<p>Observation: Got stuck debugging a stupid return value error. Lost track of what my original aim was.</p>
<p>One change at a time.</p>
<h1 id="debugging-principles">Debugging Principles</h1>
<p>Hypothesis: You need to have a really small test case.</p>
<p>My mistake with the scheduler was that I was working with a six processes all running at the same time doing god-knows-what. How are you supposed to debug that efficiently?</p>
<p>Observation: Not able to interpret the debugging output because there are too many printf statements and I don’t know what came from where.</p>
<p>Observation: Narrowed it down by toggling the high-level function calls. Things look much clearer. I know that the output is coming from a given two lines.</p>
<p>Observation: Narrowed it even further. Check only the semaphore part.</p>
<p>Observation: Right now, things “aren’t straight” in my head. I don’t know which configurations I’ve handled and which ones I haven’t. So, I don’t feel like I can reason about the behaviour of the program.</p>
<p><strong>Hypothesis</strong>: Know which inputs configurations you’ve handled and which not -&gt; feel confident about the behaviour of the program.</p>
<p><strong>Hypothesis</strong>: Notice what changes you’ve made. Any change in behaviour is due to a change you’ve made.</p>
<p>So, look at your diff from the previous state.</p>
<p><strong>Lesson</strong>: The moment you get an error, toggle back to a working state and then look at the differences.</p>
<h1 id="duplication-leads-to-more-input-configurations">Duplication Leads to More Input Configurations</h1>
<p>Observation: The official code had a state field that could take the value <code>PIPE_CONNECTED</code>, etc. However, that was strongly correlated with the writer and reader semaphore being free or not-free. So, I may have to consider multiple input configurations that actually mean the same thing.</p>
<p><strong>Hypothesis</strong>: Code duplication -&gt; more input configurations that give the same output but which you have to handle separately in case they are given inconsistently.</p>
<p>For example, I would have to flag an error in the case where the variable says <code>PIPE_CONNECTED</code> but the semaphores are actually free. Unnecessary headache.</p>
<p>Corollary: What’s more, when you finally merge those redundant input states, you’ll have to do a lot of careful work to remove the separate if-cases.</p>
<h1 id="truly-pure-functions">Truly Pure Functions</h1>
<p>Observation: Right now, some of my unit tests depend on more than one function. For example, testing disconnect depends on the correct behaviour of “connect”.</p>
<p>Hypothesis: Pure functions won’t be like that. You can genuinely test their input configurations alone.</p>
<p>Observation: But disconnect will still call pipe-related functions like reset or set writer or whatever.</p>
<p><strong>Hypothesis</strong>: Either your higher unit tests will test multiple functions or you will have to use equational reasoning.</p>
<h1 id="abstract-types-reduce-the-number-of-input-configurations">Abstract Types reduce the number of Input Configurations</h1>
<p>Question: How can we reduce the time taken to implement some features?</p>
<p>Observation: Time taken seems to depend on the number of test cases (aka input configurations) and the time taken to pass each test case.</p>
<p><strong>Hypothesis</strong>: Abstract types reduce the number of input configurations and thus reduce the number of tests.</p>
<p>For example, <code>sortInts :: [Int] -&gt; [Int]</code> has way more configurations than the generic <code>sort :: Ord a =&gt; [a] -&gt; [a]</code>.</p>
<p>Lesson: If you want to code faster, design your types well.</p>
<h1 id="understanding-knowing-the-output-for-each-input-configuration">Understanding = Knowing the Output for each Input Configuration</h1>
<p>Hypothesis: Understanding = knowing the output for each input configuration.</p>
<p>Observation: I keep saying “I don’t understand surrogate endpoints (or some other concept)”. But that doesn’t help me move forward.</p>
<p><strong>Hypothesis</strong>: Say “I don’t understand concept X” -&gt; don’t know how to move forward. Say “I don’t know the output for a particular input type X1” -&gt; can look for resources that give you the output.</p>
<p>For example, I don’t know what happens if you predict for the follow-up study in cancer trials using “principal surrogacy” or using “Prentice’s criterion”. I need to figure that out.</p>
<h1 id="forming-an-technique-to-solve-problems">Forming an Technique to Solve Problems</h1>
<p>Question: How do you come up with a technique to solve, say, the do-calculus problems that you find in exams?</p>
<p><strong>Hypothesis</strong>: Come up with a hypothesis for each input type and test it on the problems you’ve seen (and further problems that you invent).</p>
<h1 id="confidence">Confidence</h1>
<p>Hypothesis: Confidence &lt;- knowing the possible input configurations and then knowing that you’ve handled all of them.</p>
<p>With my journal notes, for example, I don’t know the input configurations for some mechanism I’m trying to figure out (like how we learn) and so I don’t know if I’ve covered everything.</p>
<h1 id="assorted-ideas-todo">Assorted Ideas (TODO)</h1>
<p><strong>TODO</strong>: Composition (<code>pipe_is_writer_semaphore_free = pipe_is_semaphore_free . pipe_writer_semaphore</code>). Should you know the properties?</p>
<p>Duplication is bad because it makes you test essentially the same branch multiple times. For example, <code>pipe_is_writer_semaphore_free</code> and <code>pipe_is_reader_semaphore_free</code> both just call <code>pipe_writer_semaphore</code> with different arguments. But I have to run different tests.</p>
<p><strong>Hypothesis</strong>: When you have roughly the same test for two different functions, you have duplicated some code.</p>
<p>Hypothesis: If two branches give you the same output, merge them.</p>
<p>Hypothesis: Uncertainty &lt;- number of branches because the answer for each of those branches could be something different. You have to know all of the outcomes.</p>
<p>Hypothesis: Duplication -&gt; takes more work to test and more work to understand.</p>
<p><strong>Hypothesis</strong>: It’s a mistake to have duplicate code because you end up doing more work to test your program.</p>
<hr />
<p><strong>Hypothesis</strong>: In deliberate practice (and thinking in general), chunks correspond to the branches of your model.</p>
<p>So, chess grandmasters who have learned 50k chunks have learned 50k different branches of their model of chess.</p>
<p>Hypothesis: There’s a lot of duplication in there. You could probably merge parts of several branches. (Maybe it’s necessary for optimization - because they can recognize formations in a flash.)</p>
<p><strong>TODO</strong>: Figure out how you can represent each chunk - aka branch - as a flashcard, for easy learning.</p>
<h1 id="top-level-interventions-vs-surgical-interventions">Top-Level Interventions vs Surgical Interventions</h1>
<p>Observation: In the scheduler problem, I had to change one part of the system to affect the overall behaviour. In the pipes problem, however, I had full control of my system (since I was coding for the unit tests).</p>
<p>Question: Are they different in kind?</p>
<h1 id="when-there-are-no-readily-available-tests">When There are No Readily Available Tests</h1>
<p>Observation: Writing a research project proposal for a course - don’t know what is good and what isn’t.</p>
<p>Question: How do I get feedback? How do I go about implementing “code” (aka models) to handle different inputs?</p>
<p><strong>Hypothesis</strong>: Causes and effects all the way.</p>
<p>For example, come up with the causes and effects of surrogate endpoints.</p>
<h1 id="make-a-change-only-when-a-test-fails">Make a Change only when a Test Fails</h1>
<p>Observation: Wasted a lot of time just staring at the screen hoping for a “perfect” solution to land in my mind.</p>
<p>Observation: I don’t have near-term tests for the changes I’m making to pipgetc. They are all abstract changes.</p>
<p>Observation: Long time since I ran <em>any</em> test (or even compiled the code). No feedback.</p>
<p><strong>Hypothesis</strong>: Make a change only when a test fails. Duh!</p>
<p>It’s called red-green-refactor. I’ve been making changes willy-nilly.</p>
<p>Corollary: Otherwise, you will end up making blue-sky changes to your code.</p>
<p>Corollary: Don’t have to think about abstract cases. Don’t have to “contemplate the ifs”. Just make the current test case pass.</p>
<p><strong>Hypothesis</strong>: Writing code without a failing test -&gt; don’t know if you’re cutting through.</p>
<p>Corollary: Writing to pass tests -&gt; consequentialism.</p>
<h1 id="interface-possible-input-configurations">Interface = Possible Input Configurations</h1>
<p>Hypothesis: Instead of talking about the “interface” to some program, talk about the different input configurations that it may receive. That, together with the expected output, defines its “interface”.</p>
<p>In other words, talk about the test cases it must satisfy.</p>
<p><strong>Corollary</strong>: Minimal interface = few input branches.</p>
<p>For example, <code>sort :: Ord a =&gt; [a] -&gt; [a]</code> has fewer possible inputs than <code>sortInts :: [Int] -&gt; [Int]</code>.</p>
<h1 id="minimizing-the-outputs">Minimizing the Outputs</h1>
<p>Observation: We’ve seen how to minimize the number of inputs to a function by combining those that produce the same output into the same category.</p>
<p><strong>Hypothesis</strong>: If you can get only a few possible outputs, forbid the other output values.</p>
<p>For example, a function that tells you whether or not a semaphore is free will return either true or false. Capturing that in an Int makes your interface unnecessarily large because the caller would have to assert that the output is either 0 or 1. So, make it a Bool.</p>
<h1 id="testing-a-high-level-function-shouldnt-be-blind">Testing a High-level Function: Shouldn’t be Blind?</h1>
<p>Question: Can you tell how many branches (and thus total test cases) a function will have, based on its type signature?</p>
<p><strong>Hypothesis</strong>: It depends on the definition.</p>
<p>For example, if I write <code>fourthRoot</code> from scratch, I would have to test several inputs cases like 0, 1, -1, 0.01, 4, etc. But if I know that <code>fourthRoot = sqrt &lt;=&lt; sqrt</code>, I feel like things become simpler.</p>
<p>Hypothesis: Number of test cases &lt;- amount of code duplication.</p>
<p>For example, <code>sortInts</code> and <code>sortLists</code> would share most of their code, except for the List- vs Int-handling parts. It would be stupid to test the same quicksort algorithm in both cases. <strong>Corollary</strong>: Amount of duplication among tests =&gt; amount of duplication among their functions. Question: So how would you do it ideally? How to not duplicate tests between <code>sortLists</code> and <code>sortInts</code>?</p>
<p>Hypothesis: The answer would seem to be to extract their common code into <code>sort</code>.</p>
<p>Then, you would write <code>sortLists = sort</code> (or just use sort directly where you would have used sortLists).</p>
<p><strong>Question</strong>: But say you did <code>fourthRoot = sqrt &lt;=&lt; sqrt</code>. What tests should you now write?</p>
<p>Hypothesis: You probably don’t need to check for invalid inputs like -1, etc. because sqrt already does that and returns <code>Nothing</code>.</p>
<p><strong>Corollary</strong>: A tester who insisted on being blind to the code and coming up with “advance predictions” would end up duplicating a ton of work for <code>fourthRoot</code>. Ditto for <code>sortLists</code> and <code>sortInts</code> if he didn’t understand that they used the same sorting algorithm.</p>
<p>Hypothesis: This is why people use type systems, so that they don’t have to duplicate their test code. They can reason about things from the types themselves.</p>
<h2 id="no-ifs-no-tests">No Ifs, No Tests</h2>
<p><strong>Hypothesis</strong>: You need to write unit tests only if you introduce new if-statements.</p>
<p>For example, take <code>f = uniq . sort</code>. Why do you believe that that function will return a sorted list unique elements?</p>
<p>Positive exemplar: When I wrote <code>pipgetc</code>, I had to test the cases where the function was supposed to return <code>SYSERR</code>. They were separate if-conditions in the code.</p>
<p>Hypothesis: Could it depend on the size of the function too?</p>
<p>Hypothesis: You should know the properties of each function in the chain.</p>
<p>For example, if I gave you <code>doSomeMagic . sort</code>, you wouldn’t really know what that function did.</p>
<p><strong>Observation</strong>: Ad hoc if-conditions in each function create exponential number of branches in a function chain.</p>
<p>In contrast, a return type of Maybe monadically composes to give you just two possible outputs at each point in the chain.</p>
<h2 id="when-can-you-chain">When can you Chain?</h2>
<p><strong>Hypothesis</strong>: You can chain together functions when each one “handles” all the possible outputs of the previous one.</p>
<p>For example, <code>uniq</code> handles the empty list and normal list outputs of <code>sort</code>. <code>sqrt</code> handles the Just and Nothing outputs of <code>sqrt</code>.</p>
<p>Corollary: Functions not in a chain -&gt; there could be output configurations you failed to handle.</p>
<p>For example, possible NULL values in C.</p>
<p>Observation: If I were doing pipe functions in a chain, I could be certain that they handled all the intermediate configurations. But since I was writing an imperative function, I didn’t know if I had handled the cases where the pipe became free after a call to wait or got disconnected or whatever.</p>
<h1 id="exams-input-branch-concept-needed">Exams: Input Branch = Concept Needed</h1>
<p>Hypothesis: Input branch = question that I have to answer. Which depends on the concepts needed.</p>
<p>Hypothesis: Input branch = concept needed. I need to have the correct output for each concept. Output = concept definition.</p>
<p>For example, I need to know what a “proper causal path” is, in case they ask for it in the exam.</p>
<h1 id="why-refactor-your-proofs-and-code">Why Refactor your Proofs and Code?</h1>
<p>Hypothesis: Refactor -&gt; find simple solution -&gt; store that as your output for that particular input.</p>
<p>Reuse that solution for other inputs -&gt; learn to recognize that input type based on this technique.</p>
<p>For example, HW2 8(c) took a lot of trial and error for me to find the answer. (Still don’t know if I’ve made a mistake somewhere.) Now, if I cleaned it up and got to the answer in, say, three steps, then I could extract general lessons from that clean solution.</p>
<p><strong>Observation</strong>: Basically, I’m unable to “draw lessons” from a jumble of trial-and-error proof steps.</p>
<p>Why not?</p>
<p><strong>Hypothesis</strong>: I can’t see which parts of the input led to which parts of the output.</p>
<p>So, my current “proof” (more like one page of arrows and scribbles) feels like it pertains only to problem 8(c). I can’t see what I would reuse for a variation of the problem.</p>
<p>Corollary: This is why you need to do proofs over and over till you get a succinct solution. (Ditto for programming.)</p>
<p><strong>Hypothesis</strong>: You need to bring your proof into a form where you can see that if you toggled a high-level variable A, you wouldn’t need to do step 1 anymore. If you toggled B, you wouldn’t need step 2 anymore, and so on.</p>
<p>Why can’t I do that now? The proof is so large and hairy that I can’t imagine the alternative.</p>
<h1 id="confusion">Confusion</h1>
<h2 id="confused-by-the-options">Confused by the Options</h2>
<p>Observation: Still confused (even though I did the proof a few minutes ago).</p>
<p><strong>Hypothesis</strong>: Confusion = don’t know the conditions when you should choose option A vs option B vs option C (in order to reach your target).</p>
<p>For example, I can see that two back-door paths from X to Y are potentially unblocked if I condition on W1 or W2.</p>
<p>What options do I have? I could apply rule 2 on X, rule 3 on X, condition on Z1, condition on W2, condition on W1, or condition on some combination of those 3. Which one should I choose?</p>
<p>Next, if I choose to condition on Z, what should I do? Rule 2 on X, rule 3 on X, rule 2 or Z, rule 3 on Z, condition on W1, etc.</p>
<p>There are tons of options!</p>
<p>Observation: Experts somehow slice through this thicket of options and hone in on the correct one.</p>
<p><strong>Hypothesis</strong>: Given the graph and the desired expression, there is a direct way to come to the correct step <em>without</em> much trial and error.</p>
<p>Observation: There are only three trails from X to Y.</p>
<p>Hypothesis: Maybe there is a simpler way to come to an ID expression without traversing the do-calculus expression tree. Use the trails somehow. (Don’t know how.)</p>
<p><strong>Observation</strong>: Still feels like every step of the proof depends on every other step.</p>
<p>Basically, I’m still traversing the tree by trial and error. If I choose rule 2 on X, then the whole rest of the proof changes (it seems).</p>
<p>Question: Why not try all possible techniques?</p>
<p>Observation: Heavy resistance from my mind when I try to do that.</p>
<p><strong>Hypothesis</strong>: I believe that trial and error is inefficient, so I have zero motivation for doing it. Correct solutions usually lead to the answers directly without much trial and error. That feels like the signature of a good technique, and conversely, trying things blindly feels like the signature of a bad technique.</p>
<p>That seems to have paid off in general. Looking for direct algorithms seems to have been a good heuristic in the past.</p>
<p>Corollary: That also makes me more confused than most, because I’m unwilling to accept trial and error where I can’t see why I’m using some technique, or use a half-cooked understanding of some technique. I need crystal-clear understanding before I take action.</p>
<h2 id="confused-write-a-test">Confused? Write a Test</h2>
<p>Observation: Confused about whether a process waiting on a semaphore will get a return value of SYSERR or OK. Been thinking about it for the last 10 minutes.</p>
<p>Hypothesis: Run a simple test to find out the answer.</p>
<p>Hypothesis: “Confused” = don’t know the output of some branch.</p>
<h2 id="infer-based-on-the-variables-we-focus-on">Infer based on the Variables we Focus on</h2>
<p><strong>Hypothesis</strong>: Which conclusion we come to &lt;- the variables we focus on.</p>
<p>Just focus on one variable, like how awesome romantic life is - feel like a life without romance is worthless. Focus on money and flashy cars and the other stuff rappers rap about - feel like a life without that is a waste.</p>
<p>Focus on more variables - get a more nuanced view. For example, celebrities may get way more compliments than you or me, but they also get a ton more hate. They get judged every single day for things they didn’t or even couldn’t do perfectly.</p>
<p>However, focus on too many variables - try to figure out a building’s architecture in one go (for a novice like me) - fail. Ditto for “complex” do-calculus problems - too much information for me to use.</p>
<p><strong>Hypothesis</strong>: Confusion (one cause) &lt;- focusing on too many variables.</p>
<p><strong>Observation</strong>: I didn’t even know the type signature of “graphical condition” or “definition for surrogate endpoints” (when starting out on my surrogate endpoints project).</p>
<p>So, I took the wrong thing to be a valid “definition for surrogate endpoints” and found out a week later that it wasn’t actually valid.</p>
<p><strong>Hypothesis</strong>: No type signature, lots of variables -&gt; focus on too many variables.</p>
<p>No type signature, some other variables -&gt; accept the wrong answer.</p>
<p>Type signatures -&gt; may not know the answer, but won’t focus on the wrong variables.</p>
<h2 id="ignore-some-variables">Ignore Some Variables</h2>
<p><strong>Corollary</strong>: If you get convinced that all the variables you see are important, you will try to take all of them into account. And because you don’t have any high-level rule that covers a dozen variables at once, you will get “confused”. You won’t know which technique to use.</p>
<p>You could have done much better if you focused on just a few variables you “understood” (i.e., for whose configuration you knew how to respond).</p>
<p>Lesson: Sometimes, it’s best to reduce the number of variables you focus on. (When?)</p>
<h2 id="case-study-edge-of-tomorrow">Case Study: Edge of Tomorrow</h2>
<p>Observation: Cage drops into the battlefield. No clue what to do. There are missiles flying every way, people fighting here and there, aircrafts exploding above. What to do for this input configuration? Turn left or right? Run or walk? Or just lay low? Massively confused.</p>
<p>Observation: He doesn’t know which events to pay attention to. He keeps looking around.</p>
<p>Hypothesis: Doesn’t know which inputs are relevant for the techniques he has.</p>
<p>For example, he can’t do anything about the aircrafts exploding miles away. So, ignore them. Ditto for the people already dead - no technique will bring them back. So, ignore them too. His gun can shoot only things that are nearby - so, focus only on targets that are nearby.</p>
<p>Observation: Guy spasming in his exo-suit. Cage gawks.</p>
<p>Observation: Hmm… A big part of being confused seems to be about wasting time on useless parts of the input.</p>
<p>Hypothesis: Given the techniques you have, you need to ignore all the parts of the inputs that are irrelevant. Otherwise, you will be overwhelmed because you have nothing stored in your mind for that exact “complex” configuration.</p>
<p>For example, Cage (along with us as the viewers) is overwhelmed by the fact that there are dozens of aircrafts hovering above doing crazy shit, missiles flying everywhere, and so on. We have no clear rule for what to do in this situation. But once you realize that all you can do with your weapons is shoot things that are nearby, you will ignore all of these factors and focus on any mimics who are close. You know how to respond to <em>that</em> situation: see mimic, shoot it.</p>
<p><strong>Hypothesis</strong>: If you have a bunch of clear high-level techniques but you focus on too many irrelevant variables, you will feel like you don’t know which technique you need for that configuration. You will be “confused”.</p>
<p>Lesson: Ignore irrelevant variables. Basically don’t waste time on useless things, like Cage gawking at the spasming soldier. Take your mind off those things.</p>
<p><strong>Lesson</strong>: Don’t pay attention to anything that is irrelevant to your target and weapons.</p>
<p>For example, don’t pay attention to the missile that just took out the guy next to you (apart from remembering to duck and walk in zigzag patterns or whatever). Don’t pay attention to the guy on fire - can’t do anything about it; will only confuse you. Don’t pay attention to the aircraft on fire (past ensuring that it’s not going to fall on you).</p>
<p>Observation: Gun - some error message in Japanese - don’t know what to do for this configuration (in order to get his safety off).</p>
<p>Hypothesis: What options does he have? He could press some combination of the buttons on the gun. One of them must turn the safety off. It is probably not some “complex” procedure because people have to do it quite often. Focusing on the fact that it is in Japanese and that you don’t know the language and that you’re screwed and so on is unhelpful.</p>
<p>Observation: Crashing aircraft. He came up with the correct response - running and jumping into a ditch.</p>
<p><strong>Observation</strong>: Swordsmen are famous for having their attention completely on their opponent. They don’t waste attention on worrying about what others think of them (because their weapon can’t help them do anything about that).</p>
<p>Observation: The only weapon he had left was the explosive. What is the only thing he could do with it? Detonate it when the enemy got close. He did that. Every other detail was irrelevant.</p>
<p>Observation: He wakes up after dying. Confused. Doesn’t know what to do for such an input configuration. What can he do? Live life again, become stronger, and hopefully kill some more mimics. The rest is kind of irrelevant. (Though he should figure out how he was awoken.)</p>
<p>Observation: Rita dies after killing the first mimic; the second time around, he’s coming up with a better technique for the same situation. (The theme of the whole movie.)</p>
<p>Question: Given a particular situation and target, how do you improve your technique?</p>
<p>Hypothesis: Use the scientific method with the input as the situation plus your technique, and the output as the outcome of your actions.</p>
<p>Notice how different variations of your technique lead to different outcomes and infer a model of which technique configurations lead to good outputs.</p>
<p><strong>Hypothesis</strong>: Basically, use the outputs to categorize your technique configurations.</p>
<p>For example, if trying to convince the Sergeant gets you nowhere, stop doing that. Eliminate that variable from your technique configuration space.</p>
<p>Hypothesis: For each input configuration, choose the high-level technique that gets you the best outcome. Categorize inputs this way.</p>
<p>Observation: He jumped off right away. He knew that other techniques would get bad results. Landed on his feet too. He’s running with a purpose now. He knows what to do for the current input.</p>
<p>Observation: Got hit by the jeep once. Not again.</p>
<h2 id="relevant-variables-only-but-still-confused">Relevant Variables Only but Still Confused?</h2>
<p>For example, I didn’t know whether to use <code>G_-X_Z-</code> or <code>G_X-_Z-</code> for rule 2 of do-calculus.</p>
<p>Hypothesis: I knew that I needed to use rule 2 in that situation, but I was confused about the <em>definition</em>.</p>
<p>Hypothesis: This is just confusion at one level down. For the input “use rule 2”, I didn’t know the correct output.</p>
<p>Instead of being confused about the high-level technique to use, I was confused about a lower-level technique within it.</p>
<h2 id="what-if-you-have-a-lot-of-low-level-techniques">What if You have a Lot of Low-level Techniques?</h2>
<p>For example, the gun had some error message in Japanese. How could Cage go about testing the different combinations of buttons on the gun to turn the safety off?</p>
<h2 id="what-if-you-have-no-techniques">What if You Have No Techniques?</h2>
<p>Question: What if you don’t have any high-level techniques?</p>
<p>For example, if you asked me to fix a broken car engine, I would have no clue what to do. There too, I would be “confused”.</p>
<h2 id="im-confused-vs-im-confused-about-x">“I’m confused” vs “I’m confused about X”</h2>
<p>Test: EB - told him I was confused about the linear programming part of ACE. He refused to back down until I specified exactly <strong>which line</strong> I didn’t understand. And when he did write it out, it was obvious!</p>
<h1 id="novice-go-slow">Novice: Go Slow</h1>
<p>Observation: Felt a lot more in control when I applied each do-calculus rule deliberately. Basically wrote out the entire condition for the rule so that I wasn’t caught by edge cases.</p>
<h1 id="unit-tests-are-better-than-blind-integration-tests">Unit Tests are better than Blind Integration Tests</h1>
<p>Observation: For HW2 in SML, I went with a benchmark of tests, where I understood neither the input nor the output data.</p>
<p>Observation: I can understand a single concrete test better.</p>
<p><strong>Hypothesis</strong>: Go for well-understood simple unit tests over blind integration tests -&gt; actually feel confident about your code vs don’t know why it works or even what it’s supposed to do.</p>
<h1 id="classified-information-everything-should-flow">Classified Information: Everything Should Flow</h1>
<p>Hypothesis: Aim of information-storage: Collect all your data into the same flow. A model must either be an alternative to or an extension of another model.</p>
<p>Corollary: You shouldn’t have information that’s just lying around. It should fit within your overall model.</p>
<h2 id="detect-redundant-models-using-concrete-examples">Detect Redundant Models using Concrete Examples</h2>
<p>We don’t want to store more than one hypothesis for the same problem type. Then, we would get confused about which one to use. Hypotheses must either be alternatives to each other (with well-defined unique inputs) or extensions (where you use one after the other).</p>
<p>Question: How to detect whether you already have a hypothesis for a given problem?</p>
<p><strong>Hypothesis</strong>: Use a concrete example vs use some name for the model -&gt; recall your existing model for that example vs may not remember existing models you have for the same problem.</p>
<p>For example, “confusion” and “being overwhelmed” and “seems chaotic” and so on refer to the same problem - not knowing which output to produce for a given input. Things become clearer when I give the example of a battle field (like in Edge of Tomorrow). All the above labels would apply, which makes me understand that I have more than one model for the same situation and I must mark them as equivalent (at least for this problem).</p>
<p>Corollary: Using lower-level concepts will do just as well.</p>
<p>For example, “boundaries” and “personal space” and “personal rights” all boil down to the economic concept of “property rights” - stuff that you control.</p>
<h1 id="static-types-help-you-abstract">Static Types help you Abstract</h1>
<p>Observation: Writing a Python function to flatten a YAML dictionary that had two redundant nested lists of dictionaries. Was going to write some hopelessly ad hoc function to deal with “innings” and “deliveries” (since those were the keys that had the nested lists).</p>
<p>Then realized that I should just write one generic function to flatten a list of dictionaries, and use that on innings and deliveries separately.</p>
<p>Would have been a no-brainer in Haskell. The type would have made it obvious (I think).</p>
<p>Hypothesis: Static types (a la Haskell) help you abstract, whereas dynamic types make it hard to see the patterns.</p>
<p>(Feels overly-general.)</p>
<h1 id="pass-a-test-with-a-chain-of-function-calls">Pass a Test with a Chain of Function Calls</h1>
<p><strong>Inference</strong>: A test will run only one branch. So, no if-statements needed. Probably just a chain of function calls.</p>
<p><strong>Hypothesis</strong>: To pass a well-designed test, you will need only a chain of function calls.</p>
<h2 id="one-test-per-function-in-the-chain">One Test per Function in the Chain?</h2>
<p><strong>Question</strong>: How many tests for a function with no if-statements but a chain of function calls?</p>
<p><strong>Hypothesis</strong>: When you have a chain f . g . h, you will need to show why you need each individual function (and if possible, each combination).</p>
<p>Test: In <code>website-join-disjointed-paragraphs</code>, I have</p>
<pre class="elisp"><code>(my-map-paragraphs-in-buffer
   (-compose (-partial 's-join &quot; &quot;)
	     (-partial '-filter 's-present?)
	     's-lines))</code></pre>
<p>I was puzzled. Why do I need that function in the middle: <code>(-partial '-filter 's-present?)</code>? I can see that <code>s-lines</code> turns a string with disjointed lines into a list of lines and that <code>s-join</code> joins them into one paragraph. When will you possibly need to filter with <code>s-present?</code>?</p>
<p>I looked at my unit test for that function (I had just one) and couldn’t see why you needed that <code>s-present?</code> function. In fact, that test passed even without the middle function. However, another test, one that tested this function on a real-world input failed. Only then did I realize that that function was there to handle a trailing newline, which all my files have.</p>
<p>I tested that theory by adding a smaller, specific test with a trailing newline and saw that toggling <code>s-present?</code> made that test pass or fail.</p>
<p>Basically, I needed to show that my function definition needed that middle function in order to pass some test.</p>
<h2 id="compose-properties-of-functions">Compose Properties of Functions</h2>
<p>It feels like that when we compose functions, we compose their properties to get the overall property.</p>
<p>Test:</p>
<pre class="elisp"><code>(defun s-join-broken-paragraph (s)
  &quot;Join broken lines in paragraph string S.&quot;
  (funcall (-compose (-partial 's-join &quot; &quot;)
	     (-partial '-filter 's-present?)
	     's-lines)
	   s))</code></pre>
<p>We know that <code>s-lines</code> will break a string into lines, <code>filter s-present?</code> will keep only those lines that are not empty, and that <code>s-join &quot; &quot;</code> will join those lines with a space in between. So, does that sum up to “join broken lines in paragraph string”?</p>
<p>Note that a big assumption is that there is only one paragraph with broken lines. If the input looks like:</p>
<pre><code>This is
the first
paragraph. Phew.

This is actually the second
paragraph. Uh oh.</code></pre>
<p>the output is:</p>
<pre><code>This is the first paragraph. Phew. This is actually the second paragraph. Uh oh.</code></pre>
<p>which is not what I want.</p>
<p>Observation: I’m assuming that a “paragraph” is some “complex” thing with lots of possible cases that I will have to handle.</p>
<p>But if we assume that one broken paragraph is just a bunch of lines with none of them separated by a blank line, then our job becomes a lot easier.</p>
<p>If we assume that a broken paragraph is a bunch of lines, then s-lines will get us all of those lines. Right now, the <code>filter s-present?</code> is just there to handle a trailing newline, so let’s ignore it. The <code>s-join &quot; &quot;</code> takes the lines and creates a string out of them.</p>
<p><strong>Hypothesis</strong>: To handle all possible configurations of some variable:</p>
<p>unpack it, do something to each part, combine them -&gt; “handle” that variable.</p>
<h2 id="succinct-properties">Succinct Properties?</h2>
<p>Test:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="dt">Prelude</span> <span class="dt">Data.Map</span><span class="fu">&gt;</span> <span class="kw">let</span> d <span class="fu">=</span> fromList <span class="fu">$</span> zip [<span class="dv">1</span><span class="fu">..</span>] [<span class="ch">'a'</span><span class="fu">..</span><span class="ch">'z'</span>]
fromList [(<span class="dv">1</span>,<span class="ch">'a'</span>),(<span class="dv">2</span>,<span class="ch">'b'</span>),(<span class="dv">3</span>,<span class="ch">'c'</span>),(<span class="dv">4</span>,<span class="ch">'d'</span>),(<span class="dv">5</span>,<span class="ch">'e'</span>),(<span class="dv">6</span>,<span class="ch">'f'</span>),(<span class="dv">7</span>,<span class="ch">'g'</span>),(<span class="dv">8</span>,<span class="ch">'h'</span>),(<span class="dv">9</span>,<span class="ch">'i'</span>),(<span class="dv">10</span>,<span class="ch">'j'</span>),(<span class="dv">11</span>,<span class="ch">'k'</span>),(<span class="dv">12</span>,<span class="ch">'l'</span>),(<span class="dv">13</span>,<span class="ch">'m'</span>),(<span class="dv">14</span>,<span class="ch">'n'</span>),(<span class="dv">15</span>,<span class="ch">'o'</span>),(<span class="dv">16</span>,<span class="ch">'p'</span>),(<span class="dv">17</span>,<span class="ch">'q'</span>),(<span class="dv">18</span>,<span class="ch">'r'</span>),(<span class="dv">19</span>,<span class="ch">'s'</span>),(<span class="dv">20</span>,<span class="ch">'t'</span>),(<span class="dv">21</span>,<span class="ch">'u'</span>),(<span class="dv">22</span>,<span class="ch">'v'</span>),(<span class="dv">23</span>,<span class="ch">'w'</span>),(<span class="dv">24</span>,<span class="ch">'x'</span>),(<span class="dv">25</span>,<span class="ch">'y'</span>),(<span class="dv">26</span>,<span class="ch">'z'</span>)]
<span class="dt">Prelude</span> <span class="dt">Data.Map</span><span class="fu">&gt;</span> <span class="kw">let</span> d2 <span class="fu">=</span> fromList <span class="fu">.</span> map Data.Tuple.swap <span class="fu">.</span> toList <span class="fu">$</span> d
fromList [(<span class="ch">'a'</span>,<span class="dv">1</span>),(<span class="ch">'b'</span>,<span class="dv">2</span>),(<span class="ch">'c'</span>,<span class="dv">3</span>),(<span class="ch">'d'</span>,<span class="dv">4</span>),(<span class="ch">'e'</span>,<span class="dv">5</span>),(<span class="ch">'f'</span>,<span class="dv">6</span>),(<span class="ch">'g'</span>,<span class="dv">7</span>),(<span class="ch">'h'</span>,<span class="dv">8</span>),(<span class="ch">'i'</span>,<span class="dv">9</span>),(<span class="ch">'j'</span>,<span class="dv">10</span>),(<span class="ch">'k'</span>,<span class="dv">11</span>),(<span class="ch">'l'</span>,<span class="dv">12</span>),(<span class="ch">'m'</span>,<span class="dv">13</span>),(<span class="ch">'n'</span>,<span class="dv">14</span>),(<span class="ch">'o'</span>,<span class="dv">15</span>),(<span class="ch">'p'</span>,<span class="dv">16</span>),(<span class="ch">'q'</span>,<span class="dv">17</span>),(<span class="ch">'r'</span>,<span class="dv">18</span>),(<span class="ch">'s'</span>,<span class="dv">19</span>),(<span class="ch">'t'</span>,<span class="dv">20</span>),(<span class="ch">'u'</span>,<span class="dv">21</span>),(<span class="ch">'v'</span>,<span class="dv">22</span>),(<span class="ch">'w'</span>,<span class="dv">23</span>),(<span class="ch">'x'</span>,<span class="dv">24</span>),(<span class="ch">'y'</span>,<span class="dv">25</span>),(<span class="ch">'z'</span>,<span class="dv">26</span>)]</code></pre></div>
<p>We can see that <code>toList</code> will get us a list of all the key-value pairs, <code>map swap</code> will make them value-key pairs, and <code>fromList</code> will construct a new map from them.</p>
<p>Of course, one edge case is when there is more than one key with the same value. Which one will be lost? The one that comes earlier in the key ordering.</p>
<p>These two function chains were easy enough. When might function chains be hard to reason about?</p>
<p>You could have a really long function chain or you could have lots of possible variations.</p>
<p>For example,</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="dt">Prelude</span> <span class="dt">Data.List</span><span class="fu">&gt;</span> <span class="kw">let</span> xs <span class="fu">=</span> [<span class="dv">1</span><span class="fu">..</span><span class="dv">10</span>]
<span class="dt">Prelude</span> <span class="dt">Data.List</span><span class="fu">&gt;</span> take <span class="dv">3</span> <span class="fu">.</span> reverse <span class="fu">.</span> sort <span class="fu">.</span> nub <span class="fu">.</span> take <span class="dv">20</span> <span class="fu">.</span> sort <span class="fu">.</span> take <span class="dv">30</span> <span class="fu">.</span> cycle <span class="fu">$</span> xs
[<span class="dv">7</span>,<span class="dv">6</span>,<span class="dv">5</span>]</code></pre></div>
<p>Why is the output [7, 6, 5]? I don’t really know. But I can sort of follow the chain.</p>
<p>Aren’t there all kinds of possible configurations? I don’t think so. It’s a list, so there are two cases - the empty list and the non-empty list. If xs is empty, the output at every point along the chain will be empty. So, that’s a trivial case.</p>
<p>Now, you just have to take a non-empty list. Shouldn’t you have to consider a lot of possible lists, maybe those that have just one element or five elements?</p>
<p>Observation: You can’t make any sort of closed-function claim about the output list. You will say that it will have the output that is dictated by the chain.</p>
<p>Observation: In the key-value swapping example before, I could claim succinctly that the final map would have key-value pairs but in the opposite order.</p>
<p><strong>Hypothesis</strong>: Some function chains lend themselves to succinct properties, some don’t. (How falsifiable!)</p>
<p>Observation: The long chain above, if encapsulated as a function, would have a very large <em>interface</em>. You couldn’t do better than just describing the chain itself.</p>
<p>Observation: When you <code>mappend</code> two strings, what you get back is still a string.</p>
<p>Question: Out of all the possible implementations of Monoid or Functor or Monad, why do we choose particular ones?</p>
<p>Test: What does it mean when you compose two Parsers? What properties are you composing?</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">abParser ::</span> <span class="dt">Parser</span> (<span class="dt">Char</span>, <span class="dt">Char</span>)
abParser <span class="fu">=</span> (,) <span class="fu">&lt;$&gt;</span> char <span class="ch">'a'</span> <span class="fu">&lt;*&gt;</span> char <span class="ch">'b'</span></code></pre></div>
<h2 id="properties-of-intermediate-values">Properties of Intermediate Values</h2>
<p>Test: Poorly-written abstract function that I found hard to understand (part of a Sudoku solver I wrote):</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">boxes3x3' ::</span> <span class="dt">Eq</span> b <span class="ot">=&gt;</span> <span class="dt">Matrix</span> b <span class="ot">-&gt;</span> <span class="dt">Matrix</span> [b]
boxes3x3' <span class="fu">=</span> fmap concat <span class="fu">.</span> overMatrix (concatMap (replicate <span class="dv">3</span> <span class="fu">.</span> concatMap (replicate <span class="dv">3</span>)) <span class="fu">.</span> map ( transpose <span class="fu">.</span> map byThrees) <span class="fu">.</span> byThrees)</code></pre></div>
<p>What now?</p>
<p>Note, however, that the interface of the function is actually pretty simple. It needs to take a Sudoku matrix where each cell contains a list of its possible values and return a matrix where each cell contains the possibilities for all the cells in its 3x3 box. (A test case would have helped greatly.)</p>
<p>Hypothesis: You need to understand the properties of the data structure at each point in the function chain.</p>
<p>Ok. I understood the function. <code>overMatrix</code> lets you map over the rows in the Matrix. <code>byThrees</code> gets you three rows at a time. Then, consider <code>transpose . map byThrees</code> on the first three rows. <code>map byThrees</code> gets you the three column values at a time for each row. <code>transpose</code> on that for the first three rows gives you the first three 3x3 boxes in the Sudoku matrix. Basically, at this point, you’ve got a 3x3 matrix of boxes. You want to give the same box to all the 9 cells in each box, so <code>concatMap (replicate 3 . concatMap (replicate 3))</code> turns the 3x3 matrix of boxes into a 9x9 matrix of boxes, where each cell has the 3x3 box that it resides in. <code>fmap concat</code> flattens each 3x3 box to give a 9-element list of its elements.</p>
<p>Observation: We can break this into three parts: the first part where you get a 3x3 matrix of boxes, the second part where you get a 9x9 matrix of boxes, and the final part where you get a 9x9 matrix of lists.</p>
<p><strong>Hypothesis</strong>: Chain - get the data type at each point and ask for its properties with respect to your goal.</p>
<p>Question: How many tests would you need to be confident in your implementation of each part? How do you know that your code really will get a 3x3 matrix of the 9 boxes in the Sudoku matrix?</p>
<p>Well, the input numbers don’t really matter. So, that reduces a lot of possible input configurations.</p>
<p><strong>Question</strong>: For any given input matrix, should we test for the entire output or can we just test a few cells?</p>
<h2 id="verify-properties-using-quickcheck">Verify Properties using QuickCheck</h2>
<p><strong>Hypothesis</strong>: Function - verify its properties using QuickCheck.</p>
<p>Test: boxes3x3’ must return a 3x3 matrix of boxes corresponding to the input Sudoku matrix – we can use QuickCheck to verify that.</p>
<h2 id="how-many-tests-for-a-chain-of-functions">How Many Tests for a Chain of Functions?</h2>
<p><strong>Question</strong>: How many tests do I need to for a chain of functions?</p>
<p>Just one? No matter what the functions are? Seriously?</p>
<p>Hypothesis: I want to know the causes of #tests for chain of functions. What are the variables? Number of functions in the chain, whether it’s about the limits of my mind vs the actual uncertainty I have about the code, the number of branches of each function, and the size of their interfaces.</p>
<h1 id="searching-within-the-program-space">Searching within the Program Space</h1>
<h2 id="code-transformation-fail-to-fail-gives-no-information">Code Transformation: Fail to Fail gives No Information</h2>
<p><strong>Hypothesis</strong>: Going from fail to fail doesn’t give you any information about your latest change.</p>
<p>old code -&gt; fail (so we know it’s broken)</p>
<p>old code broken + correct change -&gt; fail old code broken + wrong change -&gt; fail</p>
<p>Going from fail to pass tells you that your latest change is correct.</p>
<p>Going from pass to pass tells you that your latest change is correct. This is true if you changed the code, but not necessarily if you added new code (you may have forgotten to test it).</p>
<p>Going from pass to fail tells you that your latest change is wrong.</p>
<h2 id="why-is-writing-abstract-code-time-consuming">Why is writing Abstract Code time-consuming?</h2>
<p>Question: What is the exact difference in coding time between passing the test and then refactoring vs passing the test with clean code?</p>
<p><strong>Hypothesis</strong>: Pass the test with ugly code -&gt; 1 test (though you may sometimes test different parts of the chain too). Refactor the ugly code that <em>works</em> -&gt; m tests (one for each abstraction like function or class).</p>
<p>You would go from no code to code that works. 1 test. Then, you would go from code that works to code that works plus one abstraction. Then, you would go again from code that works to code that works plus abstraction. And so on till you’re satisfied. m tests.</p>
<p>Pass the test with clean code -&gt; suppose you add m abstractions and the test fails. You will need to toggle many of those abstractions (which will take time) before you isolate the bug.</p>
<p>You would go from no code to code that doesn’t work plus abstraction. Then, from code that doesn’t work to code that doesn’t plus abstraction. And so on.</p>
<p>Even if you ran a test at each point, you wouldn’t know if it doesn’t work because the current abstraction is broken or because the prior abstractions are.</p>
<p>Corollary: This whole problem would be solved if you could add abstractions like you add code. Then, you could unit test each change and romp ahead.</p>
<h2 id="why-is-debugging-so-hard">Why is Debugging so Hard?</h2>
<p>Observation: Debugging seems to be pretty hard and time-consuming. Lot more confusing and frustrating than normal coding.</p>
<p>For example, 17 out of the 30 hours I spent on OS HW2 were lost in debugging.</p>
<p>Why? Is debugging a different operation from normal coding?</p>
<h2 id="a-model-of-programming">A Model of Programming</h2>
<p>Observation: Consider a case where you have a multi-variable configuration space like (A2, B5, C1) -&gt; pass; (A1, B8, C5) -&gt; fail; etc. We will call each configuration a “program”.</p>
<p>You have different “features” that will let you change the program from one configuration to another. For example, “sort the output list” could correspond to going from B5 to B6 and thus take your program (A2, B5, C1) to (A2, B6, C1).</p>
<p>However, you are not a perfect programmer, so you could make a mistake while implementing the first feature and end up at some other value than B6.</p>
<p>Basically, you can’t tell if you are at B6. You have to infer from the result of your test case that checks for a sorted output list. It will go from “fail” for B5 to “pass” for B6 and thus tell you that you implemented the feature correctly.</p>
<p>Let’s say C1 is a function to compute the mean-squared error for two vectors. It does all that in one function. C3 is a function that does the same thing but has a “cleaner design” than C1: it calculates the error vector first and then calls <code>meansqr</code> for it. So, it requires two additional features on top of C1 - separate functions for <code>error</code> and <code>meansqr</code>. So, you have to go from C1 to C2 (i.e., C1 + <code>error</code>) and then from C2 to C3 (C1 + <code>error</code> + <code>meansqr</code>).</p>
<p>Now, the clean way to get to C3 would be to extract <code>error</code> in C1 and run a test to see if you really are at C2 (which would be the same test for C1 because C1 and C2 behave identically). Then, extract <code>meansqr</code> and run a test to see if you really are at C3 (which is the same test as for C1 or C2 as they all behave identically). Even if you made a mistake while extracting <code>error</code>, you would know that the error (heh) would be in your latest change, not anywhere else in the code. Simple. No frustration.</p>
<p>What if you extracted <code>error</code> and <code>meansqr</code> in one shot? Well, if your implementation of C3 passed the test, then you could be pretty confident that you did it right.</p>
<p>But what if the test for C3 fails? Now, you don’t know if the problem is in your extraction of <code>error</code> or in your extraction of <code>meansqr</code>.</p>
<p>How would you handle this? The best way would be to go back to the inline version of <code>meansqr</code> and check if the test passed then. If so, the problem is in your extraction of <code>meansqr</code> and you can run finer tests.</p>
<p>Assume that you didn’t have to write new code manually or press undo in your editor repeatedly till you got back to C2 and ran your test. What if you could jump from C1 to C2 or from C2 to C1 in a flash? Basically, what if you could toggle any implemented feature instantaneously?</p>
<p>Well, if your original code passed the test for C1 but your implementation of features <code>error</code> and <code>meansqr</code> failed the test, you could tell that the problem must have been somewhere in the implementation of the two features. Then, you could just toggle <code>meansqr</code> and see if that code passed the test. Say it doesn’t. So, there must be a problem with <code>error</code> (there may also be a problem with <code>meansqr</code>; we don’t know). We then toggle features within <code>error</code> to check which one broke our code until we pinpoint the culprit.</p>
<p>In the worst case, you need two tests - one to check <code>error</code> and one to check <code>meansqr</code>, which is the same number of tests as in normal coding where you test after every feature.</p>
<h2 id="debugging-is-hard-when-you-cant-toggle-easily">Debugging is Hard when you Can’t Toggle Easily</h2>
<p>Observation: Some state transitions are costlier in the reverse direction.</p>
<p><strong>Hypothesis</strong>: Debugging is hard when you can’t toggle the state space easily.</p>
<p>You can figure out the right configuration effortlessly if you can walk through state configurations in an instant. (In fact, you can even automate it.)</p>
<h2 id="hard-to-toggle-abstractions">Hard to Toggle Abstractions</h2>
<p><strong>Hypothesis</strong>: It’s easy to toggle tests.</p>
<p>I did it effortlessly with my <code>pipe</code> tests.</p>
<p><strong>Hypothesis</strong>: It’s hard to toggle abstractions.</p>
<p>Except for the last few edits or so, our editors don’t allow us to roll back abstractions. It’s a pain even if you use it.</p>
<p><strong>Hypothesis</strong>: Abstractions are usually set in stone.</p>
<p>Once you add an abstraction (like a class or function), it’s so hard to get back the original code that you stick with the abstraction.</p>
<p>But you don’t know if your abstraction itself was correct. So, you’re now uncertain about both your abstraction and your code’s behaviour.</p>
<p><strong>Hypothesis</strong>: Hard to decide whether or not to go for an abstraction unless you know the potential use cases.</p>
<p><strong>Corollary</strong>: You will dilly-dally. You won’t spend your time coding; you will spend it pondering.</p>
<h2 id="one-thing-at-a-time-abstract-while-coding---more-uncertain">One Thing at a Time: Abstract while Coding -&gt; More Uncertain</h2>
<p>For example, when testing a class in Python, I wrote the code to generate test data in the <code>setUp</code> method. But that meant that code was regenerated for test case, which was wasteful. So, I decided to move it to the class constructor. But that failed because the TestCase constructor expected two inputs (I think. I’m not sure. That’s the point). Which ones? I don’t know. So, I looked online for more details. People recommended that I use a <code>setUpClass</code> method. But that was a “class method”. I wasn’t sure what that was - a static method like in Java or something else. Anyway, I tried using <code>self.foo</code> everywhere and the code failed. Why? Because <code>self</code> wasn’t even visible in the class method (obviously). So, I replaced every instance of <code>self</code> with <code>cls</code> (since that was the name of the argument). Then my code worked.</p>
<p><strong>Hypothesis</strong>: We are more uncertain about abstractions than about normal code.</p>
<p>Corollary: So we are likely to make more mistakes when abstracting than when writing usual functions. That explains my struggle above.</p>
<p>Observation: When calculating the total runs for a player in the first and second innings, I wanted to abstract the loop into a function and call that function on the two parts. Instead, I forced myself to write two duplicate loops (<em>cringe</em>). But the code still failed the test. So, if I had abstracted the loop into a function, I would have been unsure if the problem was because of my abstraction or because of the code itself.</p>
<p><strong>Observation</strong>: Holy crap. Refactoring was a breeze! I could see exactly what I needed to change (extract a Match::balls iterator) and did it without any worries about the behaviour.</p>
<p>Observation: Again, when trying to aggregate stats from 70 matches, I’m trying to look for the ideal solution where I pickle the YAML object for future use and so on. Instead, I should just run it in a quick and dirty way, no matter what the cost.</p>
<p>Observation: Lost my way after a while and reverted to my old over-engineering habits.</p>
<h2 id="default-values-for-abstractions">Default Values for Abstractions</h2>
<p><strong>Hypothesis</strong>: Have default values for abstractions -&gt; can add an abstraction without making mistakes and without changing behaviour vs have to add an abstraction (perhaps making mistakes) and change behaviour too.</p>
<p>Observation: Still hard to reverse an abstraction.</p>
<h2 id="moving-forward-is-easier-than-debugging-backward">Moving Forward is easier than Debugging Backward</h2>
<p><strong>Lesson</strong>: Adding features and releasing at each point -&gt; quick and painless. Adding lots of features and then debugging -&gt; slow and painful (because you can’t toggle features easily).</p>
<h1 id="premature-abstraction-considered-harmful">Premature Abstraction Considered Harmful</h1>
<p>Observation: I’m struggling to get actual stats from the IPL match data even though it’s a pretty simple map of a simple function over each ball in the data.</p>
<p>Observation: I’m trying to get a “good” (aka perfect) design of Match and Ball and Player and PlayerStats. Even though all I really want is the average and total runs for each player.</p>
<p>Observation: Quick and dirty way of doing it - total runs = map over deliveries in both innings and if batsman is the given batsman, add runs scored by batsman.</p>
<p>Observation: How <em>I</em> want to do it - <code>match.get_player_stats()</code> with different seasons and so on.</p>
<p>Hypothesis: Focus on passing the test in an ugly way, then refactor -&gt; fast code + clean; focus on writing clean code -&gt; may waste time worrying about “good” design.</p>
<p>Hypothesis: Focus on passing the test in an ugly way -&gt; have code that actually <em>works</em> for some input, goddamit. Focus on writing clean code -&gt; may have code that doesn’t work for any useful input yet even after an hour of thinking.</p>
<p>Why would it be a net win to write ugly code and then refactor, rather than write clean code the first time around?</p>
<p>Hypothesis: Code that works, refactor it -&gt; you’re changing only one thing at a time (design, not behaviour) -&gt; very little time, can choose how clean you want your design to be wrt expected inputs.</p>
<p>Code that doesn’t work, write clean code -&gt; you’re changing two things at the same time (design <em>and</em> behaviour) -&gt; will take longer (?), may overengineer.</p>
<p>Observation: You don’t want to write lots of code without stopping to test. You will get very confused if you get an error. (?)</p>
<p>Hypothesis: Chain of functions that we understand -&gt; won’t take much time (why?). Branches of functions -&gt; will take time (why?).</p>
<p>Corollary: So, writing “ugly”, concrete code to pass a unit test won’t take too much time.</p>
<p>Observation: What about abstract code that still just passes one test case? For example, <code>Match:get_balls()</code> and <code>Match:map_over_balls()</code> and <code>runs_for_ball()</code>.</p>
<p>Observation: The abstraction <code>Match:get_balls()</code> may or may not work. You may have made a mistake in defining the method or in the module scope (if Match is in another file) or whatever. Source of uncertainty - have to test it.</p>
<p>Observation: You have multiple design choices - different levels of abstraction. For example, you could deal with separate methods for <code>get_balls()</code> and <code>map_over_balls()</code>, but not a separate class for <code>PlayerStats</code>. Or you could go the whole way and have subclasses for BowlerStats and BatsmanStats (and of course FielderStats) and have, god forbid, visitor methods to do complicated processing. But, for my problem of extracting data for machine learning, that is simply overkill.</p>
<p>Observation: Each time you add a new abstraction, you have to test it (since you may or may not have implemented the abstraction correctly, or may have even picked one that doesn’t fit your problem).</p>
<h2 id="rule-of-three">Rule of Three</h2>
<p><strong>Question</strong>: What if you abstracted code only on the second use?</p>
<p>Maybe go for the Rule of Three? (https://blog.codinghorror.com/rule-of-three/)</p>
<p>What’s the worst that can happen if you <em>don’t</em> abstract your code?</p>
<p><strong>Inference</strong>: Unabstracted code is hard to understand and hard to change too. It’s not just about reuse.</p>
<p>I don’t know the answer.</p>
<h2 id="quick-and-dirty-vs-clean-why-i-procrastinate">Quick-and-Dirty vs Clean: Why I Procrastinate</h2>
<p>Observation: I had the idea that mock objects were actually unnecessary if you strictly separated pure code from impure code, like in Haskell or other languages. That’s why you didn’t see Haskellers go ga-ga over mocks. (In fact, you don’t see anybody except Agile fellows.)</p>
<p>But then I got caught up in writing some elisp code (which took over two hours). Then I felt like searching online for some precision teaching books. And finally I was late for a video call. So I didn’t write down my full ideas about mock objects and didn’t commit that code. And it weighed on my mind even as I was freshening up.</p>
<p>Question: Why didn’t I simply jot down the rough idea as I did above? It would have taken me a couple of minutes, tops. It may not have been perfect, but I could commit the change and free my mind.</p>
<p><strong>Hypothesis</strong>: Expect to write correct abstract code before I commit, have some idea I need to write down, little time -&gt; don’t write it down at all.</p>
<p>Expect to just pass the test with a quick and dirty hypothesis (and maybe refactor later), have some idea, little time -&gt; write it down well enough to pass that specific test.</p>
<p>Corollary: Expect to have code that passes all tests written down (and put only as much confidence in your hypothesis as the tests warrant) -&gt; can do what needs to be done faster.</p>
<p>Test: Jotting down my mock objects idea – I wanted to get a general hypothesis that fit with all my other “complex” programming ideas.</p>
<h1 id="deliberate-execution-of-hypothesis">Deliberate Execution of Hypothesis</h1>
<p>Test your explicit hypothesis at each step by asking it what to do. If it’s blank, fill it in with your intuitive next step. For example, use your “one-button change” hypothesis to write your course programs.</p>
<p><strong>Hypothesis</strong>: Live life “deliberately” -&gt; get an explicit hypothesis about a lot of things you do.</p>
<p>For example, should you watch a YouTube video now? What is the expected outcome? What else could you be doing? Read a book? Ok. Let’s say that’s what you need to do right now. Well, does it work to simply tell yourself “I need to read a book now”? Probably not. What does work? What passes the unit test “have read a book for an hour today”?</p>
<h1 id="type-signatures-the-technique">Type Signatures: The Technique</h1>
<p>Question: What problems can be solved only by thinking in terms of type signatures?</p>
<h1 id="refactoring-induction">Refactoring = Induction</h1>
<p>Observation: I got the right answers to the most questions in OS and SML. But I’m not confident about it. I felt like I just rote-learned most of the concepts the night before the exam.</p>
<p>Question: What’s the difference between rote-learning the night before the exam and proper learning over a period of time?</p>
<p>Question: What’s the difference between correct code that’s dirty and correct code that’s clean?</p>
<p>Observation: Refactoring gets you from dirty correct code to clean correct code. The final code is more general - easier to understand and change and reuse.</p>
<p>Hypothesis: The difference is induction.</p>
<p>Hypothesis: I’m confused about my course concepts and about dirty code because I haven’t got succinct general hypotheses from them. I’m still at the concrete level that’s hard to reason about because it’s verbose (and I don’t have a clear input-output relationship).</p>
<h2 id="how-much-work-is-refactoring">How Much Work is Refactoring?</h2>
<p><strong>Hypothesis</strong>: Two different concrete functions or hypotheses -&gt; one function that does both [call this refactoring or induction].</p>
<p>example: merge <code>get_strike_rates</code> and <code>get_averages</code> into a generic <code>get_features</code>.</p>
<p><strong>Question</strong>: How much work is it to refactor (inductively generalize) two functions (hypotheses)?</p>
<p>Hypothesis: First, check where they differ.</p>
<p>If they are nearly identical functions -&gt; just abstract the difference.</p>
<h2 id="tests-1">Tests</h2>
<p>Test: <code>get_strike_rates</code> and <code>get_averages</code> had the same code except for one function call. I could accept a function argument for that call alone.</p>
<h2 id="learning-and-induction">Learning and Induction</h2>
<p><strong>Question</strong>: Is this what I’m doing when I’m reading a new book that talks about a topic I’ve understood before? Am I trying to merge my current theory along with the new theory and evidence in the book to get a unified theory?</p>
<p>For example, if I read a book about the cognitive psychology of learning, I have to figure out how it fits with my existing model of associative memory and exponential decay. That feels like quite a bit of work.</p>
<h1 id="dont-change-a-function.-duplicate-it.">Don’t Change a Function. Duplicate it.</h1>
<p>Hypothesis: Want to change a <code>generate_stats</code> function to return the average instead of strike rate &lt;- make a duplicate function that’s specific for average. You can refactor it later.</p>
<p>Corollary: This way, you can switch between them easily.</p>
<p><strong>Hypothesis</strong>: Function &lt;- input and output types, output properties (i.e., the whole interface)</p>
<p>So, if you want to change the interface of the function (return averages instead of strike rates), even if the type is the same (list of numbers), write a separate function instead.</p>
<p><strong>Corollary</strong>: To avoid dead code, have an if-condition that lets you switch between the alternative functions.</p>
<h1 id="writing-tests">Writing Tests</h1>
<h2 id="granularity-of-tests">Granularity of Tests</h2>
<p><strong>Question</strong>: How do you chose the granularity of the function for which you want to write tests? (Excellent question.)</p>
<h1 id="refactor-before-you-commit">Refactor Before you Commit</h1>
<p>Observation: My <code>generate_stats</code> script is ugly and feels hard to refactor because it takes several minutes to run.</p>
<p>Observation: I didn’t refactor it the first time around when I was trying to just get the code to run. Yes, I want to pass the simple test as soon as possible, but I should refactor after that, so that my technical debt doesn’t pile up.</p>
<p>Hypothesis: Refactor before you commit -&gt; easier to code in the future.</p>
<p>Don’t refactor before you commit -&gt; end up with ugly code that’s hard to reason about.</p>
<h1 id="costly-feedback">Costly Feedback</h1>
<p>Question: How to write code when running tests is costly?</p>
<p>For example, it takes several minutes to test whether my <code>generate_stats</code> script gives the same output as before. So, I hesitate to refactor any part of it, lest I break the code in some way that will cost me a lot to fix (where I’ll have to run the script for several minutes again to make sure I really did fix it).</p>
<p><strong>Hypothesis</strong>: If you’re writing I/O code, separate the pure and impure parts. Now, you can quickly test and thus refactor the pure logic to your heart’s content.</p>
<h1 id="consider-all-possible-configurations">Consider All Possible Configurations</h1>
<p>Observation: Good security professionals seem to consider different possible scenarios.</p>
<p>Hypothesis: Think of contingency plans to most possible scenarios -&gt; high security vs poor security.</p>
<p>Observation: I haven’t considered different possibilities about my career plans. What if I hate my research area after a couple of years? What if I never make a breakthrough in “metacognitive algorithms”? No contingency plans.</p>
<h1 id="program-to-an-interface-not-an-implementation">Program to an Interface, not an Implementation</h1>
<h2 id="program-to-an-interface-hypothesis">Program to an Interface: Hypothesis</h2>
<p>Observation: When extending XINU in C, I wrote a few linked-list manipulation functions. They repeated several well-known functions like extract from linked list and so on. I shouldn’t have had to write them from scratch. But I couldn’t find any existing functions I could reuse (or rather, I didn’t look for them). Plus, it was a “unique” linked list structure - one where the elements were part of a pre-existing table, and were not dynamically generated. Still, there should have been a generic List interface that I could just use without knowing too much about the innards.</p>
<p><strong>Hypothesis</strong>: Program to an interface, not an implementation -&gt; code that is easier to understand, reuse, and modify.</p>
<p>For example, if you want to check if an element is a value in a Map, don’t search the specific functions within Data.Map. Look for the interfaces that it satisfies: Foldable, Traversable, Functor, Monoid, etc.</p>
<p>Test: You’re given <code>Maybe (Int, String)</code> and you want to map the string to its length (“foo” to 3). That is, you want to get <code>Maybe (Int, Int)</code>. <em>Don’t</em> try to unpack Maybe into the two cases Just and Nothing and then try to convert the inner values. Instead, realize that you want to deal with Maybe as a Functor. – easier to understand, easier to reuse (you could use it with any functor of functor), easier to modify (you could change the definition of Maybe).</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">*</span><span class="dt">Main</span> <span class="dt">Data.Map</span><span class="fu">&gt;</span> <span class="kw">let</span> x <span class="fu">=</span> <span class="dt">Just</span> (<span class="dv">3</span>, <span class="st">&quot;foobar&quot;</span>)
<span class="fu">*</span><span class="dt">Main</span> <span class="dt">Data.Map</span><span class="fu">&gt;</span> fmap (fmap length) x
<span class="dt">Just</span> (<span class="dv">3</span>,<span class="dv">6</span>)</code></pre></div>
<p>Compare that to:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">*</span><span class="dt">Main</span> <span class="dt">Data.Map</span><span class="fu">&gt;</span> <span class="kw">let</span> f (<span class="dt">Just</span> (x, s)) <span class="fu">=</span> <span class="dt">Just</span> (x, length s); f <span class="dt">Nothing</span> <span class="fu">=</span> <span class="dt">Nothing</span>
<span class="fu">*</span><span class="dt">Main</span> <span class="dt">Data.Map</span><span class="fu">&gt;</span> f x
<span class="dt">Just</span> (<span class="dv">3</span>,<span class="dv">6</span>)</code></pre></div>
<p>This is a very specific function. You don’t know exactly what it’s doing unless you examine both the branches and realize that neither x nor the Maybe structure is affected, but the string s is turned into its length. It takes a while to realize that the whole point of the function was to turn the string into its length. With <code>fmap (fmap length)</code>, that purpose is front and centre. We know that we don’t care about the other value x or the structure of the Maybe value. Similarly, this is hard to reuse with any other type, such as a list of list of strings, because you have to handle a different type of structure, whereas the interface-version transfers easily:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">*</span><span class="dt">Main</span> <span class="dt">Data.Map</span><span class="fu">&gt;</span> fmap (fmap length) [[<span class="st">&quot;yo&quot;</span>, <span class="st">&quot;boyz&quot;</span>, <span class="st">&quot;I&quot;</span>], [<span class="st">&quot;am&quot;</span>, <span class="st">&quot;sing&quot;</span>, <span class="st">&quot;song&quot;</span>]]
[[<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">1</span>],[<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">4</span>]]</code></pre></div>
<p>Likewise, if you want to do something other than get the length of the string, you know exactly what to change - there are just three words in the function - “fmap”, “fmap”, and “length”. Whereas in the explicit version, you have to search for the precise thing you want to change and be wary of not affecting any of the surrounding code.</p>
<p>Test: You have a XML-like tree of sentences and you want to get all the verbs used in the tree. (Assume you have a function that will extract verbs from a sentence.) – treat the tree as Foldable and use <code>foldmap getVerbs</code>.</p>
<h2 id="minimize-the-number-of-your-weapons">Minimize the Number of your Weapons</h2>
<p>Observation: How do you check whether a value is in a Map? You could do (<code>elem</code> (elems m2)), but that would require you to know the function <code>elems</code>. Instead, you could just do (value <code>elem</code> m2)! Why? Because <code>Map</code> is in Foldable.</p>
<p><strong>Hypothesis</strong>: Have interface for commonly-used functions -&gt; don’t have to remember a lot of specific functions, can reuse code, can make your code more abstract.</p>
<p>Don’t have interface for commonly-used functions -&gt; have to remember specific functions, can’t reuse code, code is specific to that data type.</p>
<p>For example, I would have to know that <code>elems</code> was the function that returned all the values in a Map.</p>
<h2 id="mock-objects">Mock Objects</h2>
<p>Test: Test-Driven Development: A Practical Guide has a whole chapter about different types of “Mock” classes - Verifiable, MockObject, ReturnObjectList, Expectation, AbstractExpectation, ExpectationValue, ExpectationSegment, etc. Do we really need all those classes?</p>
<p>Observation: Haskell doesn’t seem to use these kinds of things. I don’t hear advanced programmers like PG or Stevey or others using mocks heavily.</p>
<p>Inference: Mocks -&gt; test behaviour of an interface without using costly I/O or computations.</p>
<blockquote>
<p>You may simply have a lot of fixture to put in place, or you may be working in the context of a large, complex system. This could be a database, a workflow system, or some system for which you are developing an extension (e.g., an IDE). Your fixture may involve getting the system into a specific state so that it responds the way your tests require. This may be impossible to do quickly.</p>
<p>– Test-Driven Development: A Practical Guide, Chapter 7</p>
</blockquote>
<p>Hypothesis: Separate pure code from impure code -&gt; won’t need to use mocks (much?).</p>
<p>What about my scheduler? Didn’t I need a default scheduler?</p>
<h1 id="refactoring-hypothesis">Refactoring Hypothesis</h1>
<h2 id="hypothesis">Hypothesis</h2>
<p>Starting out -&gt; get overall type signatures and goals.</p>
<p>one function definition - abstract it and run tests.</p>
<p>two function definitions with duplicated code and slightly different goals - extract common abstract functions and run tests.</p>
<p>one abstract function, old unrefactored code that you’re trying to subsume - check if it’s a subclass of your abstract function (that it handles a subset of the branches?)</p>
<p><strong>Question</strong>: What does this predict about programming to an interface? Will the code be easier to understand, reuse, and modify? Why?</p>
<h2 id="tests-2">Tests</h2>
<p>Test: <code>get_features_strike_rate</code> and <code>get_features_average</code> with <em>roughly the same code</em> except for <code>strike_rate</code> and <code>average</code> – accept a stat_fn and have a common abstract function.</p>
<h1 id="rewriting-refactoring-prose">Rewriting: Refactoring Prose</h1>
<h3 id="refactoring-prose">Refactoring Prose</h3>
<p><strong>Acceptance test</strong>: Refactoring - default out instead of default in.</p>
<p>Given that I have 100k+ words in different essays with almost no acceptance tests</p>
<p>when I start with a fresh, small positive exemplar that I can make sense of and then bring in untested prose only when they pass some acceptance test</p>
<p>then I will have a working product at each time and be able to make sense of things and have everything well-tested.</p>
<h2 id="disjoint-hypotheses">Disjoint Hypotheses</h2>
<p><strong>Corollary</strong>: Two hypotheses, different output variables -&gt; disjoint.</p>
<p>Two hypotheses, same output variables -&gt; overlapping.</p>
<hr />
<p>Test: category hierarchy &lt;- locality; category hierarchy &lt;- causal model – overlapping hypotheses.</p>
<p>Test: direction of car &lt;- steering wheel; speed of car &lt;- pedal – disjoint hypotheses.</p>
<h2 id="rewriting-mechanism">Rewriting Mechanism</h2>
<p>What is the input and output? The input has old hypotheses with some tests and perhaps new hypotheses with some tests. The output has hypotheses and tests that cover all previous tests and perhaps some new tests as well.</p>
<p><strong>Hypothesis</strong>: Get the original output variables, get old tests, come up with your own causes, pass new tests, pass old tests -&gt; get a hypothesis that covers all tests present and past.</p>
<p>Question: What are the tests I run to make sure the new version works the same as the old one?</p>
<hr />
<p>Test: My summary of old category hierarchy ideas. I got it down from 3800 words to 1100 words, while adding new ideas and tests. Took around 3 hours. Original prose: around 30 “hypotheses”, 30 examples (no tests or even observations). Final prose: 8 hypotheses, 28 tests.</p>
<p>Number of hypotheses straight from the original: 3.</p>
<p>The final prose was strictly in the form of disjoint hypotheses followed by tests of each branch. Around 21 hypothesis branches (including corollaries). So, roughly one test per branch, sometimes more.</p>
<p>The original prose was in the form of repetitive and overlapping hypotheses with no branches, some examples, and no real tests.</p>
<p>What about the variables?</p>
<p>Here are the output variables from the final prose that were in the original prose: grammar; easier to code in; first-class categories for certain patterns; close to the problem domain; category property; mysterious category; can reuse category hierarchy; granularity of categories. (That covered basically all the hypotheses.)</p>
<p>Here are the output variables from the original prose: learning; grammar; category hierarchy; categorize a program; high-level patterns; extend the grammar; which parts are decoupled; behaviour of the whole as a function of the behaviour of its parts; simple language; mysterious properties; can reuse category hierarchy; composing categories; granularity of categories; recomputing categories;</p>
<p>Most of the output variables are the same.</p>
<p>Test: decisiveness - had three sections talking about it, collected them all under my newest explanation (indecisiveness is caused by optimizing for too many variables), was able to cover them all, shrank my prose. – I ignored the hypotheses and collected the tests.</p>
<p>Test: “Stuff not up to standards, insult -&gt; negative reinforcement for better action” – it’s in the form of [situation, action -&gt; result].</p>
<h1 id="refactoring-algorithm-for-prose">Refactoring Algorithm for Prose</h1>
<p><strong>TODO</strong>: Meta: This is subsumed by backward inference using category hierarchy.</p>
<h2 id="refactoring-algorithm-for-prose-hypothesis">Refactoring Algorithm for Prose: Hypothesis</h2>
<p><strong>Hypothesis</strong>: Refactoring algorithm for prose</p>
<p>Basically, refactor disjunctive hypotheses of the same type to get an inverse hierarchy of conjunctive hypotheses with criteria to choose among alternatives. Start with the topmost alternatives - the high-level variables like induction or goals or learning experiments. Figure out their effects and invert them to get the inverse lookup. Then recurse.</p>
<p>Compose hypotheses of different types to pass the acceptance tests you care about.</p>
<p>Steps:</p>
<p>Collect sections that talk about a common output variable.</p>
<p>For one output variable, refactor disjunctive hypotheses into a category hierarchy of inverse conjunctive hypotheses with criteria.</p>
<p>Compose hypotheses and test using acceptance tests.</p>
<p>Question: What about isolating and importing? Doesn’t that give you feedback quicker?</p>
<p>Hypothesis: Input - a bunch of sections talking about different types.</p>
<p>Desired output - acceptance tests that show key surprising insights; decoupled prose that explains those acceptance tests; unit tests for each function.</p>
<p>Properties: No “duplication” among the imported functions. Every function should be used in some acceptance test. Every function should have unit tests for its branches.</p>
<p>Don’t those properties hold now? No. Multiple sections talking about conservative focusing. Lots of concrete sections using the scientific method or the Baconian method.</p>
<p>Question: But refactoring usually means that you <strong>change the code but not the behaviour</strong>. So you need tests. (Or, at a minimum, you check that their type remains the same.)</p>
<p>But can’t you refactor purely on the level of expressions? <code>map f . map g = map (f . g)</code>. Also, <code>A, B -&gt; C; A, B' -&gt; C =&gt; A -&gt; C</code>.</p>
<p><strong>Question</strong>: Do I need to write acceptance tests first? Do I need to bring in one section at a time or a bunch of sections on the same topic? Have to toggle the variables and find out.</p>
<hr />
<p>Test: Not sure. Let’s just try with one label.</p>
<p><strong>Test</strong>: Experiment - Bring in all sections on category hierarchy. No tests. See if you get refactored code anyway.</p>
<p>What does the input look like? What is its structure?</p>
<p>23 section headings. 119 paragraphs. 40 of them are hypotheses or corollaries or continuations of hypotheses. 31 are tests. 10 observations. 5 examples. 27 are random lines. The rest are break lines.</p>
<p>How many hypotheses can you reduce that to?</p>
<p>(Imagine that. I have 30-40 functions lying around in ~2k words of prose.)</p>
<p>You can’t get rid of the tests or observations or examples. They are valuable pieces of evidence.</p>
<p><strong>Test</strong>: My “hypotheses” don’t look <strong>composable</strong> at all. They have arbitrary inputs and arbitrary outputs.</p>
<blockquote>
<p>Write function definition -&gt; get closer to the problem domain.</p>
<p>Input to a causal model is in the form of an AST governed by a grammar &lt;- designed by the possible outputs.</p>
<p>Object, output of causal model -&gt; category property.</p>
</blockquote>
<p>I suspect <strong>reductionism</strong> - describing everything in terms of some core building blocks (like say functions) and avoiding unnecessary new <strong>categories</strong> will clear things up.</p>
<p><strong>Test</strong>: Some of it is better predicted by my latest hypotheses.</p>
<blockquote>
<p><strong>Hypothesis</strong>: Mysterious category = set of inputs for which you can’t predict the output of a model (when given just that category).</p>
<p>Test: Can’t make predictions - “magic” – Harry can’t say what will happen the next time (or what can be done and what can’t).</p>
</blockquote>
<p>After reading Skinner, I now believe that mysterious explanation means treating the cause as some hidden variable (to which you can as much detail as you please) and ignoring relevant external factors. For example, when Minerva tells Harry it’s “magic”, she fails to mention that you need to have a wand and not be a Muggle or a Squib and know the spells and concentrate and stuff.</p>
<p>Test: Output variables -</p>
<p>size of code size of grammar number of design options number of errors first-class categories for certain patterns how close you are to the problem domain mysterious category different label can reuse category hierarchy can use the same action on lower-level objects granularity of categories goal categorize according to your goal use extreme cases to test the label concrete cue for the technique notice abstractions more</p>
<h2 id="refactoring-prose-all-i-care-about-is-the-algorithm">Refactoring Prose: All I care about is the Algorithm</h2>
<p>Hypothesis: Maybe types or acceptance tests make things decoupled. You can change the functions implementing those tests without affecting the outward behaviour.</p>
<p><strong>Hypothesis</strong>: The <strong>outward behaviour</strong> - the metacognitive algorithms - of my prose should remain the same. That is, I should get the same use out of them as before.</p>
<p>So, how do I use my prose? (The answer is I don’t.) How do I want to use my prose?</p>
<p>I want to have <strong>algorithms</strong> for thinking that I burn into my mind using practice. So, when I learn, I want to learn as quickly as possible, maybe by using a representative exemplar and following the values. When I research, I want to toggle variables as per conservative-focusing and focus-gambling. When I program, I want to do much of the same, along with using equational reasoning and acceptance tests and whatnot.</p>
<p>Corollary: This means the functions and their unit tests can potentially go to hell. All I care about is my algorithm.</p>
<p><strong>Corollary</strong>: If I’m going to do the same thing as ever, there’s no point in having billions of little unit-tested functions. They don’t add any value to me.</p>
<p>Corollary: It should be easy to search for what to do in any situation.</p>
<p>Lesson: Judge your prose by the value of its acceptance tests.</p>
<p><strong>Hypothesis</strong>: Actually, I think the mysterious explanations section is pretty good (once you add my latest hypothesis). It’s got some great unit tests. Remember that your mental model is a bunch of small functions.</p>
<p><strong>Hypothesis</strong>: I have been throwing out hypotheses like confetti in this section. How do I merge all of them?</p>
<hr />
<p>Test: Tons of text about categorization algorithm. Have I actually changed the way I categorize the books I read or the lectures I attend? – Oh, hell no. Useless.</p>
<p>Test: Want to remember how to figure out a mechanism – look at my induction notes. Hard to remember. Also, lots of scattered sections.</p>
<p>Test: Try to come up with a practical acceptance test where I use my categorization ideas. - <blank>.</p>
<p>Test: (Need a positive exemplar for a practical acceptance test. Some situation where I performed better because I knew about categorization.)</p>
<p>People use the trait “he is a problem child” instead of noticing how his tantrums have been shaped by the parents ignoring the current level and then giving in when he shouts louder. – people are ignoring the relevant factors in the environment and going for a mysterious explanation in the form of a hidden variable “problem child”.</p>
<h2 id="refactoring-recognize-a-high-level-pattern-and-abstract-the-code">Refactoring: Recognize a High-level Pattern and Abstract the Code</h2>
<p><strong>Hypothesis</strong>: Unique effect -&gt; can search for it by goal (i.e., can categorize it).</p>
<p>Corollary: Come up with unique effects or diagnostic cues for all functions.</p>
<p>Corollary: Want to merge a function with refactored functions, look at the diffs between their outputs, abstract both of them if possible -&gt; get merged refactored code.</p>
<p><strong>Hypothesis</strong>: Recognize a higher-level pattern, use the higher-level function -&gt; simplify this definition (minimize interface) -&gt; easy to understand, easy to reuse, cheap to change. easy to recognize in future code.</p>
<p>Can’t recognize a higher-level pattern, minimize inputs -&gt; get a high-level function, use it -&gt; simplify this definition -&gt; ditto.</p>
<p><strong>Corollary</strong>: “Refactor” a function = recognize a high-level pattern and abstract.</p>
<p>Corollary: Final code will have high-level functions and various applications.</p>
<p><strong>Hypothesis</strong>: Large pre-existing functions, try to recognize them in new function -&gt; take a lot of time; probably won’t remember them.</p>
<p>Small pre-existing functions, try to recognize them in new function -&gt; quick; probably will remember them.</p>
<p><strong>Hypothesis</strong>: Goal of refactoring = get a bunch of functions whose patterns are easy to <strong>recognize</strong> in new code or new problems.</p>
<hr />
<p>Test: Unique effect - confused about the explanation “problem child” - look at your notes on mysterious explanations.</p>
<p>Test: Merge two functions - positive exemplar.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">sum [] <span class="fu">=</span> <span class="dv">0</span>
sum (x<span class="fu">:</span>xs) <span class="fu">=</span> x <span class="fu">+</span> sum xs

length [] <span class="fu">=</span> <span class="dv">0</span>
length (x<span class="fu">:</span>xs) <span class="fu">=</span> <span class="dv">1</span> <span class="fu">+</span> length xs</code></pre></div>
<p>Explanation: Their empty list branches are the same. And their cons list branches are similar. So, a branch by branch comparison is one way to go.</p>
<p>The other way is to abstract <code>sum</code> fully.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">sum<span class="ot"> ::</span> (<span class="dt">Num</span> a, <span class="dt">Foldable</span> t) <span class="ot">=&gt;</span> t a <span class="ot">-&gt;</span> a
sum <span class="fu">=</span> foldr (<span class="fu">+</span>) <span class="dv">0</span>

length [] <span class="fu">=</span> <span class="dv">0</span>
length (x<span class="fu">:</span>xs) <span class="fu">=</span> <span class="dv">1</span> <span class="fu">+</span> length xs</code></pre></div>
<p>Now, you can no longer do a branch by branch comparison because <code>sum</code> doesn’t seem to have branches.</p>
<p>Hmm… You have to abstract <code>length</code> using the pattern of your <code>foldr</code> function. So, you must know how to <strong>recognize</strong> the pattern of <code>foldr</code>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">foldr<span class="ot"> ::</span> <span class="dt">Foldable</span> t <span class="ot">=&gt;</span> (a <span class="ot">-&gt;</span> b <span class="ot">-&gt;</span> b) <span class="ot">-&gt;</span> b <span class="ot">-&gt;</span> t a <span class="ot">-&gt;</span> b
foldr f z [] <span class="fu">=</span> z
foldr f z (x<span class="fu">:</span>xs) <span class="fu">=</span> x <span class="ot">`f`</span> foldr f z xs</code></pre></div>
<p>Test: Man, that is non-trivial work. For example, <code>foo</code> wouldn’t have matched even though it’s almost identical:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">foo [] <span class="fu">=</span> <span class="dv">0</span>
foo (x<span class="fu">:</span>xs) <span class="fu">=</span> <span class="dv">1</span> <span class="fu">+</span> foo (xs \\ [x])</code></pre></div>
<p>You need to notice that the cons branch knows about not (:) and 1 and (+), but also about (\) &amp; []. Also, the recursive call to foo knows about three things.</p>
<p>Explanation: Not really. All you’d have to notice is that it no longer satisfies the pattern of <code>foldr</code>.</p>
<p>Test: sortInts - minimize inputs till you realize that it can be written as a polymorphic <code>sort</code>. sortStrings will be easy after that because you can match the pattern of <code>sort</code>. – got a high-level function.</p>
<p>Test: Try to recognize <code>map</code> - effortless. – Any time you want to do something to all elements of a list, use map.</p>
<p>Test: Try to recognize a nested for-loop calculating subsets in a new code, or even <code>sum (x:xs) = x + sum xs</code> – hard to see the pattern.</p>
<h3 id="refactoring-case-study-causal-hypothesis">Refactoring Case Study: Causal Hypothesis</h3>
<p><strong>Hypothesis</strong>: Algorithm - Bring in one <strong>important</strong> hypothesis. (Ignore low-value corollaries.)</p>
<p>Refactor it as much as you can by minimizing its interface and trying to reuse older functions. Rinse and repeat.</p>
<hr />
<p>Test: Variables - bring in ideas one at a time into a fresh essay.</p>
<p>Make sure that the ideas in the essay are small and clean and easy to recognize in new prose.</p>
<p>Let’s see how long it takes to cover 145 sections and 54k words.</p>
<p>Stumbling blocks:</p>
<p>Don’t know what to do with a side corollary that may or may not be important. Don’t want to lose it.</p>
<blockquote>
<p><strong>Corollary</strong>: ATDD by example (page 143): divide input into equivalence classes and pick test cases “exactly at the boundary, at least one right in the middle, and one value right before the next boundary”. For multiple input variables, consider all combinations of their boundary tests.</p>
</blockquote>
<p>Maybe just leave it in the original essay. We’ll dig it up if we need it.</p>
<p>Test: I’d been acting like I had to cover <strong>all</strong> the ideas I’d ever jotted down in my essay. – Nope. Life’s too short for that.</p>
<h2 id="search-backward-inference">Search = Backward Inference</h2>
<p><strong>Hypothesis</strong>: Organize prose by topic -&gt; decouple the different sections -&gt; need to search less (? for what?).</p>
<p><strong>Hypothesis</strong>: Search = backward inference. Need to eliminate variables that don’t cause the output. Basically, when you’re searching, you want to know which variables cause something. If you’ve organized your information poorly - that is, if you’re uncertain about it - then you will have to consider a lot of possible causes. If you’ve organized well, then you will know the exact causes.</p>
<p><strong>Hypothesis</strong>: Lots of possible causes -&gt; may have to get a lot of instances to eliminate unnecessary variables.</p>
<p><strong>Corollary</strong>: Collect sections that have similar effects (aka categorize them), induce the common causes -&gt; low uncertainty -&gt; fast search.</p>
<p><strong>Hypothesis</strong>: Minimal interface = fewer causes of the output.</p>
<p>TODO: Refactor the essay using your instincts and use the before and after to come up with hypotheses for refactoring. For example, is it the fewer comparisons thanks to the hierarchical structure that let you refactor things quicker or is that you’re merging one unrefactored function at a time with well-refactored functions? (A smaller example would be good too.)</p>
<hr />
<p>Observation: [2018-01-13 Sat] Haven’t refactored any essay in years. Have just been piling on idea after idea. (Haven’t released them either, which usually forces me to clean them up.)</p>
<p>Test: Collect sections with obvious headings - collect labels first (by going through the headings). Took about 18m.</p>
<p>Test: Unrefactored vs refactored code - sum of numbers in a list of lists. What’s the difference?</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="kw">for</span>(<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i++){
    <span class="kw">for</span>(<span class="dt">int</span> j = <span class="dv">0</span>; j &lt; k; j++){
	    sum += a[i][j];
	}
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">sum <span class="fu">.</span> map sum</code></pre></div>
<p>Explanation: In the C code, the output is caused by a lot of different things like the two for-loops, i, just, and <code>a</code>. – Have to get more evidence to eliminate those unnecessary causes (aka refactor the code). In the Haskell code, the output is caused by just the three things sum, (.), and map sum. These are necessary causes - no more work need be done.</p>
<p>Test: Search causal hypothesis essay for stuff on category formation - have to go through a lot of sections. – Don’t know exactly which ones say something important about it.</p>
<p>Test: Want to “refactor” ideas on programming - again, have to collect all the sections that mention programming (i.e., cause some insight about programming) – will take a lot of time because I don’t know which ones they are.</p>
<h2 id="disjunctive-hypothesis---lots-of-search">Disjunctive Hypothesis -&gt; Lots of Search</h2>
<p><strong>Hypothesis</strong>: Disjunctive hypothesis, want to get some output -&gt; have to look at all the possible causes of that output.</p>
<p>Conjunctive hypothesis, want to get some output -&gt; have to look at one direct cause.</p>
<p><strong>Hypothesis</strong>: Unrefactored code = disjunctive hypothesis.</p>
<p><strong>Corollary</strong>: Refactoring = inducing a conjunctive hypothesis out of a disjunctive hypothesis.</p>
<p><strong>Corollary</strong>: Programming to an interface, not an implementation = extracting a conjunctive hypothesis as an interface so that you have just one cause for the effect.</p>
<p>Hypothesis: Disjunctive hypotheses are the root of all evil (uncertainty).</p>
<hr />
<p>Test: Binary search - want to find a value - if value == arr[mid], else if value &gt; arr[mid], etc. – Have to look at maybe three if conditions. Compare that to an encapsulated function <code>find (== value) :: [a] -&gt; Maybe a</code> - you don’t have to look at any other functions.</p>
<p>Test: Want to learn how to solve the subset sums problem - could look it up on this website or that one or Wikipedia. Don’t know which ones will actually give you the “aha!” you’re looking for. – Lot of work.</p>
<p>Test: for-loop to get sum of list; for-loop to get length of list. Feels like list + sum -&gt; one program; list + length -&gt; another program; list + map -&gt; another program. – Have to look at all those possible programs. But you can cover all of them using foldr.</p>
<p>Test: for-loop in two places to initialize page directory - feels like a page directory can be created in two ways. When you want to create a page directory, you’ll have to look at both of them. – But it’s just one way - so, extract a initialize page directory function and make that explicit. Just <strong>one</strong> way to do it.</p>
<h2 id="category-hierarchy-design-no-alternatives-unless-you-encode-their-criteria">Category Hierarchy Design: No Alternatives unless you encode their Criteria</h2>
<p><strong>Corollary</strong>: Criteria to help you choose among alternatives -&gt; exactly one cause of each effect.</p>
<p>No criteria and free-form alternatives -&gt; lots of causes of each effect; have to test all of them.</p>
<p><strong>Hypothesis</strong>: Hierarchy = inverse lookup from effects to causes for a particular type (<strong>not</strong> an inverse causal structure). It’s just a data structure to help look for the right function matching a contract.</p>
<p><strong>Hypothesis</strong>: Hierarchy, want to do X and Y and Z -&gt; go “down” the hierarchy via backward inference.</p>
<p><strong>Hypothesis</strong>: Different properties -&gt; may have different “hierarchies”</p>
<p>Corollary: Want to get something that satisfies different properties -&gt; have to unify output sets from different hierarchies. (Not sure.)</p>
<hr />
<p>Test: Sort with guaranteed O(nlogn) time + extra space - merge sort; sort quickly on average - quicksort; sort almost sorted list - insertion sort; sort integer list - radix sort. – choices governed by options; not free-form.</p>
<p>Test: Drive a car - could be a Ferrari or a Toyota Camry or a Tesla or whatever. – unstructured choices; have to test all of them.</p>
<p>Test: Want to sort - use the sort algorithms hierarchy; need it to be in-place - look at quick sort and other algorithms; need it to work well for almost-sorted lists - look at insertion sort. – backward inference.</p>
<p>Test: Get the right function matching a contract - function to get a sorted list in O(nlogn) worst-case time with O(n) additional space - merge sort. Function to get O(nlogn) average time and in-place - quicksort. – they have the same type signature (<code>Ord a =&gt; [a] -&gt; [a]</code>).</p>
<p>Test: Want to get the best restaurant in town - ask certain friend and not others. Want to get the best textbook for botany - ask some other friend. – different hierarchies.</p>
<h2 id="category-hierarchy-inverse-lookup">Category Hierarchy: Inverse Lookup</h2>
<p><strong>Question</strong>: If we do backward inference so often, why not represent our programs so as to make it easier? (Wait. Isn’t that just a type signature?)</p>
<hr />
<p>Test: Speed of sorting algorithm - O(n) - radix sort, etc.; O(nlogn) - quick sort (average case), merge sort, etc.; O(n^2) - insertion sort, etc. – You need to construct that inverse list explicitly (unless two-way associations already do that for you).</p>
<p>Test: House - milky tears and compulsive behaviour and been around an earthquake =&gt; spores in the brain – inverse lookup.</p>
<h2 id="acceptance-tests-show-how-functions-compose-to-do-what-you-want">Acceptance Tests: Show how Functions Compose to do what you Want</h2>
<p>Hypothesis: Acceptance tests -&gt; show how functions compose to do the things you care about.</p>
<hr />
<p>Test: Maximum segment sum – we can see how to compose the individual functions to do what we want.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">mss <span class="fu">=</span> maximum <span class="fu">.</span> scanr (<span class="fu">@</span>) <span class="dv">0</span>, <span class="kw">where</span> x <span class="fu">@</span> y <span class="fu">=</span> <span class="dv">0</span> <span class="ot">`max`</span> (x <span class="fu">+</span> y)</code></pre></div>
<h2 id="acceptance-tests-get-an-algorithm-for-it">Acceptance Tests: Get an Algorithm for it</h2>
<p>(Notes from Continuous Delivery, chapter 8)</p>
<p><strong>Concept</strong>: Acceptance test = “verify that the acceptance criteria have been met”.</p>
<p><strong>Concept</strong>: Functional acceptance criteria = input-output behaviour of a program.</p>
<p><strong>Concept</strong>: Non-functional acceptance criteria = “capacity, performance, modifiability, availability, security, usability, and so forth”.</p>
<p>Hypothesis: Acceptance tests pass -&gt; you do what the customer wants (and has specified); have not regressed.</p>
<p>Hypothesis: Acceptance tests -&gt; less costly to create and maintain than frequent manual acceptance testing and regression testing and less costly than releasing poor-quality software.</p>
<p>Hypothesis: Acceptance tests -&gt; catch serious problems that unit or component test suites could never catch.</p>
<p><strong>Hypothesis</strong>: Want to know when to use acceptance tests or want to design a new method of testing or want to convince others - need to learn all the reasons why you should use acceptance tests.</p>
<p>Simply want to use acceptance tests - need to learn how to use acceptance tests.</p>
<p>Basically, learning all the reasoning behind acceptance tests does nothing for passing your one acceptance test, which is to write good acceptance tests for your projects.</p>
<p><strong>Corollary</strong>: What I want is an algorithm, not a causal model.</p>
<hr />
<p>Test: 25 sentences per page x 30 pages per chapter = 750 sentences per chapter. If we assume that one sentence corresponds to one branch of a causal model, that’s 750 branches.</p>
<p>Test: First, he gave the high-level reason why acceptance tests are worth implementing. Then, he dived into the detailed reasons.</p>
<p>Test: No negative exemplar for acceptance tests.</p>
<p>Test: Manual acceptance testing - if it is not done every time it is released, defects will be released.</p>
<p>Test: Manual acceptance testing - if it is done every time it is released, defects will not be released.</p>
<p>Test: Manual acceptance testing is costly (positive exemplar - $3mn per release).</p>
<p>Test: Release is costly -&gt; can’t release frequently.</p>
<p>Test: Manual acceptance testing - needs to be performed after dev-complete and as a release is approaching.</p>
<p>Test: Time between dev-complete and a release is a time when teams are under extreme pressure to get software out of the door.</p>
<p><strong>Test</strong>: Implement your test in the domain language; otherwise it will be brittle. A change in the UI would break many of your tests.</p>
<p>Test: Ideally, we should test using the user interface of the system; otherwise, we’re not using the same code paths as the users.</p>
<h2 id="acceptance-test-format-test-your-mental-model">Acceptance test format: Test your Mental Model</h2>
<p><strong>Hypothesis</strong>: If it’s a technique or concept, test your mental model on a real-world problem (that tests only one or two more features than before).</p>
<p>If it’s a project, examine it with a reader’s eye.</p>
<p>If it’s a habit, check that your rate of action isn’t regressing.</p>
<hr />
<p>Test: [2018-03-08 Thu] Currently, my acceptance tests just lie there inertly, all 260 of them, without me doing the slightest bit to run them. – takes too long to run them all.</p>
<p>Test:</p>
<blockquote>
<p><strong>Acceptance test</strong>: Behaviour - watching YouTube videos when I’m tired.</p>
<p>Given that I don’t “feel” like working (or it has not been reinforced)</p>
<p>when I feel like spending time on YouTube</p>
<p>then I will review flashcards instead.</p>
</blockquote>
<p>Explanation: How will I know if I have passed that test? Many hypotheses are hand to falsify; this one is hard to confirm (and yes, getting a hypothesis up to 99% posterior probability is enough to call it “confirmed”). [go by rate of videos instead]</p>
<p>Test:</p>
<blockquote>
<p><strong>Acceptance test</strong>: Algebra of programming - greedy algorithm.</p>
<p>Given the shortest path problem</p>
<p>when I try to use algebra to get the answer</p>
<p>then I should get Dijkstra’s.</p>
</blockquote>
<p>Explanation: This one’s just too hard.</p>
<p>Test:</p>
<blockquote>
<p><strong>Acceptance test</strong>: TA recitation 1 - content.</p>
<p>When I look at the presentation</p>
<p>then I must have an overall structure.</p>
<p>When I look at each point in my slides</p>
<p>then I must have a real-world example.</p>
<p>When I think of noise in data vs outlier</p>
<p>then I must have an answer.</p>
</blockquote>
<p>Explanation: This one takes a really long time to run. I have to go over the whole presentation each time I change it. [go over your final presentation with a reader’s eye]</p>
<p>Test: [2018-03-08 Thu] Currently, my tests are too hard, take too long to run, or are ambiguous. – bad.</p>
<p>Test: My Python tests for softsec, on the other hand, were easy to pass, quick, and unambiguous. – better.</p>
<p>Test: Real-world problem to test my technique on - solve problems from past assignments or the textbook exercises – good test of your mental model.</p>
<p>Test: Only slightly harder (add just one feature) - have learned what min-cut means (but not Dinic’s algorithm) - so test yourself on a minute-cut problem – just one new feature.</p>
<h2 id="separate-tested-and-untested-prose">Separate Tested and Untested Prose</h2>
<p>TODO: Refactor above prose on tests to show all of their effects in one place (like no overlapping hypotheses, short cycle time, etc.)</p>
<p><strong>Hypothesis</strong>: Have lots of untested prose -&gt; no tests or type signatures; not refactored into small functions -&gt; hard to find existing functions for your use case -&gt; hypotheses may overlap; hard to use or reuse; hard to change.</p>
<p>No tests or type signatures, but refactored into small functions -&gt; TODO.</p>
<p><strong>Hypothesis</strong>: Try to change large untested prose in place -&gt; still lots of prose with no tests or type signature; don’t know which parts work and which parts don’t -&gt; may still have the above problems; have not compared functions for duplicated code; have to wait till everything is fixed before you can use it “as a whole” (no overall flow?); not clear how much work is left.</p>
<p>Import only those functions that have been tested and refactored -&gt; all prose has tests or type signatures; is refactored; know exactly which parts work and which parts don’t -&gt; easy to find existing functions for your use case -&gt; hypotheses won’t overlap; confident that every function has been compared against other functions for duplicated code; easy to use or reuse; easy to change; clear how much work is left.</p>
<p><strong>Lesson</strong>: Stop treating your untested prose as if it is actually worth anything. Sequester it and bring in only clean tested prose.</p>
<hr />
<p><strong>Test</strong>: Causal hypothesis essay - lots of scattered ideas; haven’t explained the old evidence using my latest hypotheses like induction or categories as equivalence classes; no “overall structure” - when I’m given a new problem, I don’t have a clear algorithm with which to attack it. I don’t know which idea to use. All those ideas lying in there are useless if I can’t get at them when I need to.</p>
<p>145 level 1 headings, 188 level 2 headings, 54k words. That is not a sane organization of my ideas.</p>
<p>Explanation: It’s too large because I haven’t explained all the evidence using my latest evidence and rather have some obsolete hypotheses lying around.</p>
<p>It’s hard to use because I don’t have concrete acceptance tests (or type signatures) to guide me through each scenario I may be in.</p>
<p>It’s hard to reuse in my future essays too, because I simply don’t remember what ideas I have had.</p>
<p>It’s hard to change because I don’t know where to insert a new test and add some hypothesis explaining it.</p>
<p>Also, there are wrong, untested hypotheses.</p>
<p>Finally, I don’t know how much work I have left. Nothing I do seems to make a dent.</p>
<h2 id="refactoring-merge-one-at-a-time">Refactoring: Merge One at a Time</h2>
<p><strong>Hypothesis</strong>: Merge n unrefactored functions all at once -&gt; don’t get feedback until you’ve covered them all - slow; don’t know the impact made by each section (by looking at the prose before and after toggling it); hard to debug - which section is getting you stuck?; have to <strong>compare</strong> each section with every other section for duplication because you don’t have tests or types - laborious.</p>
<p>Merge one unrefactored function at a time with refactored functions -&gt; get feedback after every function - quick; know the impact of each section as you toggle it; easy to debug; have to compare only with a few sections of the same type - quick.</p>
<p>Corollary: When summarizing a book or some other prose sources, merge sections one at a time with your current clean hypothesis -&gt; quick.</p>
<p>Lesson: Algorithms win. Don’t fret about the “complexity” of “managing your code”. Ask instead how long it takes to merge n sections all at once vs one at a time.</p>
<hr />
<p><strong>Test</strong>: If I think of refactoring the essay right now, it feels like I’ll have to compare each section against each of the other sections for duplicated code and thus take O(n^2) time (?). Maybe 15 of the 145 sections will combine to give a new section and, to figure out which they are, I have to read the essay over and over. Plus I won’t know how much progress I’m making or whether I’ve actually covered all the ideas that I should have.</p>
<p>If I try to refactor (or start testing) prose by importing an untested, unrefactored section into an essay full of tested and well-refactored code, where each function is guaranteed to have no code in common with any other, then I can simply split it into parts if needed and merge them with whichever clean functions I need. At each point, I’ll know exactly how much progress I’ve made. And I’ll know that the essay (or program) is clean in the sense of having no duplicated code among its functions.</p>
<p>Plus, if the clean code was written, well, cleanly, then you can merge new unrefactored code pretty quickly.</p>
<p>Explanation: Have to compare each section against every other section - time-consuming; don’t get feedback until it’s all “done”; don’t know the contribution of each section.</p>
<h2 id="hierarchy-gives-you-fast-lookup">Hierarchy gives you Fast Lookup</h2>
<p><strong>Hypothesis</strong>: Hierarchy by topic -&gt; have to search only through a little (ideally, don’t have to search at all). Roughly O(log n) lookup (?).</p>
<p>No clear hierarchy by topic -&gt; have to search through a lot to get what you want. Basically, O(n) lookup.</p>
<p>Corollary: Man, lookup takes a lot of time. Well, it is a function of your uncertainty about the prose. The more unstructured your prose is, the more uncertain you will be about it, and thus the more you will have to search.</p>
<p>Corollary: Section headings give you a lot of clues about their contents.</p>
<hr />
<p><strong>Test</strong>: Try to get sections that are covered by one test - had to walk through a <strong>lot</strong> of sections just to look for those that talk about refactoring prose. Just reading the headings of the 145 sections (around 800 words) took me around 15 minutes. Not cool. – Have to narrow it down even further. O(n) lookup.</p>
<p>Test: “Forward and backward inference” - straightforward enough. “mathematical research” - ditto. – Nice.</p>
<p>Test: causal hypothesis essay - which sections talk about goals? I can use imenu to get the four sections that have “goal” in their headings. That doesn’t mean I’ve exhausted all goal-related sections, though.</p>
<h1 id="hypotheses-about-hypotheses-model-of-the-domain">Hypotheses about Hypotheses: Model of the Domain</h1>
<p>Hypothesis: My state-transition <em>model</em> of programming seems to cover all the hypotheses that talk about amount of uncertainty about your program’s correctness or the amount of work required to fix bugs.</p>
<p><strong>Hypothesis</strong>: One type of hypothesis: move from concrete inputs to an abstract model, make abstract predictions, and then convert them to concrete predictions.</p>
<p>Test: Toggling one design variable at a time seems to be easier to handle than changing multiple variables – the state-transition model of programming seems to explain this.</p>
<p>Observation: My other “hypotheses” seem to be heavily under-specified. For example: [Multiple changes when trying to go to a desired state -&gt; could leave the system in a state that is “hard to reason about”]. The undefined terms here are “the system”, “state”, “multiple changes”, and “go to a desired state”.</p>
<p><strong>Question</strong>: How did you locate that abstract model in the first place? Aren’t you overgeneralizing from a few examples (a1 -&gt; b1 to a -&gt; b)?</p>
<p>Question: How do we write normal abstract programming functions?</p>
<p>Hypothesis: We categorize - we look at all the possible input configurations and group together those that give the same output configuration.</p>
<p>Hypothesis: We basically considered the simplest function definition for each input configuration and then merged them all, leaving aside some differing components.</p>
<h1 id="skill-acquisition">Skill Acquisition</h1>
<h2 id="skill-acquisition-hypothesis">Skill Acquisition: Hypothesis</h2>
<p><strong>Hypothesis</strong>: Skill you’re trying to learn, have a “unit test” for it -&gt; know whether you have actually learned it or not</p>
<p>Skill you’re trying to learn, don’t have a “unit test” for it -&gt; don’t know whether you have actually learned it or not</p>
<p>Skill you’re trying to maintain, run your “unit test” for it -&gt; know whether you still have it or not</p>
<p>Skill you’re trying to maintain, don’t run your “unit test” for it -&gt; don’t know whether you still have it or not</p>
<p><strong>Hypothesis</strong>: Situations, possible actions, situation-action associations - learn how to apply the actions to anything and then store the right action for each concrete situation -&gt; skill acquisition.</p>
<h2 id="learning-abstract-ideas">Learning Abstract Ideas</h2>
<p><strong>Hypothesis</strong>: Procedure you want to learn as skill, refactor it, make flashcards as unit tests for the different configurations -&gt; build the cue-memory associations.</p>
<p>Test: Making a junction tree out of a Markov random field - “first high-level step” -&gt; “variable elimination”, etc.</p>
<h2 id="fluency-and-flashcards">Fluency and Flashcards</h2>
<p><strong>Hypothesis</strong>: Test yourself using flashcards repeatedly (overlearning) -&gt; high fluency.</p>
<p>Test: Reviewing flashcards for SML final exam - went from 27 seconds per flashcard to 8 seconds to 5 seconds. For the causality midterm - went from 30 seconds per flashcard to 9 seconds to 4 seconds! – tested again and again - high fluency.</p>
<h2 id="skill-acquisition-tests">Skill Acquisition: Tests</h2>
<p>Test: I want to reinforce good behaviour. Am I doing that? (Too vague, I suspect.)</p>
<p>Test: I learned about inadequacy analysis. Do I think about the amount of work required to get some value when analyzing HP fanfiction (like in Eliezer’s Hero Licensing)? – Is this a good unit test? I don’t know.</p>
<p>Test: The classic graph for front-door criterion - will you apply the front-door criterion? I suspect that I will remember the solution directly.</p>
<p><strong>Question</strong>: How to avoid <strong>remembering</strong> the solution and actually <strong>generating</strong> it?</p>
<p>Test: Reinforcement - I give away my ideas for free thus reinforcing freeloading.</p>
<p><strong>Question</strong>: How to remember to do stuff on specific cues? Can you have unit tests for that?</p>
<p>Test: People come up with some suggestion - I can either reinforce or punish. Choose one of the four options. – just four possible abstract actions. However, there are a lot of concrete situations, like “when something falls short of your standard” or “thought about past action” or “someone tries to manipulate you”. Store the right action for each situation based on careful analysis or just feedback.</p>
<h2 id="motivation-aka-ignition-close-positive-exemplars">Motivation aka Ignition: Close Positive Exemplars</h2>
<p><strong>Hypothesis</strong>: See someone similar to yourself achieve great things i.e., close positive exemplar -&gt; feel that you could do it too if you made those small changes.</p>
<p>See someone dissimilar to yourself achieve great things i.e., distant positive exemplar -&gt; feel that they must have some special “aura of destiny” and that you couldn’t do it no matter what.</p>
<hr />
<p>Test: Me and Samsung Patrick. Korean female golfers and the first one. – close positive exemplar.</p>
<p>Test: Einstein. Mad scientists like Rick or whoever. “Geniuses” like the famous startup founders who talk weirdly and wear sweatshirts. Mathematical “geniuses” who look and act completely differently from normal people. “Smart” people using big words and an affected American accent - all to say that restore() simply sets the <strong>one</strong> bit back to what it was. – distant positive exemplars. Feel like I could never <em>be</em> like them. But I don’t have to <em>be</em> like them, I have to <strong>do</strong> what they did. And for that, I don’t have to emulate all their other characteristics.</p>
<h1 id="my-experiments-with-programs">My Experiments with Programs</h1>
<p><strong>TODO</strong>: Test the Roman Numerals problem again by using an integration test from the problem statement to get the high-level design.</p>
<h2 id="experiment-program-i-know-how-to-write">Experiment: Program I know how to write</h2>
<p><strong>Test</strong>: Roman Numerals.</p>
<p>Failed miserably to write the program quickly (or even correctly).</p>
<p><strong>Question</strong>: I’m terribly confused. WHAT THE FUCK takes so much time when writing a program?</p>
<p>Why did it take me <strong>24 minutes</strong> to figure out how to concatenate <code>[Parser [a]]</code>? (Ed: [2017-12-25 Mon] You weren’t isolating the mechanism? But you were working in the interpreter. Then, maybe you weren’t being smart about your changes.)</p>
<p>Where was I searching and what could I have tried instead?</p>
<h3 id="roman-numerals-observations">Roman Numerals: Observations</h3>
<p><strong>Question</strong>: Should I have toggled some fixed assumption? Which one?</p>
<p>Let’s look at this as scientific experimentation.</p>
<p><strong>Goal</strong>: My job was to find a correct program in the space of all programs - one that would pass my tests.</p>
<p><strong>Observation</strong>: An empty program -&gt; will fail tests</p>
<p><strong>Observation</strong>: My Seasoned Schemer program (or some other random program) -&gt; will fail tests (how did I know that?)</p>
<p><strong>Observation</strong>: My old Roman Numerals program -&gt; passes tests</p>
<p>My tests tell me that my final program should have the type <code>romanToInt :: [Char] -&gt; Int</code>, should type-check, and further accept a valid roman numeral as input and return its decimal value as output.</p>
<p>I suppose that valid roman numeral to int is easy enough. (How do I know that?)</p>
<hr />
<p>3m to figure out that the program needed just two simple functions intToRoman and romanToInt, with no parsing.</p>
<p>4m to figure out how to use Parser and run it with a simple <code>char 'f'</code> Parser (memory)</p>
<p>10m to create the RomanNumeral type and create a one-character parser</p>
<p>3m to create an alternative parser</p>
<p>8m to append list of RomanNumeral</p>
<p>24m to figure out how to concat <code>[Parser [a]]</code> - writing the type signature would have helped me out</p>
<p>15m to realize that it doesn’t work for “XX”.</p>
<p>Look at everything I tried to concat <code>[Parser [a]]</code>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="dt">Main</span><span class="fu">&gt;</span> parse (numeralParser <span class="dt">M</span>) <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;MMCMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="kw">let</span> foo <span class="fu">=</span> parse (numeralParser <span class="dt">M</span>) <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;MMCMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> liftM concat [foo, foo]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="kw">let</span> bar <span class="fu">=</span> parse (numeralParser <span class="dt">CM</span>) <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;MMCMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="kw">let</span> bar <span class="fu">=</span> parse (numeralParser <span class="dt">CM</span>) <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;CMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> bar
<span class="dt">Main</span><span class="fu">&gt;</span> liftM concat [foo, bar]
<span class="dt">Main</span><span class="fu">&gt;</span> liftM (liftM concat) [foo, bar]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t liftM concat [foo, bar]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t [foo, bar]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t liftM concat
<span class="dt">Main</span><span class="fu">&gt;</span> liftM concat [foo, bar]
<span class="dt">Main</span><span class="fu">&gt;</span> concat <span class="fu">.</span> liftM concat <span class="fu">$</span> [foo, bar]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="kw">let</span> bar <span class="fu">=</span> parse (numeralParser <span class="dt">CM</span>) <span class="st">&quot;(unknown)&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t bar
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="kw">let</span> foo <span class="fu">=</span> parse (numeralParser <span class="dt">M</span>) <span class="st">&quot;(unknown)&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t foo
<span class="dt">Main</span><span class="fu">&gt;</span> bar <span class="fu">&lt;&gt;</span> foo
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t fmap <span class="fu">.</span> fmap
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t fmap <span class="fu">.</span> fmap <span class="fu">.</span> fmap
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t (fmap <span class="fu">.</span> fmap <span class="fu">.</span> fmap) foo bar
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t (fmap <span class="fu">.</span> fmap <span class="fu">.</span> fmap) (<span class="fu">++</span>) foo bar
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t fmap <span class="fu">.</span> fmap <span class="fu">.</span> fmap
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t (fmap <span class="fu">.</span> fmap <span class="fu">.</span> fmap) (<span class="fu">++</span>) [foo, bar]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t (fmap <span class="fu">.</span> fmap <span class="fu">.</span> fmap <span class="fu">.</span> fmap) (<span class="fu">++</span>) [foo, bar]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t (fmap <span class="fu">.</span> fmap <span class="fu">.</span> fmap ) concat [foo, bar]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t mParser
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t numeralParser <span class="dt">M</span>
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="kw">let</span> x <span class="fu">=</span> numeralParser <span class="dt">M</span>
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="kw">let</span> y <span class="fu">=</span> numeralParser <span class="dt">CM</span>
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t [x, y]
<span class="dt">Main</span><span class="fu">&gt;</span> sequence [x, y]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t sequence [x, y]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t fmap concat
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t traverse
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t sequence [<span class="st">&quot;yo&quot;</span>, <span class="st">&quot;boyz&quot;</span>]
<span class="dt">Main</span><span class="fu">&gt;</span> sequence [<span class="st">&quot;yo&quot;</span>, <span class="st">&quot;boyz&quot;</span>]
<span class="dt">Main</span><span class="fu">&gt;</span> sequence [<span class="dt">Just</span> <span class="st">&quot;yo&quot;</span>, <span class="dt">Just</span> <span class="st">&quot;boyz&quot;</span>]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t fmap concat <span class="fu">.</span> sequence [x, y]
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t fmap concat <span class="fu">.</span> sequence <span class="fu">$</span> [x, y]
<span class="dt">Main</span><span class="fu">&gt;</span> parse romanNumeral <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;CMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> parse romanNumeral <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;MMMCMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> parse romanNumeral <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;MMMCMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span><span class="kw">type</span> intToRoman'
<span class="dt">Main</span><span class="fu">&gt;</span> main
<span class="dt">Main</span><span class="fu">&gt;</span> parse romanNumeralParser <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;MMMCMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> map show <span class="fu">$</span> parse romanNumeralParser <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;MMMCMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> map (map show) <span class="fu">$</span> parse romanNumeralParser <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;MMMCMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> <span class="fu">:</span>t parse romanNumeralParser <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;MMMCMMMoobar&quot;</span>
<span class="dt">Main</span><span class="fu">&gt;</span> fmap (map show) <span class="fu">$</span> parse romanNumeralParser <span class="st">&quot;(unknown)&quot;</span> <span class="st">&quot;MMMCMMMoobar&quot;</span></code></pre></div>
<p>I tried 50+ different things before I got the (incorrect) final program.</p>
<p><strong>Observation</strong>: Firstly, I went wrong in working with <code>foo</code> and <code>bar</code> in the interpreter, which were of type <code>Either ParseError [RomanNumeral]</code> and not <code>Parser [RomanNumeral]</code> like the parsers in my code.</p>
<p><strong>Observation</strong>: I tried</p>
<pre><code>liftM concat
liftM (liftM concat)
concat . liftM concat
bar &lt;&gt; foo
(fmap . fmap . fmap) foo bar
(fmap . fmap . fmap) (++) foo bar
(fmap . fmap . fmap . fmap) (++) [foo, bar]
(fmap . fmap . fmap ) concat [foo, bar]
sequence [x, y]
fmap concat
traverse
sequence [&quot;yo&quot;, &quot;boyz&quot;]
sequence [Just &quot;yo&quot;, Just &quot;boyz&quot;]
fmap concat . sequence [x, y]
fmap concat . sequence $ [x, y]</code></pre>
<p><strong>Hypothesis</strong>: Clearly I was trying stuff at random (<code>fmap . fmap . fmap . fmap</code>).</p>
<p><strong>Hypothesis</strong>: Rather, I <em>thought</em> the problem was something, but it turned out to be something else.</p>
<p><strong>Observation</strong>: Before the <code>fmap . fmap . fmap</code> attempt, I saw that</p>
<pre><code>bar :: [Char] -&gt; Either ParseError [RomanNumeral]
foo :: [Char] -&gt; Either ParseError [RomanNumeral]</code></pre>
<p>and so thought that I needed to go three levels deep (<em>wrong</em> - it was two) so that I could fmap append (<em>wrong</em> - <code>fmap</code> is for one argument) the roman numerals inside foo and bar (<em>wrong</em> - I cared about the Parsers in my code not the output).</p>
<p><strong>Observation</strong>: I was worried that I would get combinations of the inner array if I used <code>sequence</code>.</p>
<p><strong>Observation</strong>: I didn’t remember (or didn’t understand) that <code>sequence</code> on <code>[m [a]]</code> gives <code>m [ [a]]</code> without touching the inner array.</p>
<p>In fact, I should have generalized further. What I wanted was <code>[m b] -&gt; m [b]</code>.</p>
<p>Hmm… I was thrown off by the fact that I wanted to concatenate the inner lists.</p>
<p><strong>Hypothesis</strong>: So, I tried to <em>jump</em> from <code>[m [a]]</code> to the final <code>m [a]</code> in one step. And <em>that</em> is why I spent 24m trying to do a simple concatenation.</p>
<p><strong>Observation</strong>: I had a similar struggle in the dark with trying to convert RomanNumeral to Int.</p>
<pre><code>map show $ parse romanNumeralParser &quot;(unknown)&quot; &quot;MMMCMMMoobar&quot;
map (map show) $ parse romanNumeralParser &quot;(unknown)&quot; &quot;MMMCMMMoobar&quot;
:t parse romanNumeralParser &quot;(unknown)&quot; &quot;MMMCMMMoobar&quot;
fmap (map show) $ parse romanNumeralParser &quot;(unknown)&quot; &quot;MMMCMMMoobar&quot;</code></pre>
<p>Again, I didn’t think of the type signature and ended up trying to solve the wrong problem (I didn’t need to do <code>fmap (map show)</code>).</p>
<p>Nor did I generalize enough - I should have seen that the output was <code>Either ParseError [RomanNumeral]</code>, thus <code>f [RomanNumeral]</code>, and therefore I just needed to do an <code>fmap</code>. (Still, this wasn’t the problem I wanted to solve.)</p>
<p><strong>Observation</strong>: Look what I did to <em>append</em> two Parsers. (8m lost.)</p>
<pre><code>chainl mParser (++) cmParser
chainl mParser (liftM2 (++)) cmParser</code></pre>
<p>Again, no clear type signature and not enough abstraction.</p>
<hr />
<p><strong>Observation</strong>: Wow. Look at the range of strategies I tried! Who said humans can’t search?</p>
<p><strong>Question</strong>: What led to the range of strategies? Did each failed test give me the idea for the next test?</p>
<h3 id="solving-the-wrong-problem-at-the-wrong-level-of-abstraction">Solving the Wrong Problem at the Wrong Level of Abstraction</h3>
<p><strong>Hypothesis</strong>: What I should have done was to look at the type signature for my problem, after hiding the particulars.</p>
<p>For example, I wanted <code>[Parser [a]] -&gt; Parser [ [a]]</code>. Generalizing further, I wanted <code>[m [a]] -&gt; m [ [a]]</code>.</p>
<p><strong>Corollary</strong>: Having the desired type signature in mind will also keep you focussed on your goal.</p>
<p>You won’t waste time trying to append the lists in <code>Either ParseError [RomanNumeral]</code> when you really care about <code>Parser [RomanNumeral]</code>.</p>
<p><strong>Hypothesis</strong>: Keep type signature in mind -&gt; use time well. Don’t keep type signature in mind -&gt; may waste time on the wrong problem.</p>
<p><strong>Corollary</strong>: Maybe there’s something to David Rock’s idea of writing down your overall goal so that you don’t forget it (and don’t have to keep it in your mind).</p>
<hr />
<p><strong>Hypothesis</strong>: Not generalizing enough -&gt; get confused vs clear.</p>
<p>example: During my <code>sequence</code> confusion above, what I wanted was <code>[m b] -&gt; m [b]</code> but I kept working with the types <code>[m [a]] -&gt; m [a]</code>.</p>
<p>Similarly, I tried to go 3-4 levels deep after looking at <code>foo :: [Char] -&gt; Either ParseError [RomanNumeral]</code>. But I should have generalized it as <code>foo :: f1 (f2 [RomanNumeral])</code>.</p>
<p><strong>Hypothesis</strong>: Not remembering the exact type signature of functions -&gt; get confused vs clear</p>
<p>example: I didn’t remember (or didn’t understand) that <code>sequence</code> on <code>[m [a]]</code> gives <code>m [ [a]]</code> without touching the inner array.</p>
<h3 id="work-at-the-right-abstraction-level">Work at the Right Abstraction Level</h3>
<p><strong>Hypothesis</strong>: You need to <em>generalize</em> your problem in a way that makes it easy to apply your next step.</p>
<p>For example, if I had “simply” generalized the first step of my problem “concatenate <code>Parser [a]</code>” as <code>[m b] -&gt; m [b]</code>, I would have got the answer in a jiffy (<code>sequence</code>). I should have realized that <code>Parser</code> was irrelevant to my goal of concatenating the inner lists, and further that getting <code>m [a]</code> came after getting <code>m [ [a]]</code>.</p>
<p>Somehow, I needed to realize that given my goal of concatenating the inner lists, <code>Parser</code> was irrelevant.</p>
<p><strong>Hypothesis</strong>: You first come up with a strategy, and then prepare your code to make it easy to apply that strategy.</p>
<p>For example, I decided to concatenate the Parsers above. So, I should have abstracted <code>Parser a</code> as <code>m a</code>.</p>
<p>I decided to convert RomanNumeral into decimal by looking up the value of each token and summing it. So, I should have abstracted <code>Either ParseError [RomanNumeral]</code> as <code>f [RomanNumeral]</code>.</p>
<p>How to abstract your code?</p>
<p><strong>Hypothesis</strong>: Look at what your strategy needs. Abstract everything else.</p>
<p><code>concat</code> needs <code>[ [a]]</code> and will give you <code>[a]</code>. So, abstract everything else.</p>
<p><code>lookup</code> needs a <code>String</code>, which needs a <code>RomanNumeral</code>, so get in and get a RomanNumeral somehow. Abstract everything else.</p>
<h3 id="scientific-method-for-programming">Scientific Method for Programming</h3>
<p><strong>TODO</strong>: Create an ideal program for RomanNumeral and compare it to your current one.</p>
<p>What I really want is to test for presence and absence of test-passing. However, it’s silly to use unrelated programs like <code>SudokuSolver</code> or <code>SExprParser</code>.</p>
<p>I need something that is similar to RomanNumeral but wrong.</p>
<p><strong>Observation</strong>: Right now, I can’t think of variables that differ between working programs and non-working programs.</p>
<p><strong>Hypothesis</strong>: Maybe we need to compare intermediate versions of my program to get variables. Look at which versions gave an error and which ones didn’t.</p>
<h4 id="variables">Variables</h4>
<p><strong>Observation</strong>: Look at each diff of RomanNumeral:</p>
<pre><code>data type RomanNumeral
parser for M
parser for CM
alternative between them
many parsers
many M and many CM
Roman numeral to int
parsers for all Roman digits
combine many parsers in sequence
function to create parser for one Roman digit
handle Either output of Parser
tests
QuickCheck property</code></pre>
<hr />
<p>Coming up with a parser for M involves trial and error. After that, a parser for CM is trivial (since they obviously differ only in the digit string).</p>
<p>Again, after <code>many M</code>, <code>many CM</code> is easy.</p>
<p><strong>Hypothesis</strong>: Basically, if you can get the same output with slightly different values, then you’ve got a variable.</p>
<p>For example, parser for M and parser for CM.</p>
<h3 id="type-signature-of-the-scientific-method">Type Signature of the Scientific Method</h3>
<p><strong>Observation</strong>: I’m not at all clear about the type signature of the scientific method here.</p>
<p>Maybe the program is the output?</p>
<p><strong>Hypothesis</strong>: We want to figure out the model: thoughts -&gt; correct program vs wrong program.</p>
<p>One hypothesis so far is that not keeping a type signature in mind leads to the wrong program. Another is that not abstracting the current program correctly leads to the wrong program in the next version.</p>
<p>For example, I needed to know how to append two <code>Parser [a]</code> and I kept trying lots of things.</p>
<p><strong>Hypothesis</strong>: My target model there was: problem statement, current version of program, strategy -&gt; program that passes the test of the problem statement (appending two <code>Parser [a]</code>) vs fails vs passes more tests than before.</p>
<p>So, the variables to change are the problem statement, the current version of the program, and your strategy.</p>
<p><strong>Hypothesis</strong>: Strategy :: current version of the program -&gt; next version of the program.</p>
<p>And the strategy can be pretty subtle, like abstracting <code>[m [a]]</code> as <code>[m b]</code>. The first one led to a wild goose chase, the second one gave the answer in an instant.</p>
<p><strong>Observation</strong>: Still don’t know how to compare or even <em>observe</em> strategies.</p>
<hr />
<p><strong>Lesson</strong>: Remember to include all your information in your model. For example, I design my program using the problem statement and the current version of the program.</p>
<h3 id="how-to-come-up-with-strategies">How to come up with Strategies?</h3>
<p><strong>Question</strong>: How to come up with strategies?</p>
<p>How did I decide that I needed to concatenate Parsers?</p>
<p><strong>Observation</strong>: I had a cached thought that a Parser would be a good idea for getting Roman numerals.</p>
<h3 id="more-programming-experiments">More Programming Experiments</h3>
<p><strong>Observation</strong>: I finished most of the little problems from 99 Problems in around a minute each.</p>
<p><strong>Observation</strong>: <code>rotate</code> took 5 minutes, though.</p>
<p>Didn’t know for sure how split worked. That took a minute.</p>
<p>Error because I didn’t use n’. Another minute.</p>
<p><strong>Observation</strong>: Combinations - lazy solution - ~4m; recursive solution - 3m</p>
<h2 id="time-taken-is-proportional-to-loc">Time Taken is Proportional to LOC?</h2>
<p><strong>Hypothesis</strong>: (Due to Brooks) Time taken to write a program is proportional to the number of lines of code?</p>
<p>Note: I used <code>website-count-body-lines</code> to count LOC for Haskell.</p>
<p>RomanNumeral - 54 LOC - 68m - 1.25926 - 35 =s 99 Problems - 22 LOC - 25m - 1.13636 RPN Solver - 36 LOC - 97m - 2.69444 - 20 =s RaceSort - 36 LOC - 77m - 2.13889 - 32 =s CIS194 Monads - 79 LOC - 238m - 3.01266 - 65 =s Wikibook Applicative Functors - 221 LOC - 257m - 1.1629 - 305 =s LispJavaPhoneNumber2017 - 86 LOC - 208m - 2.4186 - 62 =s</p>
<p>Calc says that the correlation between [54, 22, 36, 36, 79, 221, 86] and [68, 25, 97, 77, 238, 257, 208] is <em>0.78</em>.</p>
<p>Why would this be? For one, <code>rotate</code> had two equations, the main one and then the calculation for n. But <code>encode</code> had three, even though they were simple. <code>dupli</code> and <code>split</code> were just a few words long.</p>
<h2 id="how-to-make-observations-follow-the-evidence">How to Make Observations: Follow the Evidence</h2>
<p><strong>Hypothesis</strong>: How to make observations? Observations require <em>evidence</em>. So, look at the places where you get evidence.</p>
<p>example: A, B -&gt; C; A, ~B -&gt; ~C; you need to see the output</p>
<p>Could you program in the dark, with no type-checking or intermediate tests or checking documentation, but still get it right? Probably not.</p>
<p>So, you need evidence. And what do you do with evidence? You update on it.</p>
<p><strong>Corollary</strong>: Your output categories are determined by the feedback mechanism.</p>
<p>Such as “9/15 tests pass” or “type error in the definition of romanToInt”.</p>
<h2 id="aim-optimize-how-you-use-evidence">Aim: Optimize how you use Evidence?</h2>
<p><strong>Hypothesis</strong>: Maybe my aim is to <em>optimize</em> my use of evidence. Get to the right answer with the least amount of evidence (and thus hopefully the least time).</p>
<p><strong>Hypothesis</strong>: Time taken is decided by the amount of evidence you get and how well you process it.</p>
<p><strong>Observation</strong>: When I had trouble with concatenating <code>Parser [a]</code> (I’m never going to live that down), I tried around 50 commands in the interpreter.</p>
<p>encodeModified - 7 times (4 loads, 3 test runs) - 2m decodeModified - 3 times (2 loads, 1 test run) - 1.5m dupli - 3 times (2 loads, 1 test run) - 1m split - 3 times (2 loads, 1 test run) - 1m rotate - 14 times (6 loads, 5 test runs, 2 type queries, 1 evaluation) - 5m combinations - 19 times (9 loads, 6 test runs, 1 type query, 3 evaluations) - 8m</p>
<p>Correlation (according to Calc): 0.98 between [7, 3, 3, 3, 14, 19] and [2, 1.5, 1, 1, 5, 8]</p>
<hr />
<p>As a programmer, you’re basically a scientist. You’re trying to discover the causal model as described by the problem statement and tests.</p>
<p>So, if you want to program really fast, you need to process evidence really fast. Which means making powerful observations, inferences, and experiments.</p>
<h3 id="evidence-from-within">Evidence from Within</h3>
<p><strong>Observation</strong>: The interpreter is not your only source of evidence. Your mind can give you evidence too.</p>
<p>For example, using my rule of using type signatures, I could have seen that I just needed to use <code>sequence</code> to help concatenate <code>[Parser [a]]</code>.</p>
<p><strong>Hypothesis</strong>: Are rules sources of evidence?</p>
<p><strong>Observation</strong>: I can tell that <code>fmap foo . sequence [xs, ys]</code> is going to blow up without evaluating it because I have a crude interpreter in my mind. My rule says that a dot-composition needs a <code>$</code> before the argument.</p>
<p><strong>Observation</strong>: When a function gets over 50 lines of code, my mind warns me that it will be a headache later on (the code, not my mind).</p>
<p><strong>Observation</strong>: Similarly, my mind tells me whether some technique will work (<code>sequence</code> to transpose a matrix) and how far a program is from completion. Useful things to know.</p>
<p>Trying 50 different ways to concatenate <code>Parser [a]</code> is stupid and inefficient. You’re not making full use of the evidence given to you by the interpreter.</p>
<blockquote>
<p>Tum sunn nahi rahe ho, yaar.</p>
<p>– Music director in Rockstar</p>
</blockquote>
<p><strong>Hypothesis</strong>: You need to find out as soon as possible if your idea will work.</p>
<h2 id="experiment-sujeet-rpn-solver">Experiment: Sujeet RPN Solver</h2>
<p>TODO:</p>
<h2 id="experiment-sudoku-solver">Experiment: Sudoku Solver</h2>
<p>TODO:</p>
<h2 id="experiment-heathrow">Experiment: Heathrow</h2>
<p><strong>Hypothesis</strong>: I had to consult the interpreter several times because I was dealing with an <em>unfamiliar</em> library (the Writer monad). Ditto for Parser.</p>
<p>However, Sujeet didn’t need to check any other resources for <code>solve_rpn</code> because he knew everything he needed to write that program.</p>
<h2 id="experiment-sudie-heathrow-with-twist">Experiment: Sudie Heathrow with Twist</h2>
<p>TODO:</p>
<h2 id="ideas-for-programming-experiments">Ideas for Programming Experiments</h2>
<p>Give them instructions.</p>
<p>For example, when they finish writing one block, tell them to test their code so far.</p>
<p>When they make an error, ask them to narrow their scope and work on a toy example.</p>
<p>Tell them to think of the problem’s type signature.</p>
<h2 id="programming-experiment-design">Programming Experiment Design</h2>
<p><strong>Hypothesis</strong>: Controlled experiment &lt;- toggle some variable that you suspect is a cause.</p>
<p>If you think an using an interpreter or even running test cases gives you feedback, then eliminate them to see how that affects programming time.</p>
<p>If you think the “complexity” of the problem statement affects programming time too, then make it simpler or more complex somehow.</p>
<p><strong>Lesson</strong>: In short, write your hypothesis as “programming time &lt;- X, Y, Z” and toggle them individually (or maybe all at once to get a sufficient condition).</p>
<p>Fine-tune your variables to the point where you can predict each extra minute of programming time.</p>
<p>What if you provided helper functions, like <code>isOperator</code> or <code>isOperand</code>? How much less time would they take?</p>
<p><strong>Hypothesis</strong>: Also, figure out - response &lt;- programming situation.</p>
<p>Why did I not toggle all the variables when tracking down that Markdown <code>mark-paragraph</code> bug? Where did I go wrong?</p>
<p>If you think programming time is caused by past experience, access to interpreter, and other things, then toggle them. Remove the effect of past experience somehow. (How? Maybe make them program in a new language.)</p>
<h1 id="vague-stuff">Vague Stuff</h1>
<h2 id="programming-acceptance-test">Programming: Acceptance Test</h2>
<p><strong>Acceptance test</strong>: CS527 - CTF problems.</p>
<p>Given a CTF problem</p>
<p>when you try to solve it using your hypothesis explicitly</p>
<p>then you should either solve it really quickly or learn something that helps you solve the rest of the problem really quickly.</p>
<p><strong>Acceptance test</strong>: CS527 - security project.</p>
<p>Given a security project</p>
<p>when you try to implement it securely, poke holes in others’ security, and patch your own holes</p>
<p>then you should succeed very quickly.</p>
<p><strong>Acceptance test</strong>: Want to make a Beamer presentation - can’t remember exactly how to do it. Look it up in my integration tests [fast index]. Want to add a pause between slides - can’t find it [try to look it up]. Search online and experiment within the demo presentation [add technique to integration test first]. Use the template.</p>
<p><strong>Acceptance test</strong>: Writing a C program - I want to know how to get a pointer to an array. Is <code>p = &amp;a[0]</code> good enough? Can we just do <code>p = a</code>? [remember the integration test; look it up].</p>
<p><strong>Acceptance test</strong>: ATDD by example: the parking charge calculator - they wrote an end-to-end test for the calculator in the browser [integration test] that initially checked just one branch of valet parking [short cycle time].</p>
<p><strong>Acceptance test</strong>: Milo against Avada Kedavra - he has never fought such a curse before. None of his “acceptance tests” (aka past experience or secondhand knowledge) has anything like this [no precedent in current acceptance tests].</p>
<p>He searched his rule book of techniques (or just his memory) [search techniques] and came up with the Skeletal Troll [new acceptance test].</p>
<p><strong>Acceptance test</strong>: [PASS] Anagrams</p>
<p>I tested it once with a small “dictionary”</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">&gt;</span> anagrams [<span class="st">&quot;yo&quot;</span>, <span class="st">&quot;boyz&quot;</span>] <span class="st">&quot;yoboyz&quot;</span>
[<span class="st">&quot;yoboyz&quot;</span>,<span class="st">&quot;boyzyo&quot;</span>]</code></pre></div>
<p>once with a full dictionary but a nonsense word</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">&gt;</span> anagrams dw' <span class="st">&quot;yoboyz&quot;</span>
[<span class="st">&quot;yboozy&quot;</span>,<span class="st">&quot;boozyy&quot;</span>,<span class="st">&quot;boozyy&quot;</span>,<span class="st">&quot;yboozy&quot;</span>]
(<span class="fl">0.44</span> secs, <span class="dv">190</span>,<span class="dv">065</span>,<span class="dv">168</span> bytes)</code></pre></div>
<p>and finally with a fully dictionary and a phrase from <a href="http://steve-yegge.blogspot.in/2006/10/egomania-itself.html">Steve Yegge</a>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">&gt;</span> anagrams dw' <span class="st">&quot;agilemanifesto&quot;</span>
[<span class="st">&quot;ngaliemasoftie&quot;</span>,<span class="st">&quot;ofeliamangiest&quot;</span>,<span class="st">&quot;ofeliasteaming&quot;</span>,<span class="st">&quot;agilemanifesto&quot;</span>,<span class="st">&quot;agleamnotifies&quot;</span>,<span class="st">&quot;foamiestgenial&quot;</span>,<span class="st">&quot;foamiestlinage&quot;</span>,<span class="st">&quot;foetalimagines&quot;</span>,<span class="st">&quot;fogieslaminate&quot;</span>,<span class="st">&quot;foliageinmates&quot;</span>,<span class="st">&quot;genialfoamiest&quot;</span>,<span class="st">&quot;goaliemanifest&quot;</span>,<span class="st">&quot;imaginesfoetal&quot;</span>,<span class="st">&quot;infamieslegato&quot;</span>,<span class="st">&quot;inmatesfoliage&quot;</span>,<span class="st">&quot;laminatefogies&quot;</span>,<span class="st">&quot;legatoinfamies&quot;</span>,<span class="st">&quot;linagefoamiest&quot;</span>,<span class="st">&quot;mangiestofelia&quot;</span>,<span class="st">&quot;manifestgoalie&quot;</span>,<span class="st">&quot;manifestoagile&quot;</span>,<span class="st">&quot;notifiesagleam&quot;</span>,<span class="st">&quot;semifinaltogae&quot;</span>,<span class="st">&quot;softiengaliema&quot;</span>,<span class="st">&quot;steamingofelia&quot;</span>,<span class="st">&quot;togaesemifinal&quot;</span>]
(<span class="fl">61.92</span> secs, <span class="dv">69</span>,<span class="dv">279</span>,<span class="dv">505</span>,<span class="dv">520</span> bytes)</code></pre></div>
<p>That’s all it took for me to be confident in my program. Those were my three acceptance tests. And I didn’t automate them. But it was still good enough for my purposes (which was just to test if I could write a quick one-off anagram generator in the Haskell interpreter). [don’t need to automate acceptance tests]</p>
<p><strong>Acceptance test</strong>: Siebel self-experiment on Fischer random chess</p>
<p>http://www.gigamonkeys.com/misc/fischer-random-chess.txt</p>
<p>He wrote down his thoughts after every iteration.</p>
<p>Challenge: Explain his thought process. Predict what he is going to do next.</p>
<p><strong>Acceptance test</strong>: Siebel self-experiment on the “Impossible Book” problem</p>
<p>http://www.gigamonkeys.com/misc/impossible-book-tdd.txt</p>
<p><strong>Acceptance test</strong>: Designing at speed - OS HW3 Paging.</p>
<p>How to go from the problem statement to the high-level design?</p>
<p>Your attempt: how could you have reached the final version faster? How could you have processed evidence more efficiently?</p>
<p><strong>Acceptance test</strong>: Speed coding - OS HW2 Pipes.</p>
<p>How to implement the given high-level functions as quickly as possible (using the problem statement)?</p>
<p><strong>Acceptance test</strong>: Code compression - Monads</p>
<p>How much longer is your code if you don’t use monads?</p>
<h3 id="lisp-java-phone-number-problem">Lisp-Java Phone Number Problem</h3>
<p>Source: http://www.flownet.com/ron/papers/lisp-java/</p>
<p><strong>Acceptance test</strong>: Lisp as an Alternative to Java - Phone number problem.</p>
<p>Convert phone number to phrases that encode it. Each final phrase should decode to the given phone number and should be made of words from the dictionary (and maybe single digits).</p>
<p>(I understood the problem statement by intuition. Don’t know how to use the quantitative requirements.)</p>
<p>Picking an integration test by most “complex”-seeming:</p>
<pre><code>10/783--5: neu o&quot;d 5
10/783--5: je bo&quot;s 5
10/783--5: je Bo&quot; da</code></pre>
<p><strong>Observation</strong>: That wasn’t really an integration test. It was just a bunch of unit tests. Also, I didn’t flesh out the integration test by progressively replacing the stubs.</p>
<p>Property:</p>
<p>(concatMap decode . map stripQuotes $ phrase) == just the digits == stripPunctuation phoneNumber</p>
<p>I’m sure Bird would take the inverse somehow and get the answer in a few steps.</p>
<p>Ok. How to get the “fully-specified integration test”?</p>
<p>10/783–5 -&gt; 107835 [phone number -&gt; digits]</p>
<p>107835 -&gt; 1 07835; 10 7835; 107 835; 1078 35; 10783 5. [digits -&gt; prefixes and suffixes]</p>
<p>10 7835 -&gt; je [recursive call on 7835] -&gt; je bo“s [recursive call on 5]; je Bo” [recursive call on 35] -&gt; je bo“s 5; je Bo” da. [prefix, suffix -&gt; phrase]</p>
<p>Hmm… Ok. That <em>is</em> a fully-specified integration test. Let’s run with it and see how it goes. [Step one done. Step two too.]</p>
<p>Hello world works. [Step three done.]</p>
<p>Integration test passes with one stub. One-button deployment.</p>
<p>Follow <strong>all</strong> the values. Write tests for each function call needed to pass the integration test.</p>
<p><strong>Observation</strong>: I’m making sure progress. May be slow (or not). But I’m definitely moving with a purpose.</p>
<p>Observation: 34 minutes into the implementation - done with encode to words and the others. Didn’t expect to finish this easily. (<code>encode</code> is still left, though.)</p>
<p>When debugging encode (which gave [] instead of phrases), I went back to a working version.</p>
<p>My first integration test passed.</p>
<p>Observation: However, <strong>stuck</strong> on the others. “*** Exception: Prelude.head: empty list”.</p>
<p>Time for my debugging algorithm to step up.</p>
<p><strong>Hypothesis</strong>: No debugging -&gt; anybody can coast through the problem.</p>
<p>Debugging -&gt; way better to have unit tests and well-designed code.</p>
<p>Test: What to do when you <strong>don’t</strong> have a diff? When you fail for a new test? – Narrow down the test first, I guess. (And then, maybe start stepping through the code.)</p>
<p>Turns out I was using head on an empty list.</p>
<p>Huh. It was in <code>checkConsecutiveWords</code>. Once I turned that off, the test passed.</p>
<p>Test: Man, that “severe bug” was handled easily. It took all of two minutes to squint at the error message and realize that <code>head</code> was causing the exception. I overestimated the difficulty of the problem.</p>
<p><strong>Test</strong>: Ran everything under one test - had to run tests several times before I could get the generated outcome for each of them. Much easier when I put them in separate tests and got all the generated outcomes in parallel. Way more <strong>information</strong>! You can easily refactor the test names later. For now, it’s more important to get information quickly.</p>
<p>Test: Hard to get the <strong>output</strong> of intermediate mechanisms when you use <code>where</code> statements. High cycle time (?). Uncertainty about the cause of the output.</p>
<p>Test: Separated f and thus the value of <code>result</code>. Realized that</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">filter (not <span class="fu">.</span> null) <span class="fu">.</span> concatMap (g dict letterMap) <span class="fu">$</span> possibleSplits <span class="st">&quot;112&quot;</span></code></pre></div>
<p>itself gives <code>[&quot;1 &quot;]</code>. Narrowed down!</p>
<p>Test: Broke down the input list <code>possibleSplits &quot;112&quot;</code> and checked the value. Turns out that <code>[(&quot;1&quot;,&quot;12&quot;)]</code> is what is giving the wrong output.</p>
<p>Test: I’m running manual tests. Have to keep fucking binding dict and letterMap each time.</p>
<p>Test: I don’t seem to have any first-class output for <code>g</code>. It’s just magic to me at this point. Hmm… I don’t know if <code>g</code> should return <code>[&quot;&quot;]</code> or <code>[]</code> when the suffix can’t be encoded. I don’t have a contract for <code>g</code>.</p>
<p>Test: Took me 3h19m. Pradeep_2014 did it in 2h17m and he used better types than mine. I used Strings everywhere, for God’s sake. (Maybe his types led to a better design.)</p>
<p>Test: Major problem - I was using functions or variables like <code>encode</code> and <code>g</code> and <code>result</code> without knowing their exact types or contracts. (I wrote those functions without specifying a test for them, even a rudimentary one based on the integration test.)</p>
<p><strong>Hypothesis</strong>: I should have inferred g’s contract from its input and output for the integration test.</p>
<p>[2017-12-31 Sun] Want to refactor <code>g</code>. Realize that it’s type is pretty bad.</p>
<hr />
<p>Observation: Feeling like shit right now because I didn’t zoom through the problem.</p>
<p><strong>Hypothesis</strong>: Don’t overpromise, keep improving -&gt; you will get the most utilons you can and you will be happy with that. No need to worry about what others might say.</p>
<h3 id="inverse-oriented-programming">Inverse-Oriented Programming</h3>
<p><strong>Acceptance test</strong>: Clean up your phone number example and publish it.</p>
<p><strong>Acceptance test</strong>: Use inverse functions to solve Sudoku using its property.</p>
<p><strong>Acceptance test</strong>: Test your algorithm on the number to digits problem.</p>
<p><strong>Acceptance test</strong>: Collect examples from Bird. (Implement laws as functions.)</p>
<h3 id="acceptance-test-fix-bugs-in-os-hw3">Acceptance Test: Fix Bugs in OS HW3</h3>
<p>That project involves legacy code and takes a while to compile and test as well.</p>
<h3 id="acceptance-test-write-tests-for-and-refactor-os-hw1">Acceptance Test: Write Tests for and Refactor OS HW1</h3>
<p>It has legacy code and it is in C. Enjoy. Make sure that you can write acceptance tests and pass them with ease. Remember how much trouble you had earlier.</p>
<p>(Toggle the scheduler behind an interface.)</p>
<h3 id="acceptance-test-refactoring">Acceptance Test: Refactoring</h3>
<p><strong>Acceptance test</strong>: Refactoring example from Ruby conference.</p>
<p>Given some concrete code</p>
<p>when I try to get minimum interface everywhere</p>
<p>then I will get super-clean code.</p>
<h3 id="acceptance-test-debugging">Acceptance Test: Debugging</h3>
<p><strong>Acceptance test</strong>: Debugging an Awk one-liner</p>
<p>Given that I wanted to extract acceptance tests from my essays</p>
<p>when I tried an awk one-liner</p>
<p>then it kind of worked, but missed more than half of the acceptance tests for reasons I couldn’t figure out. [negative exemplar]</p>
<p>when I tried to change a few things</p>
<p>then I got random changes. Didn’t know what worked. [toggling on a negative exemplar]</p>
<p>when I started with one narrow section for which the command works perfectly</p>
<p>then I could extend it from there quickly. [positive exemplar; don’t debug; fall back to a positive exemplar]</p>
<h3 id="acceptance-test-type-signatures">Acceptance Test: Type Signatures</h3>
<p><strong>Acceptance test</strong>: Type signatures - Awk - make them simpler and easier to compose.</p>
<p>Given that I had an Awk script to get acceptance tests but it occasionally printed stuff beyond the current section</p>
<p>when I broke the input Markdown files into sections [type: sections, not free-form text]</p>
<p>then I could handle it effortlessly. [simple type]</p>
<h3 id="interview-question">Interview Question</h3>
<p><strong>Acceptance test</strong>: Interview question - subset sums</p>
<p>Given the problem statement “Given a set of candidate numbers (C) (without duplicates) and a target number (T), find all unique combinations in C where the candidate numbers sums to T. The same repeated number may be chosen from C unlimited number of times.”</p>
<p>when I try to figure out the algorithm</p>
<p>then I should get</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> combinationSum(candidates, target):
	xs <span class="op">=</span> [[] <span class="cf">for</span> _ <span class="op">in</span> <span class="bu">range</span>(<span class="dv">0</span>, target<span class="dv">+1</span>)]
	xs[<span class="dv">0</span>] <span class="op">=</span> [[]]
	<span class="cf">for</span> x <span class="op">in</span> candidates:
		<span class="cf">for</span> i <span class="op">in</span> <span class="bu">range</span>(target, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):
			k <span class="op">=</span> <span class="dv">1</span>
			<span class="cf">while</span> i <span class="op">&gt;=</span> k <span class="op">*</span> x:
				xs[i] <span class="op">+=</span> [ys <span class="op">+</span> [x] <span class="op">*</span> k <span class="cf">for</span> ys <span class="op">in</span> xs[i <span class="op">-</span> k <span class="op">*</span> x]]
				k <span class="op">+=</span> <span class="dv">1</span>
	<span class="cf">return</span> xs[target]</code></pre></div>
<h3 id="more-acceptance-tests">More Acceptance Tests</h3>
<p><strong>Acceptance test</strong>: Grammar for problem statement of programming problem.</p>
<h2 id="programming-algorithm">Programming Algorithm</h2>
<p><strong>Hypothesis</strong>:</p>
<p>Get a “representative” integration test from the problem statement with input and output at every step. [fully-specified representative test]</p>
<p>Follow the values step-by-step to get a high-level design along with type signatures (by looking at what values the output depends on). [follow the values]</p>
<p>Start on top of a working hello-world program. [hello-world]</p>
<p>Set up and pass the integration test with stubs. [stubs]</p>
<p>Make it a one-button deployment. [deployment pipeline]</p>
<p>Implement necessary functions in isolation [implement in isolation] using tests from the integration test [initial unit tests from the integration test; red-green]. Run the integration test every time. Replace stub with actual function call. [flesh out the integration test; run the deployment pipeline]</p>
<p>Pass the test in a quick and dirty way. [coding hat]</p>
<p>Add unit tests for each of the functions. [unit tests] Then refactor. [refactoring hat]</p>
<p>If you need to use some technique, look it up in a Haskell integration test. [look it up in integration test]</p>
<p>If you get a failing test or compilation error, narrow down the causes. [narrow down the causes by backward inference on top of the last working version - look at the diff]</p>
<h2 id="committing-partially-working-code-or-partially-correct-ideas">Committing Partially-Working Code or Partially-Correct Ideas (??)</h2>
<p>Hypothesis: If I commit ideas that I will soon subsume with another idea, then I will have trouble finding them. – Not true. I can always look at the git log and diff.</p>
<p>But then my repo will no longer satisfy the property that, at any point, every function exists for a purpose - that is, it helps pass an acceptance test that wouldn’t be passed otherwise.</p>
<p>Won’t it, though? At the previous state in the repo, the acceptance test would be passed thanks to the old idea. After you’ve subsumed the idea, the acceptance test would be passed thanks to your new idea. At no point is there a function that doesn’t pull its weight.</p>
<p>Maybe the problem is that the code isn’t fully refactored. But that isn’t part of your repo property. It doesn’t say everything will be beautifully written. It just says everything will be necessary for passing the acceptance tests.</p>
<p>Hypothesis: I don’t want there to be wrong ideas in my repo history aka perfectionism. What will people say?</p>
<p><strong>Hypothesis</strong>: New idea, no acceptance test, want to refactor old ideas that the new idea subsumes -&gt; have to go through the whole essay (or at least the revision log) to find out ideas that it subsumes.</p>
<p>New idea, no acceptance test but old changes are uncommitted, want to refactor old ideas that the new idea subsumes -&gt; have to go through just the uncommitted changes.</p>
<p>New idea, have acceptance test, want to refactor old ideas that it subsumes -&gt; go through the acceptance tests to see which value transformations you could do by yourself.</p>
<hr />
<p>Test: I hesitate to commit partially-correct ideas that I’m in the middle of improving, even when they add up to over a thousand words.</p>
<p>For example, I’m writing about reductionism and behaviorists and observable consequences and how you should have definitions that make more than one prediction and so on. I know that my final hypothesis will tie up all these loose ends elegantly pretty soon, so I don’t want to commit the rest before that.</p>
<p><strong>Test</strong>: Tried committing partially-correct ideas - felt unclean, somehow. Didn’t like it at all. Felt like the log message would be misleading for future Pradeep. It would say “advance predictions &lt;- testable definitions”, which isn’t the whole story, especially because of what I’m working on next. – It’s extra work for him. If he had the obsolete ideas lying around uncommitted, he would know exactly what to change instead of having to trawl the essay or revision log. (There might still be other old ideas that could be subsumed, but at least this extra work would be avoided for the given ideas.)</p>
<h2 id="specs-and-estimation">Specs and Estimation</h2>
<p><strong>Hypothesis</strong>: Spec -&gt; estimate how long it will take.</p>
<p><strong>Hypothesis</strong>: Spec -&gt; may turn into a to-do list and thus negative reinforcement instead of the positive reinforcement of building something that has never existed before.</p>
<hr />
<blockquote>
<p>Number three giant important reason to have a spec is that without a detailed spec, it’s impossible to make a schedule. Not having a schedule is OK if it’s your PhD and you plan to spend 14 years on the thing, or if you’re a programmer working on the next Duke Nukem and we’ll ship when we’re good and ready. But for almost any kind of real business, you just have to know how long things are going to take, because developing a product costs money. You wouldn’t buy a pair of jeans without knowing what the price is, so how can a responsible business decide whether to build a product without knowing how long it will take and, therefore, how much it will cost? For more on scheduling, read Painless Software Schedules.</p>
<p>– <a href="https://www.joelonsoftware.com/2000/10/02/painless-functional-specifications-part-1-why-bother/"></a></p>
</blockquote>
<p>Test: CS373 HW1 - can’t seem to estimate how long it will take me. Feels like it will take a very, very long time and that I will surely fail to do a “good job” (even though I’m not clear about what that is).</p>
<h2 id="other-tests">Other Tests (??)</h2>
<p>Test: page table code in HW3 - wrote hopelessly buggy pointer arithmetic code. Zero tests.</p>
<p>Test: Wasn’t sure how to condition on a variable when there were two factors. Did the derivation in a scratch page - got the answer!</p>
<p>Test: Wasn’t sure how to do pointer arithmetic on an array. Ditto for bit shifting. Results were shocking! – yup.</p>
<p>Test: HW3 - no unit tests, just constant rebooting; still discovered all my bugs by reading the diffs. – read diff line by line.</p>
<p><strong>Test</strong>: Trying to write org-autoclock - should I create an automated test or do a manual test? Which would lead to faster (quick-and-dirty) code?</p>
<p>Test: org-autoclock - manual test - fast; try to write automated test - lost! – impure function.</p>
<p>Test: function to paste joined text - automated test - fast – pure function.</p>
<h1 id="testing">Testing</h1>
<h2 id="look-at-the-input-configurations-todo---flashcards">Look at the Input Configurations (TODO - flashcards)</h2>
<p><strong>Hypothesis</strong>: pure function, know all possible input configurations for which the output is different -&gt; know test cases; clear how to proceed.</p>
<p>pure function, don’t know all possible input configurations for which the output is different -&gt; don’t know all test cases; not clear how to proceed.</p>
<p>impure function, know exactly where it will be called and what you expect (thus, know all possible input configurations for which the output is different) -&gt; know test cases; clear how to proceed.</p>
<p>impure function, don’t know all the places where it will be called and what you expect (thus, don’t know all possible input configurations for which output is different) -&gt; don’t know test cases; not clear how to proceed.</p>
<p>two input configurations, don’t know if they are supposed to give the same output or not, plan for both -&gt; can choose the correct one once you get feedback.</p>
<p>two input configurations, don’t know if they are supposed to give the same output or not, plan for neither -&gt; confused even after feedback?</p>
<p><strong>Hypothesis</strong>: Concrete walk-through, toggle each variable (come up with alternatives for each concrete value) -&gt; get possible input configurations.</p>
<hr />
<p>Test: <code>org-autoclock</code> – crystal-clear after I wrote out the configurations.</p>
<pre><code>Three variables: task, clock, file

no clock, task file -&gt; ask for org task
no clock, not in task file -&gt; do nothing
clocked in, task file -&gt; resume if needed
clocked in, not in task file -&gt; clock out if needed
clocked out, task file -&gt; resume
clocked out, not in task file -&gt; do nothing</code></pre>
<p>Test: unclear about vcreate and what it actually does - well, hsize can be 100, 300, or 1M. What to do for each case? Next, allocate_bs may return SYSERR - what to do then? – write input configurations -&gt; clear!</p>
<p>Test: <code>deallocate_bs</code> - not sure of all the places where it is called. I can see that it is called when a process is killed. But where else? I feel unsure. – impure function, don’t know all possible input configurations.</p>
<p>Test: Haskell - list recursion - either empty or head and tail - clear. – pure function - know all possible configurations.</p>
<p>Test: OS HW3 - <code>open backing store</code> - don’t know whether more than one process can access the same backing store. If so, then I have to handle the case where multiple processes try to access the store and own different pages in it. If not, then I don’t have to worry about any of that. – don’t know all possible input configurations for which output is different. If one process, then no matter what, we know that the behaviour is the same simple thing. If multiple processes, then we know that the behaviour depends on which process is asking for what page and whether somebody else is accessing the store right now.</p>
<p>Test: OS HW3 - don’t know whether hsize can be more than 1600 or not. Every other doubt stems from this uncertainty. – if hsize is only within 1600, then I know what to do. If not, then I don’t know what to do, but I can find out. Clear.</p>
<p>Test: OS HW3 - What worked, I think, was to have a concrete walk-through. That told me where there could be potential hotspots.</p>
<p>“You want to read from some address in your private heap. [might want read from elsewhere] (You’ve already used vgetmem to allocate the memory. [might not have used vgetmem yet]). First, there will be a page fault because you’ve never accessed that page before [might have accessed that page before and it might be present or not]. So, you will allocate one frame for the page table and then one frame for the page itself [may not need to allocate one frame for the page table]. And then copy that page from the backing store [or just don’t]. There will always be a free frame available, so no problem [there may not be a free frame available, in which case, problem].” – Input configurations - want to access memory within your private heap or not; have used vgetmem or not; have accessed page before; is present in memory; need to allocate frame for page table; copy from backing store or don’t; free frame available or not. Also, it’s one process right now. What if you have multiple processes?</p>
<h2 id="compare-with-the-past-our-acceptance-tests-are-implicit">Compare with the Past: Our Acceptance Tests are Implicit</h2>
<p><strong>Hypothesis</strong>: Humans don’t carry around an explicit checklist of features they want to have in their next project. They simply compare it to the set of features they have seen in a successful project (and not seen in failed projects).</p>
<p><strong>Corollary</strong>: Types of acceptance tests - compare with a similar past project to make sure you have all its features; compare with a similar failed project to make sure you don’t repeat your mistakes.</p>
<p><strong>Corollary</strong>: So the similar projects we have <em>are</em> our acceptance tests.</p>
<hr />
<p><strong>Test</strong>: Designing a homework assignment - given previous assignment and current assignment, when you compare each part of their structure (like the submission instructions, the dataset details, the heading, points adding up to 100, examples of the intended output, specifying whether you want the code or just the answers in the PDF, etc.), then you should have covered everything they did – your assignment should have all the features the previous one did.</p>
<p><strong>Test</strong>: Writing a programming project - given that I sucked at the first OS homework and didn’t have any unit tests, when I check my second OS homework, then I should have (something resembling) unit tests for my functions. – don’t repeat your mistakes.</p>
<p><strong>Test</strong>: Algos midterm 2 - given that I blew some stupid questions in the first one and ran out of time, when I prepare for the second one, then I must clarify simple concepts (and perhaps add them to my cheat sheet) and hurry up in the exam – don’t repeat your mistakes.</p>
<p>Test: Classmate uses an automation tool that I didn’t know about and that starts, interacts with, and stops the OS on a remote computer without any human interaction - given that I am working on an OS project or some other project that requires manually entering commands, when I look at what I’m doing, then I should be using that automation tool – learn from others’ successes.</p>
<p>Test: Preparing for my midterm - looked at past midterm notes to know how I’d done it – acceptance test.</p>
<p><strong>Test</strong>: Forgot that this chilli powder is extra hot and that I should use less of it – forgotten acceptance test.</p>
<h2 id="acceptance-tests-vs-unit-tests-done-when-acceptance-tests-pass">Acceptance Tests vs Unit Tests: Done when Acceptance Tests Pass</h2>
<p>Hypothesis: Can write “working product” without writing or passing all unit tests -&gt; may go faster without them.</p>
<p>Can’t write “working product” without passing all acceptance tests (even if implicitly) -&gt; may go faster by writing them explicitly.</p>
<p>Corollary: Expert programmers write programs with implicit acceptance tests in their minds.</p>
<p><strong>Corollary</strong>: You don’t need to <strong>automate</strong> your acceptance tests.</p>
<p>You may need to run it only once in a while and the overhead of doing it by hand might be worth the convenience.</p>
<hr />
<p>Test: Jamie Zawinski</p>
<blockquote>
<p>There’s bound to be stuff where this would have gone faster if we’d had unit tests or smaller modules or whatever. That all sounds great in principle. Given a leisurely development pace, that’s certainly the way to go. But when you’re looking at, “We’ve got to go from zero to done in six weeks,” well, I can’t do that unless I cut something out. And what I’m going to cut out is the stuff that’s not absolutely critical. And <strong>unit tests are not critical</strong>. If there’s no unit test the customer isn’t going to complain about that. That’s an upstream issue.</p>
<p>– <a href="https://gigamonkeys.wordpress.com/2009/10/05/coders-unit-testing/"></a></p>
</blockquote>
<p>Explanation: Can write what matters without writing or passing all unit tests.</p>
<h2 id="acceptance-test-merge-old-tests-for-speed">Acceptance Test: Merge Old Tests for Speed</h2>
<p><strong>Hypothesis</strong>: Starting out, test one feature at a time -&gt; fine-grained feedback.</p>
<p>Pretty sure your code works, test one feature at a time -&gt; slow.</p>
<p>Pretty sure your code works, merge tests into most valuable paths -&gt; quick.</p>
<p>Pretty sure your code works, error cases, keep them vs don’t -&gt; ??.</p>
<hr />
<p>Test: Softsec project - lots of single command scripts like <code>whoami\n</code>, etc. – pretty slow; not of much use.</p>
<h2 id="write-notes-in-acceptance-tests-format-obsolete">Write Notes in Acceptance Tests Format (Obsolete)</h2>
<p><strong>Hypothesis</strong>: Add notes and to-do items in the form of acceptance tests -&gt; collect ideas by scenario and goal; know exactly where an idea is needed and thus how important it is.</p>
<p>Add free-form notes and to-do items -&gt; don’t collect ideas by scenario and goal; don’t know where an idea is needed or how important it is.</p>
<hr />
<p>Test: When writing acceptance tests for a presentation, I found myself moving material from my free-form notes to the tests. For example, seeds for k-means clustering - I moved in notes about a visualization tool I found online. Similarly, for weaknesses of k-means - I moved in notes from Wikipedia. – could tell the scenario for which each note was useful. It wasn’t lying around without a home.</p>
<p>Test: Negative exemplar - free-form notes - my essays - 200k words lying around just like that – don’t know where each idea is needed or how important it is.</p>
<h2 id="actually-writing-acceptance-tests">Actually Writing Acceptance Tests</h2>
<p><strong>Hypothesis</strong>: Use an actual, slightly-comical person in your acceptance test -&gt; make it more lively.</p>
<blockquote>
<p>When you’re writing a spec, an easy place to be funny is in the examples. Every time you need to tell a story about how a feature works, instead of saying:</p>
<pre><code>The user types Ctrl+N to create a new Employee table and starts entering the names of the employees.</code></pre>
<p>write something like:</p>
<pre><code>Miss Piggy, poking at the keyboard with a eyeliner stick because her chubby little fingers are too fat to press individual keys, types Ctrl+N to create a new Boyfriend table and types in the single record &quot;Kermit.&quot;</code></pre>
<p>– <a href="https://www.joelonsoftware.com/2000/10/15/painless-functional-specifications-part-4-tips/"></a></p>
</blockquote>
<hr />
<p>Test: Instead of saying</p>
<blockquote>
<p>Given that this is just after the command “login foo” and the password for foo is bar</p>
<p>when foo types “pass bar”</p>
<p>then foo must be successfully “authenticated”.</p>
</blockquote>
<p>I said:</p>
<blockquote>
<p>Given that this is just after the command “login j0hn_5m17h” and the password for j0hn_5m17h is j0hn_5m17h123</p>
<p>when the user types “pass j0hn_5m17h123”</p>
<p>then j0hn_5m17h is successfully “authenticated”.</p>
</blockquote>
<p>Explanation: There’s no semantic difference between the two. And yet, the latter feels like it’s talking about an actual person, complete with a super-weak password.</p>
<h2 id="red-green-refactor-vs-focus-gambling">Red-Green-Refactor vs Focus-Gambling (??)</h2>
<p>Test: Implementing the pseudo-code first and then covering branches with tests violates red-green-refactor. Then again, focus-gambling itself violates red-green-refactor. You’re concluding first and running tests later.</p>
<h2 id="unit-testing-vs-regression-testing">Unit Testing vs Regression Testing</h2>
<p><strong>Hypothesis</strong>: In any kind of testing, you have to provide the input for the (hopefully) representative test. In unit testing, you have to provide the desired output as well. In regression testing, the last good implementation provides the output.</p>
<p>So, if you’re regression-testing a React component, you still have to construct representative test inputs. It’s just that the program will produce the output and Jest will save that snapshot.</p>
<h2 id="shallow-testing-vs-deep-testing">Shallow Testing vs Deep Testing</h2>
<p><strong>Hypothesis</strong>: Shallow tests distinguish between completely failing products and reasonably working products (especially if your code doesn’t game the test) and are quick to write.</p>
<p>Deep tests distinguish between completely working products and any non-working products but are slow to write.</p>
<p>Hypothesis: Shallow tests are better than nothing. And since they’re pretty quick to write, if use them early you will be able to measure partial progress.</p>
<p>If you insist on using only deep tests, you will have to wait a long time before you can pass your test.</p>
<p>Corollary: These are probably the tests that Harry was talking about. Run quick, easy checks to test whether your ideas are right or not.</p>
<hr />
<p>Test: Shallow test - check if the CSS class for a button is in the DOM – shallow test that distinguishes between a completely failing and a reasonably working product. Quick.</p>
<p>Test: Deep test - check if the React component matches the previous snapshot – deep test that distinguishes between a completely working and any non-working product. Slow.</p>
<h2 id="regression-tests-are-awesome">Regression Tests are Awesome!</h2>
<p><strong>Observation</strong>: [2018-07-26 Thu] “8 volunteers needed” vs “8 more volunteers needed”. – May never have caught that!</p>
<h2 id="testing-refactors-your-code">Testing Refactors your Code</h2>
<p>Hypothesis: Testing forces you to think about the input and output of your function, at least for a representative example.</p>
<p>Hypothesis: Testing makes you refactor your code by breaking out unnecessary dependencies.</p>
<p>Wow. Testing forces you to <strong>decouple</strong> your code.</p>
<p>For example, I just realized that the volunteering stuff had nothing to do with the rest of the to-do list. It was limited strictly to the row.</p>
<p>Hypothesis: Snapshot testing turns your code’s behaviour into a first-class output. Easy to test.</p>
<p><strong>Observation</strong>: <code>jest --watch</code> is super-sweet! Instantaneous feedback!</p>
<hr />
<p><strong>Test</strong>: [2018-07-10 Tue] Trying to Jest snapshot test a React component made me realize that it wasn’t pure. (It looked up some config stuff from a store.) – break the dependency.</p>
<p>Test: Snapshot is a JSON file – first-class output. Easy to test.</p>
<h2 id="testing-makes-you-think-of-the-different-branches">Testing makes you think of the Different Branches</h2>
<p>Hypothesis: Testing makes you think of the different branches and thus the different representative tests you will need to understand the individual functions.</p>
<p>(Note that understanding the system as a whole may take more representative exemplars. Or not.)</p>
<p><strong>Corollary</strong>: That means that I need to think about the different branches in my own essays to figure out what tests I need. Right now, it’s all just a test-less mess.</p>
<p>Hypothesis: Why I resist making sweeping changes here on the frontend - testing all the different branches again would be a massive pain.</p>
<hr />
<p><strong>Test</strong>: [2018-07-13 Fri] Testing a Flux store - realized that there were just around 10 actions and that they each had simple effects. There were practically no branches at all. So, all I would need would be 10 tests.</p>
<p>Note, though, that there are still edge cases like adding an item at index -1 (which would currently put it at the front of the list) or removing an item at an index that doesn’t exist.</p>
<p>Test: Just discovered a bug (several, in fact) - reset list doesn’t reset the last added index.</p>
<h2 id="unit-tests-help-you-eliminate-irrelevant-factors-in-a-function">Unit Tests help you Eliminate Irrelevant Factors in a Function</h2>
<p>Hypothesis: Unit tests are like instances that help you learn a hierarchy of relevant factors. In particular, they help you eliminate the parts of your functions that are irrelevant to your use cases (i.e., your category feedback).</p>
<h1 id="programming-at-speed-cycle-time">Programming at Speed: Cycle Time</h1>
<h2 id="speed-is-determined-by-the-number-of-constraints">Speed is Determined by the Number of Constraints</h2>
<p><strong>Hypothesis</strong>: Time taken to complete some task is proportional to the number and severity of constraints.</p>
<p>TODO: Labels: “severity of constraint” - give me positive and negative exemplars; how does it affect the time taken?</p>
<p>Corollary: Start with as few constraints as you can get away with to work at maximum speed. This is the MVP.</p>
<p>For example, get correctness before you get quality. Further, get correctness in some aspects before you get in others.</p>
<hr />
<p>Test: Positive exemplar - constraint - food must taste good – positive.</p>
<p>Test: Negative exemplar - constraint - doesn’t matter how much of the zero-calorie drinks I drink – negative (within reason).</p>
<p>Test: Cooking right now - wanted it to taste great, be nutritious, finish as quickly as possible, and leave minimal trash. – too many constraints. Would rather not do it at all.</p>
<p>Test: Friends - don’t have as many constraints on what you can say or do together – lower constraints.</p>
<p>Test: Learn about different types of people who read your blog – lots of constraints, blocks you (h/t Stevey).</p>
<p>Test: Try to write a perfect schema the first time around - take really long – lots of constraints.</p>
<h2 id="why-do-i-hesitate-to-bite-the-bullet">Why do I Hesitate to Bite the Bullet?</h2>
<p>Hypothesis: If you take on a problem that is too hard for you but refuse to admit it, then you won’t run enough tests (since they would be a waste of time for someone who actually was that skilled) and thus will take longer to debug your program.</p>
<p>If you take on a problem that is too easy for you but don’t realize it, then you will run too many tests and waste your time while others zoom past you.</p>
<p><strong>Hypothesis</strong>: Higher-level patterns are those for which you don’t need to test the intermediate outputs.</p>
<p><strong>Hypothesis</strong>: The time taken to find the cleanest design possible is the time needed to go through <strong>every</strong> existing implementation! That’s why I take a long time to understand a code base. I feel like I need to understand the <strong>best</strong> design currently used (if not the best design possible).</p>
<p>Corollary: That is the true cost of perfectionism. You have to go through all existing implementations to find the best current design.</p>
<p><strong>Hypothesis</strong>: A satisficer would stop after the first positive exemplar. A perfectionist would have to go through all positive exemplars.</p>
<p>Corollary:: When there’s more than one way to do it, I become paralyzed because I feel compelled to go through all of the possibilities and figure out the smallest set of sufficient factors.</p>
<p>Corollary: This could also be why I try to decouple a new feature as much as possible so that there is just one way to implement it (since there are no extraneous factors) and I don’t have to waste time experimenting with a lot of the possibilities.</p>
<hr />
<p>Test: I have a decent solution for the frontend-backend connection idea. But I’m hesitating to actually go and implement it.</p>
<p>I don’t know the best plan for testing - should I do just the frontend part and check if the middle part gets the data (and do the same with the middle part to the backend)? Or should I build a complete thing and test whether the real object was created (so that I need to run fewer tests)? Basically, running tests for each part feels like I’m wasting time, like a skilled programmer wouldn’t waste time running that many tests. But not running intermediate tests feels like I’m bound to end up with errors (given that there are so many moving parts) and will find it hard to debug because I don’t have a close positive exemplar.</p>
<p>Huh. That’s a nice Catch 22. And it’s all because I’m not realistic about what problems I can solve comfortably. If the problem is realistically too hard for me, then it’d be a big mistake to wait to test until the end because I wouldn’t be able to debug my inevitable mistakes. However, if the problem is too easy for me, then it’d be a waste of time to test each part of my program because it’d probably work right most of the time. In short, tests would be highly informative in the former and uninformative in the latter.</p>
<p>And we know that time taken to implement something increases with the number of tests. (Do we know that?)</p>
<p>Test: Too easy a problem - it’d be stupid to test the output at each step of <code>grep -v foo.txt | wc -l</code> or <code>sort | uniq -c | sort -k1,1nr</code>. I <strong>know</strong> how the output relates to the input. That’s the whole point of having higher-level patterns - you don’t have to test their output. – waste of time to test.</p>
<p>Test: Too hard a problem - (finding it hard to think of a reasonable problem that I would admit as hard) solving the phone number problem - took me a few hours the last time I tried it – need to test each part.</p>
<p><strong>Test</strong>: Also, I fear that there is a cleaner way to do it, which I can find by reading even more code, and therefore I don’t go ahead with a half-assed design that would actually work.</p>
<p>Basically, I won’t go ahead until I’ve found the <strong>cleanest</strong> way to do it. Which would require me to go through <strong>all</strong> the existing code and check all of their designs. If any of them has a cleaner design (which is my output variable), then I will ignore the other options and go with the better one.</p>
<p><strong>This</strong> is why I am such a slow learner.</p>
<h2 id="the-cost-of-induction-depends-on-the-cost-of-diffing">The Cost of Induction depends on the Cost of Diffing</h2>
<p><strong>Hypothesis</strong>: The cost of inducing over several existing implementations to find out the smallest sufficient set of factors is the cost of diffing.</p>
<p>You’re given two implementations spanning several files and their output features. You have to <strong>diff</strong> the two programs and match the diffs to the diffs of their output features. And humans take a while to diff.</p>
<p>Corollary: Wow. Induction can be costly. This is why people should do it for you by abstracting the common parts and leaving only the specific details to each instance.</p>
<p><strong>Corollary</strong>: Good abstractions shorten your code and thus speed up your diffing. This is why succinctness is power.</p>
<p><strong>Corollary</strong>: A good grasp of high-level patterns also speeds up diffing because you can get away with shallow diffs.</p>
<p>For example, if you know that the tests folder contains non-critical test code, you can skip it. If you know that the object fields will be defined in a particular place, you can compare those methods with each other only (instead of comparing everything with everything else).</p>
<p><strong>Hypothesis</strong>: Structure eases diffing by telling you which parts to compare with which parts.</p>
<hr />
<p>Test: Paralyzed - had to check the different implementations of features because I didn’t want to miss out on a potentially way easier and way cleaner technique. Spent a hour and a half simply testing that hypothesis because I had to go over every function. – deep comparison to figure out which factors were similar and which different (including the output factors).</p>
<p>For example, I wanted to check if implementation B gave any newer output features than implementation A. So I had to compare the output variables deeply too.</p>
<p>Test: Good abstractions can save you time in comparing:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">sum [] <span class="fu">=</span> <span class="dv">0</span>
sum (x<span class="fu">:</span>xs) <span class="fu">=</span> x <span class="fu">+</span> sum xs

product [] <span class="fu">=</span> <span class="dv">1</span>
product (x<span class="fu">:</span>xs) <span class="fu">=</span> x <span class="fu">*</span> product xs</code></pre></div>
<p>vs</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">sum <span class="fu">=</span> foldr (<span class="fu">+</span>) <span class="dv">0</span>
product <span class="fu">=</span> foldr (<span class="fu">*</span>) <span class="dv">1</span></code></pre></div>
<p>Explanation: The differences are way more readily obvious in the latter.</p>
<h2 id="how-to-get-an-mvp">How to Get an MVP?</h2>
<p>Hypothesis: Imagine the product without certain features (or with relaxed constraints). If it still satisfies some <strong>valuable acceptance tests</strong>, then those features are not part of your MVP.</p>
<p>Or maybe it’s about the end-to-end acceptance tests that you choose not to pass.</p>
<p>Hypothesis: Decide how much value you want in your MVP and then pack in as many high-value acceptance tests (or easy acceptance tests) as needed to produce that value.</p>
<p>TODO: Labels: “value you want in your MVP”, “value of acceptance test” - need positive and negative exemplars.</p>
<p>Hypothesis: Ask yourself “what would I do if I had to release right now?”. That will give you a current positive exemplar, even if it is low-quality (as opposed to a nebulous ideal exemplar, which only leads to a negative exemplar right now).</p>
<hr />
<p>Test: Super Mario - the game “works pretty well” even without the princess. Well, decompose the output (in this case, your gaming experience). You are entertained by the jumping and running.</p>
<p>Test: Low-quality but immediate positive exemplar - what benchmark would I use for my equational calculator? Probably programming challenges.</p>
<h2 id="deployment-pipeline-automatically-get-output-from-input">Deployment Pipeline: Automatically get Output from Input</h2>
<p>Hypothesis: A deployment pipeline is when you can get the output directly by setting the input.</p>
<p>This is obvious for a program like <code>square</code>, where you can feed in <code>3</code> and get <code>9</code>.</p>
<p>But it’s more subtle for a project where your output is a report. Any change you make to the project should create a new instance of the final report. For example, if you add more training data, that should obviously affect the report. If you add a new machine learning algorithm, that should too. In short, if you set up an automated pipeline, you can measure your progress simply through the final result (your report). Otherwise, you will have to judge a multi-factor project on things like the training data, the machine learning algorithms, and so on. It’s much harder than judging a single report.</p>
<p>Corollary: You can design your next action by looking at the next thing you want to add to your report.</p>
<h2 id="iterative-development-easy-to-change-high-level-design">Iterative Development: Easy to Change High-level Design</h2>
<p>Hypothesis: If you release a simple version of your project, you can try out different high-level designs cheaply since you have small inputs.</p>
<p>If you wait until you’ve done the rest of work before you try a different high-level design, you’ll have to work a lot to get it running since you have large inputs.</p>
<p>Corollary: You can still get those benefits after you’ve begun by experimenting in a new blank project and moving in your old changes.</p>
<p>Observation: I wanted to try different formats for a file that was going to be read by another program. Easy to do given that all I had in the file was one line.</p>
<p>If I wanted to do it after I had a long file, I’d have to keep modifying the data in the file according to the new format.</p>
<p>Observation: This is what writers call outlining.</p>
<p>Observation: This is what filmmakers call story-boarding.</p>
<h2 id="iterative-development-deal-with-migration-problems-one-at-a-time">Iterative Development: Deal with Migration Problems One at a Time</h2>
<p>Hypothesis: If you settle on a high-level design up front, you can deal with migration problems one at a time.</p>
<p>If you change your high-level design when you’re deep into your project, you will have to deal with migration problems all at once.</p>
<p>Observation: Want to format a long LaTeX file like a research paper. All of a sudden, I have to deal with a lot of changes, like diagrams or tables or headings, all at once.</p>
<p>If I’d started with an empty research paper template, then I would have had to deal with each problem one at a time.</p>
<h2 id="speed-coding-hat-vs-refactoring-hat">Speed: Coding Hat vs Refactoring Hat</h2>
<p><strong>Hypothesis</strong>: adding a new feature, one long chain of function calls -&gt; will pass the test case (one branch), very little time, will not overengineer. Refactor -&gt; easier to test going forward -&gt; quick. h/t Kent Beck.</p>
<p>adding a new feature, abstract code (using separate functions or classes) -&gt; will pass the test case (one branch), will take more time because you’re changing the design too, may overengineer. Debugging -&gt; slow.</p>
<p>adding a new feature, optimized code (low-memory quick functions or detailed, convincing examples) -&gt; will pass the test case (one branch), will take more time because you’re changing the design at the same time you’re making it faster; may overengineer. Debugging -&gt; slow.</p>
<p>Tests that already pass, ugly code, refactor -&gt; really quick.</p>
<hr />
<p><strong>Test</strong>: [2017-11-05 Sun] Tried to write quick and dirty code to pass one simple unit test. Nearly got a heart attack in the process. Here it is:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> batsman_total(match, player):
	d <span class="op">=</span> match.match_details[<span class="st">'innings'</span>][<span class="st">'1st innings'</span>][<span class="st">'deliveries'</span>]
	<span class="bu">print</span>(d)
	total <span class="op">=</span> <span class="dv">0</span>
	<span class="cf">for</span> ball_num, ball <span class="op">in</span> d.items():
		<span class="cf">if</span> ball[<span class="st">'batsman'</span>] <span class="op">==</span> player:
			total <span class="op">+=</span> ball[<span class="st">'runs'</span>][<span class="st">'batsman'</span>]
	<span class="cf">return</span> total</code></pre></div>
<p>I couldn’t bring myself to write <code>total += anything</code>. Felt so fucking gauche. Ditto for the for-loop and direct testing (<code>if ball['batsman'] == player</code>). I felt like reaching for a map and filter. But that would probably be overkill. I needed to bring myself to cut through to the actual output.</p>
<p>But this code is fine for my purposes! I usually overengineer. I can code faster by writing quick and dirty code and then refactoring, instead of throwing in abstractions like <code>map</code> and <code>filter</code> and so on, especially in a predominantly-imperative language like Python.</p>
<p>Test: Want to write down my completeness proof in LaTeX - hesitating because I feel like I need to write a complete report that flows from start to end, and maybe have diagrams and stuff. No! All I need to write is the proof alone. Everything else can come later. – one thing at a time.</p>
<p>Test: Spent the last one hour coming up with a crystal-clear model that would show how <span class="math inline">\(U_Z\)</span> and Y are related even though that’s not the point of my proof. Dammit. – I was trying to abstract? Was I? I was trying to optimize for a <strong>great</strong> proof - one that would convince any snotty critics. But I didn’t really need that. This isn’t my final draft; this is just a proof of concept.</p>
<p><strong>Test</strong>: Others seem to finish assignments sooner than me. Is it because they’re writing different code than me or because they’re writing the same code faster?</p>
<p>Test: OS HW3 - I’m taking a long time to pass each test. Is it some essential difficulty of the problem (with respect to my current skill) or am I just being slow somehow?</p>
<p>Test: Refactoring is really cheap! - it’s taking me a matter of 2-4 minutes to extract functions from what looked like irredeemably-tangled code (that actually passed the tests). – huh. One thing at a time.</p>
<h3 id="what-the-really-fast-coders-do-run-the-program-in-your-mind">What the Really Fast Coders Do: Run the Program in your Mind</h3>
<p>Hypothesis: Fast coders -&gt; get feedback sparingly.</p>
<p><strong>Hypothesis</strong>: Focus-gamble - try more than one thing at a time.</p>
<p><strong>Hypothesis</strong>: Me and people who do TDD - we’re getting <strong>dependent</strong> on fine-grained feedback. Right now, I’m running tests after every couple of lines or so. I feel like I don’t know what would happen otherwise. But I’m missing out on the feedback that I would get by simply looking at the code without running it. Maybe that’s faster. That’s probably how fast coders do it.</p>
<p>When you run tests every few minutes, you don’t think about how your code works. You don’t <strong>have</strong> to, and that can save you time and prevent bugs. But you’re probably losing the skill of analyzing code without running it.</p>
<p>You don’t need to test each new library call separately. That’s wasted feedback. Once you know the general interface of that library call, you should be ready to use it.</p>
<p><strong>Hypothesis</strong>: Fast coders, 20 lines of code -&gt; can predict the output without running it.</p>
<p>People who have gotten used to running unit tests continuously, 20 lines of code -&gt; can’t predict the output; have to run it.</p>
<p>Corollary: If that is true, then people who run the code frequently like that would get overwhelmed pretty easily by moderately large code. They would go around looking for understandable <strong>outputs</strong> instead of trying to understand the <strong>code</strong> itself.</p>
<p><strong>Corollary</strong>: Basically, get feedback from your mental model instead of waiting for feedback from the mechanism itself.</p>
<p><strong>Hypothesis</strong>: Depend on feedback from others or from tests -&gt; don’t build a full model of the code in your head -&gt; feel that there are some missing magical pieces that only others have.</p>
<p>Don’t depend on feedback from others -&gt; build a full model of the code in your head -&gt; feel that there are no missing magical pieces, that it is mundane and solvable.</p>
<p>Remember, mysterious explanations are formed when you ignore some external factors and start postulating some hidden causes.</p>
<p><strong>Hypothesis</strong>: Dependent on feedback from the computer, write “complicated” code -&gt; feel the urge to test each part of it in isolation because anything could go wrong.</p>
<p>Dependent on feedback from other people (like TAs), work on a tough problem -&gt; feel the urge to get feedback about each part of your work because anything could go wrong.</p>
<p>Not dependent on external feedback, write “complicated” code -&gt; don’t feel the urge to test each part of it; wait till you write a reasonable amount of code and then test it.</p>
<hr />
<p>Test: Saw a guy write a simple JS snake game in 4m30s. He had obviously done this several times before. But the main thing was that he didn’t run the code even once. – He got no feedback.</p>
<p>Test: New library - wasn’t able to follow the code at first go - kept looking for an understandable output of some function – kind of lost the habit of understanding code itself.</p>
<p>Test: Wanted to add my multiple-command exploit to the project - delayed because I was afraid I wouldn’t be able to integrate it correctly – All I had to do was read the code and build a half-decent model of it.</p>
<p>Test: Negative exemplar - interview answer - have to judge it by myself. Was pretty surprised at how far I was able to get when I <strong>actually</strong> walked through each line of my function with a trivial input. – your mental model can give you a <strong>lot</strong> of feedback.</p>
<p><strong>Test</strong>: Wanted to replace each string in a one-liner with its minified counterpart. Wrote this in the Emacs Lisp minibuffer:</p>
<pre class="elisp"><code>(r-evil-map (region-beginning) (region-end) (lambda (line) (s-replace-all '((&quot;before_string&quot; . &quot;bs&quot;) (&quot;ebp_minus_4&quot; . &quot;m4&quot;) (&quot;ebp_value&quot; . &quot;ev&quot;) (&quot;ebp_plus_4&quot; . &quot;p4&quot;) (&quot;after_ebp&quot; . &quot;ae&quot;) (&quot;main_address&quot; . &quot;ma&quot;)) line)))</code></pre>
<p>(I wanted to minify the Python one-liner since it was getting too long to run on the remote computer, if you want to know the purpose. Don’t think you can write a loop in a Python one-liner. Sucks.)</p>
<p>I immediately felt the urge to run <code>r-evil-map</code> on a simple line to make sure it worked the way I thought it did (urge #1). Then, when I added the lambda, I felt the urge to test whether it could handle just one single string (urge #2). When I made myself keep going, I felt like I had to test whether the strings would overlap with each other somehow and mangle the result (urge #3). Finally, I felt like transforming my Python one-liner and running it locally to make sure that it still worked like before. (urge #4. I gave in here and tested it locally.)</p>
<p>Explanation: When I ultimately transformed the one-liner I was using on the remote computer, it worked instantly! I didn’t have to give into any of the above four urges for feedback.</p>
<p><strong>Test</strong>: Every time I think of asking for the TA for help, I feel like there’s some mysterious essence of the problem that I simply cannot grasp and that he can help me with. But the last few times, when I’ve stopped myself from posting a message and instead tried to solve my problem myself, I found that the answer turned out to be pretty mundane (as it always is).</p>
<p>I had to use a different <code>$ebp</code> address on the remote server or brute-force different offsets to figure out where it might be or use Python wrapper for libc to generate random numbers the way C does or use a different shell code. It’s usually a problem that I <strong>can</strong> solve. But notice how easily I impute a mysterious solution to the problem.</p>
<p>(Yes, sometimes the TA does hold a missing piece that I couldn’t have known by myself, such as the fact that you have to use <code>env - $(pwd)/a.out</code> to clear the environment and get a better idea of the stack addresses or that <code>%n</code> writes to the address pointed to by the location on the stack, not to the location itself (even though I could figure this out in theory). But those are pretty rare, I think.)</p>
<p>Explanation: In short, I ignore certain external factors that I could have easily accounted for and instead postulate some mysterious missing piece that only people with the true vision know.</p>
<p>Test: Positive exemplar - turnaround - did it all by myself. – I know it inside out.</p>
<p>Test: Negative exemplar - bof - still not 100% sure – asked for a lot for help.</p>
<h3 id="math-get-answers-without-getting-empirical-feedback">Math: Get Answers without Getting Empirical Feedback</h3>
<p><strong>Hypothesis</strong>: Math is how you get answers without getting empirical feedback.</p>
<p><strong>Hypothesis</strong>: Holy crap. Is this our surrogate endpoint? Is this how we get answers without running costly real-world trials?</p>
<p>It’s the classical debate between empiricism and deduction. You can calculate 37 times 14 in two ways: lay out pebbles in 37 rows of 14 each and then count the total or simply use your grade school multiplication algorithm to get 518. The former is empiricism and the latter is deduction (or computation or whatever you want to call it). In empiricism, you assume (or realize) that you can’t compute the final answer by yourself and you want to outsource it to nature, which has vastly more computational power. In computation, you take on the burden of evaluating each step of the function yourself.</p>
<hr />
<p>Test: Decision tree - reduced error pruning - what if you go top-down and decide whether to split at a node based on the validation set? – either run the experiment or use your logic.</p>
<p>Test: Negative exemplar - empiricists like Newton and others would probably prefer to run the experiments, especially if they are cheap. – depend on feedback.</p>
<p>Test: Is my surrogate endpoints theorem right? Have to judge based on the math proof. – need to use math.</p>
<p>Test: Will the Haskell program work? – can reason equationally.</p>
<p>Test: Will my change to my Python data mining script work? Can’t wait five hours for the script to finish all the processing, reach that step, and crash. Would like to know right now. – have to reason using logic.</p>
<p>Test: “Armchair” economics - produce answers to real-world questions using economic models instead of actual reality. For example, Tim Harford predicted that most of the coffee shop profits would go to the landlords because what was scarce was their corner store location, not the coffee. – reason.</p>
<p><strong>Test</strong>: Algorithms - cycle property - the costliest edge in a cycle can never be part of an MST. – logic.</p>
<p><strong>Test</strong>: Algorithms - cut property - the cheapest edge in a cutset is part of the MST. – logic.</p>
<h3 id="efficient-processing-how-often-do-you-get-feedback">Efficient Processing: How often do you get Feedback? (??)</h3>
<p><strong>Hypothesis</strong>: Measure how many times you run commands in the interpreter or run your tests -&gt; learn how efficiently you process information.</p>
<h2 id="continuous-deployment">Continuous Deployment</h2>
<p>Hypothesis: Continuous deployment -&gt; low risk and low tension when it comes to release day.</p>
<p>Release only the day before -&gt; high risk and high tension.</p>
<hr />
<p>Test: JWZ about Netscape - they released their browser for all platforms at the same time, whereas the conventional practice was to release Windows first and handle Mac later. – That’s what failed companies did.</p>
<blockquote>
<p>The other big thing was we always shipped all platforms simultaneously; that was another thing they thought was just stupid. “Oh, 90 percent of people are using Windows, so we’ll focus on the Windows side of things and then we’ll port it later.” Which is what many other failed companies have done. If you’re trying to ship a cross-platform product, history really shows that’s how you don’t do it. If you want it to really be cross-platform, you have to do them simultaneously. The porting thing results in a crappy product on the second platform.</p>
<p>– JWZ, Coders at Work</p>
</blockquote>
<p>Test: CS373 HW1 - Note how much time I’m spending just <strong>wrestling</strong> with R and CSV. I haven’t done any actual work yet. – Need to release a hello world before you do anything else. Here, it would have been a simple installation of R itself, then reading CSV in R, CSV with arrays, converting JSON to CSV, and then other stuff. All because I didn’t release sooner.</p>
<h2 id="short-cycle-time---integration-tests-duplicate">Short Cycle Time &lt;- Integration Tests (duplicate)</h2>
<p><strong>Corollary</strong>: Have detailed integration tests -&gt; short cycle time, especially if you consider fleshing out a function to be progress.</p>
<p>Don’t have integration tests -&gt; long cycle time.</p>
<hr />
<p>Test: Bird theorem - could get to the end quickly and understand something useful from it when just trying to follow the values, which makes for an impromptu integration test. – short cycle time.</p>
<h2 id="continuous-delivery-run-acceptance-tests-in-a-production-like-environment">Continuous Delivery: Run Acceptance Tests in a Production-Like Environment</h2>
<p><strong>Hypothesis</strong>: Continuous delivery = running acceptance tests in a production-like environment.</p>
<p>(You still have to build and stage all the way to a production-like environment, running unit tests and integration tests along the way).</p>
<hr />
<p>Test: Writing a research report in LaTeX - production-like environment is the LaTeX PDF (not your handwritten sheaf of papers); running acceptance tests - getting feedback from yourself by looking at it from the eye of a reader and from others. – yup.</p>
<p>Test: Negative exemplar - continuous integration where you simply run unit tests – that is not a production-like environment nor are they acceptance tests.</p>
<h2 id="acceptance-test-clear-focus-on-what-matters">Acceptance Test: Clear Focus on What Matters</h2>
<p><strong>Hypothesis</strong>: Failing acceptance test -&gt; you know exactly what needs to be done; you know it matters; need to remember only your current failing acceptance tests.</p>
<p>No failing acceptance test, write unit tests or just implement code -&gt; you don’t know exactly what <strong>needs</strong> to be done; you don’t know if it matters; have to remember a lot of TODOs.</p>
<p><strong>Lesson</strong>: Writing a TODO - instead, make a failing acceptance test for it.</p>
<p><strong>Lesson</strong>: What to do next - make a failing acceptance test pass.</p>
<p><strong>Question</strong>: What is the ideal behaviour for programming (on, say, the phone number problem)?</p>
<hr />
<p>Test: Phone number problem - I knew that <code>10/783--5: neu o&quot;d 5</code> wasn’t working yet and I needed to get on it. – No need to waste time on pointless “design” of beautiful types. Get that test passing ASAP. And I knew it mattered because that was they would test. Just needed to focus on that failing acceptance test.</p>
<p>Test: Scheduler OS HW1 - no failing acceptance test (no real tests at all, in fact) – didn’t know if I was working on the right thing; didn’t know exactly what to do next (?). Had to remember a lot of to-do items in my Org file.</p>
<p>Test: Want to write a to-do item for “handle multiple processes accessing the same virtual memory address” – instead, just add a failing acceptance test and set it aside. Don’t need to keep track of lots of to-do items.</p>
<p>Test: Unsure what to work on right now - take up a failing acceptance test - such as “how to refactor ideas from different essays I’ve written”. – know exactly what to do.</p>
<h2 id="what-to-do-next-unfinished">What to do Next? (?? Unfinished)</h2>
<p><strong>Hypothesis</strong>: Have a dynamically updated list of acceptance tests, choose something that is easy to do -&gt; can find out what to do next.</p>
<hr />
<p><strong>Acceptance test</strong>: What to do next?</p>
<p>Given that I have a bunch of acceptance tests, some of them failing and some of them already passed</p>
<p>when I look for something to do next</p>
<p>then I must be able to find it quickly</p>
<p>when I pick a next action [get techniques from HW1]</p>
<p>then it shouldn’t be a risky decision. If I get it wrong, I should be able to get quick feedback and change within an hour or so. [used ESS to reduce my cycle time.]</p>
<h2 id="dsl-only-what-you-need">DSL: Only What you Need</h2>
<p><strong>Label</strong>: DSL = Set of features that will be needed in a set of use cases.</p>
<hr />
<p>Test: R - will be doing a lot of matrix multiplication and vector manipulation – add that feature.</p>
<p>Test: Negative exemplar - Haskell matrix multiplication - cool, but you also have all these other language features that you don’t need for matrix algebra – extraneous features.</p>
<h2 id="test-your-mechanism-in-isolation-no-need-to-change-the-rest-refactor-using-short-cycle-time">Test your Mechanism in Isolation: No Need to Change the Rest (?? refactor using “short cycle time”)</h2>
<p><strong>Hypothesis</strong>: Work needed to test all branches of a mechanism = work needed to set the desired inputs, get the outputs, and understand the outputs. Everything else is screened off by the input.</p>
<p><strong>Corollary</strong>: Unit tests -&gt; minimum work to set the inputs, minimum time to get the outputs, minimum work to understand the outputs.</p>
<p>Integration tests -&gt; need to do extra work to set the desired inputs because you have to <strong>change</strong> the rest of the program, lot of time to get the outputs since there may be other code before the final output, harder to understand the outputs because they could be caused by any part of the program.</p>
<p><strong>Hypothesis</strong>: Got the type signature for a mechanism (using your integration test), write and test it in isolation -&gt; less work to get to a correct implementation, can exhaustively test all the relevant input configurations -&gt; quick, correct.</p>
<p>Got the type signature for a mechanism (using your integration test), write and test it as part of your overall program -&gt; more work to get to a correct implementation, costly to exhaustively test all the relevant input configurations -&gt; slower, may have errors.</p>
<p>(Note also that isolated mechanisms have smaller interfaces than in-place mechanisms. You’re forced to minimize what you will accept as explicit arguments.)</p>
<hr />
<p>Test: My friend kept changing code within his (already large) functions. I had to keep telling him to extract the code and test it separately. (For example, plotting figures or using an array of arrays or getting all combinations of some configurations.) – changing code was easy enough, even though the interpreter would have been much faster; getting the output took longer because he had to train the classifiers first; didn’t know if the error was because of the code or something else.</p>
<p>Test: I ended up with a script that was costly to test when I was extracting features from a dataset - I couldn’t test the matrix-saving code until I ran the 15-minute script. And if it failed for some trivial reason after 15 minutes, like it did, I was fucked. – pretty easy to change the inputs; took ages to get the output; not too hard to understand the output.</p>
<p>Test: OS HW3 - inverted page table – had to do a lot of work to get its inputs (in fact, I didn’t even separate its interface; I just used it inline wherever I wanted); had to wait for the whole program to run before I could see the output; and had to parse the whole table output to see what was going on.</p>
<p>Test: OS HW3 - FIFO order – didn’t write any unit tests. Had to set inputs only via the tests I ran; had to wait for the output; couldn’t understand the output directly because I wasn’t using first-class reference strings. 1 hour 50 minutes right there.</p>
<p>Test: rectangle numbering in Emacs - wanted it to start from 1 instead of 0, but kept putting it off because it felt like it wouldn’t be worth it to dive into some foreign code and change what I wanted. Just realized that it’s <em>my</em> code that starts from 0. Changed it in a jiffy. – somebody else’s code - have to do a lot of work to set the input (in case configuration variables don’t exist). my code - can just dive in and change whatever I want.</p>
<p>Test: When trying to figure out how to send in a function pointer to my benchmark function, I decided to test it in a stand-alone program first. Fewer changes. In contrast, lots of stuff could go wrong in the benchmark code. – Faster output.</p>
<p>Test: Negative exemplar - wrote a long function when I could have easily extracted <code>hasFoo(post)</code> into its own function. – didn’t implement it in isolation.</p>
<h2 id="first-class-inputs-and-outputs-fast-direct-feedback">First-Class Inputs and Outputs: Fast, Direct Feedback</h2>
<p><strong>Hypothesis</strong>: First-class input -&gt; can set the input without doing any other work.</p>
<p>No first-class input -&gt; have to set the input by changing a lot of other variables.</p>
<p><strong>Hypothesis</strong>: First-class output -&gt; can test the output without doing much work.</p>
<p>No first-class output -&gt; have to test in a round-about manner.</p>
<p>Corollary: Impure function (it can do <strong>I/O</strong>) -&gt; input and output are obviously not first-class.</p>
<p><strong>Corollary</strong>: Extract code into a function -&gt; forced to make your input and output first-class.</p>
<hr />
<p>Test: OS HW1 scheduler – couldn’t test it with a particular configuration of ready processes with different priorities. Had to change the whole system just to get that configuration right.</p>
<p>Test: pipputc – couldn’t really test with first-class inputs. Had to set up processes. Work.</p>
<p>Test: batsmen average – could just test using the 3-over mini-game. Little work. (Though I couldn’t really test it with arbitrary inputs. Had to work with what I was given.)</p>
<p>Test: OS HW1 scheduler – no first-class output of (next process, next ready list) that I could test directly. Had to run all the processes for several seconds and observe their steady-state CPU usage ratio.</p>
<p>Test: pipgetc – could test the output of the pipe without even using another process.</p>
<p>Test: org drill - get session data - it inserts stuff into a buffer instead of returning a string (no first-class output). It also uses <code>(current-time)</code> - not a first-class input. – have to run the whole drill session to set the input; have to look at the log file to check the output.</p>
<p><strong>Test</strong>: Python - had a for-loop in main to try different things with print statements. Extracted it into a function - had to think about building and returning a string instead of just printing to standard output. – first-class outputs.</p>
<h2 id="cycle-time-time-it-takes-to-toggle-and-get-feedback">Cycle Time: Time it takes to Toggle and get Feedback</h2>
<p><strong>Corollary</strong>: Long time to get feedback (<strong>long cycle time</strong>) -&gt; get it less frequently -&gt; more uncertain about your code -&gt; slower.</p>
<p>Short time to get feedback (<strong>short cycle time</strong>) -&gt; get it more frequently -&gt; less uncertain about your code -&gt; faster.</p>
<p><strong>Hypothesis</strong>: Key question - how much time does it take to toggle a feature (or set its value for the first time) and get understandable feedback? In other words, what is the cycle time?</p>
<hr />
<p>Test: Joel Spolsky: – get feedback less frequently and find it harder to code and make more silly errors.</p>
<blockquote>
<p>If the process takes any more than one step, it is prone to errors. And when you get closer to shipping, you want to have a very fast cycle of fixing the “last” bug, making the final EXEs, etc. If it takes 20 steps to compile the code, run the installation builder, etc., you’re going to go crazy and you’re going to make silly mistakes.</p>
<p>– <a href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/"></a></p>
</blockquote>
<p>Test: Joel Spolsky - why developers always want faster hardware – faster cycle time.</p>
<blockquote>
<p>A crucial observation here is that you have to run through the loop again and again to write a program, and so it follows that the faster the Edit-Compile-Test loop, the more productive you will be, down to a natural limit of instantaneous compiles. That’s the formal, computer-science-y reason that computer programmers want really fast hardware and compiler developers will do anything they can to get super-fast Edit-Compile-Test loops.</p>
<p>– <a href="https://www.joelonsoftware.com/2001/01/27/daily-builds-are-your-friend/"></a></p>
</blockquote>
<p>Test: Math proofs - long time to get the output. You have to be the human interpreter and run the proof line by line. Sometimes you may not know either way and may have to wait for an experienced mathematician to give you feedback. You can’t (without automatic theorem provers, which I don’t think most mathematicians use) get the output in an instant. In this regard, we programmers are fortunate. – more uncertain about your math proofs. That’s why they have more than one proof for the same theorem (according to Terence Tao).</p>
<p>Test: OS HW1 - tons of output data. – Can’t really observe variables I care about. Hard to parse the output.</p>
<h2 id="frequent-automated-releases-low-effort-low-cycle-time">Frequent, Automated Releases: Low Effort, Low Cycle Time</h2>
<p><strong>Hypothesis</strong>: One-button change (or one-button execution) -&gt; set inputs with little work. (Zero-button -&gt; zero work!)</p>
<p>Automated release -&gt; get output with little work. It may take time, but you don’t have to do anything manually.</p>
<p>Dashboard -&gt; understand output with little work. The output gets interpreted for you.</p>
<p>Frequent releases -&gt; actually get feedback about your changes and thus have lower uncertainty.</p>
<p>Corollary: Daily build -&gt; zero-button execution.</p>
<p>Corollary: Unit tests -&gt; automated release, easy-to-understand output (“10/11 tests passed.”)</p>
<h2 id="powerful-abstractions-lead-to-quick-tests">Powerful Abstractions lead to Quick Tests</h2>
<p><strong>Corollary</strong>: Powerful abstractions -&gt; less code to set a particular configuration as input to some other mechanism, less work to understand the output (since it is at a high level), may be slower.</p>
<hr />
<p>Test: When testing my pop-by-age code when trying to delete a process’ frames, I needed to get frames that had maximum age. Get maximum of a list (or tree or anything) by age - in Haskell, one word - <code>maximumBy</code> (assuming it implements Foldable). In C, I have to write an explicit for-loop keeping track of <code>max_age</code> and <code>max_i</code>. – less code to set a particular configuration in Haskell; less work to understand the output because it’s just an element (in C, it’s the index of the list); speed doesn’t matter much here.</p>
<h2 id="have-a-hello-world-program-one-button-installation">Have a Hello-World Program: One-Button Installation</h2>
<p><strong>Hypothesis</strong>: Some workflow you want to have for your projects, have a blank project that has all the necessary stuff and just works -&gt; have to work only on adding our project-related features -&gt; less uncertainty, less work.</p>
<p>Some workflow you want to have for your projects, have to install it manually using several steps -&gt; have to work on getting it to run and on adding our desired features -&gt; more uncertainty, more work.</p>
<hr />
<p>Test: Wanted to test <code>pre-commit</code>. Could download their <strong>demo repo</strong> and test the pre-commit hooks with zero fuss. – easy.</p>
<p>Test: Node JS, wanted to use RESTful API, no working blank project - stuck for hours. Abandoned it. – spent all our time trying to get the RESTful API to work even though that wasn’t really the point of our project.</p>
<h2 id="implementing-a-spec-acceptance-tests-vs-unit-tests">Implementing a Spec: Acceptance tests vs Unit tests (??)</h2>
<p><strong>Hypothesis</strong>: Given high-level design, pseudo-code that you know is correct, implement first, write tests later, put only as much confidence in your program as the number of tests you pass -&gt; get correctness first and good module-level design later -&gt; low uncertainty about each function because you already know the pseudo-code, quick.</p>
<p>Given high-level design, pseudo-code that you know is correct, test-driven design -&gt; get correctness and good module-level design at the same time -&gt; low uncertainty, but slow because you have to code step-by-step.</p>
<hr />
<p><strong>Test</strong>: OS HW3 - I’m given the pseudo-code for page fault handling and free frame obtaining. But I’m still taking a long time to “design” the free-frame obtaining code correctly. – slow because you’re trying to get correctness and good design at the same time.</p>
<p><strong>Test</strong>: pipcreate - all possible configurations handled, but it took a long time (~25 hours) before I could pass even one shell integration test. – was going test by test.</p>
<h2 id="cut-through-work-in-the-final-medium">Cut Through: Work in the Final Medium</h2>
<p><strong>Hypothesis</strong>: Experiment on the mechanism directly, get full feedback -&gt; low cycle time because you can toggle and get feedback quickly, can get to the final version faster.</p>
<p>Experiment from within your final medium, get full feedback (by definition) -&gt; slower feedback because you can’t isolate the mechanism (toggling might be tedious, especially if you aren’t skilled in the medium), can get to the final version a bit slower.</p>
<p>Experiment on the mechanism directly, don’t get full feedback -&gt; quick but partial feedback (may not even get full feedback from myself), may not get to the final version quickly.</p>
<hr />
<p>Test: Research report - handwritten notes vs LaTeX notes. – handwritten notes - won’t get feedback from others; may not even get harsh feedback from myself because I don’t look at it from a reader’s point of view. Earlier, I wasn’t skilled enough to think in LaTeX. Now I realize that I can. Done.</p>
<p>Test: Unsure about pointer manipulation or struct indirection in C - tested it in a separate C file that wouldn’t be part of the final product. Helped a lot! – low cycle time because I isolated the mechanism!</p>
<p>Test: Unit tests - they last. – you’re working in the final medium, full feedback, can isolate the mechanism,</p>
<p>Test: Documentation - lasts. – ??</p>
<p>Test: Website - it lasts. – final medium, full feedback (if you release), but at least partial feedback if you write it up (as compared to your journal notes); skilled - so it’s natural by now (see this essay).</p>
<p>Test: Memory via spaced repetition (or just frequency testing) - it lasts. – you get full feedback in the future.</p>
<p>Test: org-autoclock within my Emacs vs a blank Emacs. – got misleading feedback by running it in my Emacs; got full feedback from the user.</p>
<h2 id="quick-and-dirty-vs-carefully-planned-the-fear-of-future-change">Quick and Dirty vs Carefully Planned: The Fear of Future Change (??)</h2>
<p><strong>Hypothesis</strong>: Change is costly, fear that my code or “understanding” of some subject might change -&gt; don’t commit to it (don’t create flashcards, don’t practice the technique, don’t build other ideas on top of it).</p>
<p>Change is costly, feel 100% sure that this fact will remain this way forever -&gt; commit to it (create flashcards, practice the technique, build other ideas on top of it).</p>
<p>Change is cheap, _ -&gt; commit to it.</p>
<p>Question: Why is change so costly? (“Asked in such fashion, the question answers itself.”)</p>
<p><strong>Hypothesis</strong>: High coupling between modules -&gt; change is costly.</p>
<p>Low coupling between modules -&gt; change is cheap.</p>
<p><strong>Hypothesis</strong>: Not completely clean -&gt; I hesitate to commit it (literally).</p>
<p>Completely clean -&gt; I commit it.</p>
<p><strong>Hypothesis</strong>: I need to <strong>reinforce</strong> the action of getting and quick and dirty results for a test, and just as importantly, the action of <strong>refactoring</strong> that code afterwards.</p>
<p><strong>Corollary</strong>: I need to split up my essays into decoupled modules. Instead of saying “don’t couple unrelated things”, make it so that I “can’t couple unrelated things”.</p>
<hr />
<p>Test: My current flashcards - why use salted hash [permanent information] – willing to commit.</p>
<p>Test: how to run an <code>HUnit</code> unit test [permanent information] – willing to commit.</p>
<p>Test: why I dislike do-blocks [permanent information] – willing to commit. Pretty solid theory.</p>
<p>Test: keybinding for <code>find-tag</code> [permanent information] – willing to commit. Pretty solid keybinding.</p>
<p>Test: Negative exemplar - impermanent information - category hierarchy - still not sure how exactly to build a “category hierarchy” and whether that will “really work”. (Only recently figured out how category formation and concept attainment really work. Still not memorized that like hell.)</p>
<p>I seem to have a major block around using any technique I don’t understand <em>completely</em>. So I keep procrastinating till I have refactored each technique to within an inch of its life and placed it in its proper home in a global, flexible, easy-to-remember category hierarchy. This. Is. Retarded.</p>
<p>Explanation: My main worry: what if I change my idea tomorrow of how to form a “category hierarchy”? Then… Then what? Then I would have to narrow down and update the flashcards I created on this topic. (Easy fix: just delete the old ones.)</p>
<p>What else? Not much.</p>
<p>Minimize the effect of a <strong>change</strong> in one model on the other models. Dude, this is basic software engineering. Deal with it. Minimize your interfaces and move on. Decouple your models. Don’t write giant-ass essays.</p>
<p>Test: Decoupled models that I fail to separate - category hierarchy and … everything else. But it still feels like it’s intimately connected. Doesn’t your thinking algorithm affect everything you think?</p>
<p>But category hierarchy and, say, minimizing interface are 100% decoupled. No matter how we humans categorize things, minimizing interface is still going to be the ideal way to decouple a function from other functions, make it easier to understand, easier to reuse, and easier to change. That part really is pretty solid. – I act like I can’t proceed with flashcards for minimizing interface and other programming techniques until I get a handle on category hierarchy.</p>
<p>Test: Hesitated to commit this section because I felt like it could be cleaned up even more. – suggests that submitting not-completely-clean code has been punished, somehow.</p>
<h2 id="carry-the-source-and-mechanism-along-with-the-output">Carry the Source and Mechanism along with the Output</h2>
<p>(h/t The Pragmatic Programmer, chapter 5)</p>
<p><strong>Label</strong>: Source plus mechanism for an output = mechanism that produces the desired output when given the source.</p>
<p><strong>Hypothesis</strong>: Have the generating mechanism and source for an output, lose the output -&gt; can regenerate it (at some cost).</p>
<p>Have the generating mechanism and source for an output, have the output -&gt; can change the source to get different outputs.</p>
<p>Don’t have the generating mechanism or the source for an output, have just the output -&gt; can’t get a different output.</p>
<p>Don’t have the generating mechanism, have the source, have just the output -&gt; can try to port the source.</p>
<p>(Basically, having the source means that you can set the inputs and having the mechanism means that you can generate the output. You have got low cycle time.)</p>
<p>Hypothesis: One-button change -&gt; force you to carry the generating mechanism along with the output. Why? Because it’s easier to change the source material (like LaTeX) than the target material (final presentations).</p>
<hr />
<p>Test: Source plus mechanism - positive exemplar - LaTeX file plus the pdflatex program – can generate various outputs.</p>
<p>Test: Source plus mechanism - negative exemplar - old homework assignment – have the mechanism <code>pdflatex</code> and even the output, but not the source.</p>
<p>Test: Source plus mechanism - negative exemplar - my old Turbo-C++ Breakout clone - have the source for the game but not the mechanism – can’t recreate the game (without looking up some modern port of <code>graphics.h</code>).</p>
<p>Test: Presentation – pretty useless if you lose the source. Have to work hard to recreate the slides (and muck around with image-editing tools).</p>
<p>Test: Presentation - have the professor’s slide - want to include some of the slides or pictures – have to work hard to recreate them. Need to do a Google image search for the pictures.</p>
<p>Test: LaTeX - lost the source for the original homework assignment – had to copy the text and wrestle with the formatting till I got it looking right again.</p>
<p>Test: Plots generated for the output of k-means or other clustering algorithms – can’t change the input slightly (maybe have five clusters or try a modification of the algorithm).</p>
<p>Test: Gifs generated to visualize the steps of the k-means algorithm – can’t change the input slightly, just like above. Don’t have the mechanism either.</p>
<p>Test: Dendrogram generated from hierarchical clustering – can’t change one variable (the distance measured used) to get another dendrogram because I don’t have the source or the mechanism.</p>
<p>Test: Negative exemplar - have a text file containing the number of points I’ve got. Want to change it – can do it effortlessly because I have the source and the mechanism (which is just a text editor to change the text and view it or a shell command to do the same).</p>
<p>Test: What about my mental model of something? – may not have the source books and lectures and personal experiments that formed my mental model; still have the generating mechanism though (my mental learning algorithm), even if it has changed after experience. It’s not a first-class output either. So, I can’t recreate the output in some other mind and I can’t give them the source material for them to recreate it themselves.</p>
<p>Test: Citations in a book or paper backing some fact – can re-read the paper and get the actual fact.</p>
<p>Test: Citations plus quotation – don’t even have to re-read the cited paper (unless you’re suspicious); you can read the source quote itself.</p>
<h2 id="isolate-the-features-youre-most-uncertain-about">Isolate the Features you’re Most Uncertain about</h2>
<p>Hypothesis: Isolate the features you’re most uncertain about and implement them in reverse order -&gt; minimum time and worry.</p>
<hr />
<p>Test: For example, I’m super-uncertain about the theoretical questions in my assignment – wait until later.</p>
<p>Test: Also not sure about how to use pandas or how to prune. Not fully sure how to handle missing attributes either. – wait.</p>
<p>Test: Negative exemplar - I know exactly how to implement the vanilla version – do it right now.</p>
<h2 id="dont-bite-off-more-than-you-can-chew">Don’t Bite Off More than You can Chew</h2>
<p><strong>TODO</strong>: Write an essay about releasing early and how you try to optimize constraints that are not worth optimizing. How should you ideally approach the matter? How do you get stronger?</p>
<h2 id="key-to-peace-of-mind-thorough-fine-grained-testing">Key to Peace of Mind: Thorough, Fine-grained Testing</h2>
<p>Hypothesis: The way to be confident about a system is to test for exactly the properties you want it to have, including past behaviour. That way, if the tests pass, you know you’re golden.</p>
<p>If you don’t test for your desired behaviour or don’t test for regression, you will always be worried.</p>
<p>Why? Because the positive and negative exemplars from your tests would narrow down the causes of things for you and remove your ambient worry about everything else.</p>
<hr />
<p>Test: [2018-07-10 Tue] Earlier, I didn’t have positive exemplars of how to render a post. Full of worry.</p>
<p>Test: [2018-07-10 Tue] Now, I do. No worries.</p>
<h2 id="to-prevent-regression-change-only-within-your-if-condition">To Prevent Regression, Change only within your If-Condition</h2>
<p><strong>Hypothesis</strong>: If you add code <strong>only</strong> within the conditional logic for your feature, you can be confident that you haven’t affected any other feature’s behaviour.</p>
<p>If you add code without a conditional check for your feature, then you have to confirm that the other features aren’t affected too much by your change. The more features there are, the more time this takes.</p>
<p><strong>Lesson</strong>: Always add new code under an if-condition for your feature.</p>
<p>Corollary: If you keep all your features under separate condition checks, you can switch among them with just one button.</p>
<p>If you don’t, you have to go and manually change the shared code that must be different for each of them.</p>
<p>Corollary: As long as you change code within an if-condition for your feature, you know you won’t regress other features. However, to ensure correctness for your feature, you still have to handle all possible paths that lead to your output. So, if there are two paths, you need to add your code under both of them. (Ideally you would merge them first.)</p>
<p>Corollary: If you want to change common code, first move it under a default if-condition and then add your changed code in a new if-condition for your feature.</p>
<p><strong>Corollary</strong>: Code is hard to change when it’s used by multiple features and when you don’t add separate if-conditions (or can’t add them because you don’t know the set of features that use this code).</p>
<p>Corollary: OOP abstracts these if-checks by having the conditional logic for a particular feature at all points along the data flow within one class.</p>
<p>Corollary: If you add debug code only under a DEBUG check, then you can be confident that that code will be run only when debugging is turned and will not affect the normal logic.</p>
<hr />
<p><strong>Test</strong>: [2018-07-29 Sun] If you want to disable a “Submit” button until the form data is valid, you have to worry not only about disabling it only for your feature but also not accidentally disabling or enabling it for other features that use the same form.</p>
<p>If you add some conditions that apply only to your feature, then you can be confident that you’re not affecting any of the logic for the remaining features (since they will never even enter your code branch).</p>
<p>However, if you add some code without checking specifically for your feature, then it would be executed even for other features and thus you might affect their behaviour.</p>
<h2 id="fast-correct-duplicated-code-vs-slow-regressive-succinct-code">Fast, Correct, Duplicated Code vs Slow, Regressive, Succinct Code</h2>
<p><strong>Hypothesis</strong>: If you handle each type of input separately, you will make progress easily (because you will have few constraints at each point) and you won’t break existing features (because you won’t touch other branches) but you will duplicate code across the branches.</p>
<p>If you try to handle multiple inputs in the same branch, you will have trouble making progress (because you will have a lot of constraints to handle) and you may break existing features (because a change within one branch will affect multiple existing features) but you will have succinct code.</p>
<hr />
<p>Observation: Duplication vs regression strikes again! Handling a new case by itself is pretty trivial (if tedious). But handling the new case without affecting the else case too much is very hard. No wonder I’ve been stuck on this.</p>
<p>Observation: When you duplicate and change, you get to start from scratch. You have far fewer constraints. Much more peaceful.</p>
<h2 id="coupled-tests-are-harder-to-pass">Coupled Tests are Harder to Pass</h2>
<p>Hypothesis: When you have several tests you must pass but they don’t correspond to different branches in your code, you will find it harder to code because at each point you will have to satisfy multiple constraints.</p>
<p>Hypothesis: When you satisfy multiple constraints with the same branch of code, it means that your solutions don’t <strong>compose</strong>.</p>
<p>If you can handle the constraints separately, that means you can compose the results.</p>
<hr />
<p>Test: CSS - a single row in a form should handle short text, long text, hovering, clicking elsewhere, etc. with the same CSS config.</p>
<p>Test: Applicative parser - handle the two sum types separately and compose using <code>&lt;|&gt;</code> – your solutions compose.</p>
<p>Test: Constraint - the meta text has to align with the item text in a list. But the item text has to be centered in line with the circle at the start of the list. – couldn’t do it.</p>
<h2 id="mocks-give-you-fine-grained-feedback-for-your-ui">Mocks give you Fine-grained Feedback for your UI</h2>
<p>Hypothesis: Use the design mocks to get fine-grained feedback about your UI design.</p>
<h2 id="change-only-data-that-this-feature-owns">Change Only Data that this Feature Owns</h2>
<p>Question: What about side effects? Can’t you inadvertently affect other features by changing common variables?</p>
<p><strong>Hypothesis</strong>: If you change data that belongs to your feature, you can be confident that you won’t affect the behaviour of other features.</p>
<p>If you change common data, then you have to check that other features aren’t affected.</p>
<p>Corollary: OOP separates data for different features by keeping all of a feature’s data within the same class.</p>
<p>Corollary: Pure functions mean that you never change data used by other features.</p>
<p>Global mutable variables mean that you change data used by other features.</p>
<h2 id="to-prevent-overgeneralization-have-a-default-else-case">To Prevent Overgeneralization, Have a Default Else Case</h2>
<p><strong>Hypothesis</strong>: Having a default else-case for your code will force you to specify the exact conditions under which your feature is applicable and, importantly, all the other conditions under which it is not known to be applicable. Even if you find out that it generalizes to other areas, you can expand the if-condition while still keeping the default else-case. This way you will prevent yourself from overgeneralizing.</p>
<p>This is the same idea as eliminating potential factors only after seeing them toggled in some positive exemplar.</p>
<h2 id="editor-wars">Editor Wars</h2>
<p>Observation: Atom (Nuclide) seemed highly adequate during my internship. No real complaints.</p>
<h2 id="linters-gives-you-fast-feedback">Linters gives you Fast Feedback</h2>
<p>Test: Stopped using a field in a Relay fragment – <em>immediately</em> got a lint warning saying that the field was unused!</p>
<h1 id="changing-a-program-and-reusing-code-minimize-the-interface">Changing a Program and Reusing Code: Minimize the Interface</h1>
<h2 id="implement-in-a-new-branch-or-implement-in-isolation">Implement in a New Branch or Implement in Isolation</h2>
<p>Hypothesis: If you want to add a new feature, implement it in a new if-branch.</p>
<p>If you want to extend the output within an if-branch, implement the change in isolation and move it in.</p>
<h2 id="toggle-behind-an-interface-with-one-button">Toggle behind an Interface with One Button!</h2>
<p><strong>Hypothesis</strong>: Feature you want to toggle, hide the current feature behind an interface and toggle completely with one button -&gt; handle each use of the interface (read or write), don’t mix and match between the features, quick -&gt; no uncertainty, no errors.</p>
<p>Feature you want to toggle, don’t hide the current feature behind an interface or don’t toggle completely or don’t have just one button -&gt; may miss places where it is used, will take longer -&gt; uncertainty, errors.</p>
<p><strong>Hypothesis</strong>: Searching for all uses of the thing you’re toggling leads to recursive toggles.</p>
<hr />
<p><strong>Test</strong>: OS HW3 - massively confused. Don’t know how to implement <strong>page-directory switching</strong>. Don’t know what could go wrong. Don’t know all the places where page-directory could be <strong>used</strong> (and thus be messed up by me). - Try getting one integration test. If it breaks, you can always revert back to confusion. – It worked! All I had to do was add an entry to procent, initialize it during create, have pointers to the global page tables, set up procent for nullproc too, update the page directory entry in <code>page_fault_handler</code>, and simply load the directory upon context-switch. Basically, set up process page directory correctly for all processes (initialize, pointers to global page tables, null process); update it when needed; load it when needed.</p>
<p>Ah, fuck. I should have hidden <code>process.page_directory</code> and made them come for it. That way I would have known who wanted to read it and who wanted to write it. What a way to drive in an age-old lesson - program to an interface, not an implementation. I forgot it when it came to OS development in C.</p>
<p>Explanation: I had the integration test of two processes writing to the same virtual address. When it came to the first 4096 pages, both the alternatives would work the same. They would differ only when going beyond the initial pages. The default alternative would overwrite one of the values in the null process’ page directory. My new per-process page directory alternative would have separate page directories for them and thus write separate values. So, pdbr should point to the current process’ page directory. Also, as per the integration test, the page fault handler should also use the current process’ page directory.</p>
<p>Hmm… I should basically have grepped for <code>page.*directory</code> and looked at everything that depended on it.</p>
<p>Look at the interface for everything.</p>
<p>The kernel’s view of the “page directory” - <strong>all</strong> it knew or cared about was CR3. So, if I wanted it to use a different page directory, I needed to change CR3. Where? At the end of <code>resched</code>.</p>
<p>Similarly, the OS’s view of the page directory - right now, everything depended directly on <code>page_directory_nullproc</code>. That was the only page directory in existence. I wanted to propose an alternative to it - a per-process page directory. So, I should have hidden it behind an interface and then toggled to the per-process page directory without anyone being any wiser.</p>
<p>Actual explanation: Feature I wanted to toggle - global page directory vs per-process page directory; didn’t hide the global page directory behind an interface -&gt; missed places where it was used (like the page fault handler and resched).</p>
<p>Test: Didn’t hide procent behind an interface when toggling the feature “no page_directory field” to “page_directory field” -&gt; missed places where it was used (like create, initialize, and global initialize).</p>
<p>Test: I forgot to update nullproc’s page directory. Why? Because I updated procent without hiding it behind an interface. So, I didn’t catch all its users, in particular <code>initialize</code>. I should have looked for everything that initialized procent (since nothing would read or write to <code>page_directory</code> yet). – Caused errors.</p>
<p>Test: When toggling global page directory with per-process page directory, I have to toggle the definition of procent, which requires me to seek all uses of procent. Similarly, toggling memlist involves toggling meminit, which requires finding out all the places where meminit is called.</p>
<h3 id="old---modularity-make-changes-behind-an-interface">OLD - Modularity: Make Changes behind an Interface (??)</h3>
<p><strong>Hypothesis</strong>: Identify what changes you want to make and turn those hotspots into an interface. Then, implement the new module you want behind that interface. Nothing in the rest of the system has to change.</p>
<p><strong>Hypothesis</strong>: List of changes -&gt; properties for the category definition.</p>
<p>For example, we define the categories of “greedysubset” and “forwardfitting” by what they do in their inner loops. (Otherwise, they’re both the same.)</p>
<p>Corollary: Don’t anticipate making any changes -&gt; no need to use an interface.</p>
<p>Question: What about code reuse?</p>
<p><strong>Hypothesis</strong>: Coding in a modular program -&gt; you will change stuff <em>only</em> behind the interface. Won’t have to touch the rest of the system.</p>
<p>Hypothesis: Refactoring -&gt; will change the rest of the system to use your new interface.</p>
<p>Observation: OS HW1 - I changed only the scheduler code and looked only at the scheduling output (not the memory usage or pipe behaviour).</p>
<p><strong>Hypothesis</strong>: Change behaviour of a big system &lt;- choose output property, narrow down the parts you want to change into an interface, toggle to your heart’s content.</p>
<p><strong>Hypothesis</strong>: Focus on just one small property (like being unreactive) and figure out what you need to change to get it -&gt; minimum interface (wrt that property).</p>
<h2 id="small-interface-expose-only-one-thing-at-a-time">Small Interface: Expose Only One Thing at a Time (??)</h2>
<p><strong>Hypothesis</strong>: Small interface -&gt; easier to use.</p>
<p>Large interface -&gt; harder to use.</p>
<hr />
<p>Test: Haskell monad transformers - sound scary, but are surprisingly usable.</p>
<p>For example, the implementation of ReaderT may look intimidating:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">ReaderT</span> r (<span class="ot">m ::</span> k <span class="ot">-&gt;</span> <span class="fu">*</span>) (<span class="ot">a ::</span> k)
  <span class="fu">=</span> <span class="dt">ReaderT</span> {<span class="ot">runReaderT ::</span> r <span class="ot">-&gt;</span> m a}</code></pre></div>
<p>But look at its interface: you can use it as a functor or an applicative or a monad. So, if you want to use <code>applyDiscount :: Float -&gt; ReaderT Config m Float</code> twice, you can just say <code>applyDiscount &lt;=&lt; applyDiscount</code> without worrying about anything else because <code>ReaderT Config m Float</code> is just <code>m1 Float</code>.</p>
<p>Also, when defining <code>applyDiscount</code>, if you have a function <code>discount :: Float -&gt; Float -&gt; Float</code> that accepts an amount and reduces it by the given discount rate, then you can use <code>asks discountRate :: Monad m =&gt; ReaderT Config m Float</code> and then <code>fmap (discount givenAmount)</code> over the value to get the discounted amount within the ReaderT monad. You’re programming to the interface of functors and monads.</p>
<h2 id="abstract-dont-accept-all-the-information-youre-given">Abstract: Don’t Accept all the Information you’re Given</h2>
<p><strong>Hypothesis</strong>: Desired output, accept all the information given (deal with a concrete type) -&gt; have to deal with more input configurations.</p>
<p>Desired output, abstract the inputs using the possible outputs (deal with an abstract type) -&gt; have to deal with fewer input configurations.</p>
<hr />
<p>Test: <code>findPerson</code> vs <code>find</code>. – Have to deal with Person being male or female.</p>
<h2 id="abstract-as-much-as-the-goal-allows-use-cases---new-hypothesis">Abstract as much as the Goal allows (?? use cases - new hypothesis)</h2>
<p><strong>Hypothesis</strong>: Goal doesn’t ask about the specifics of the input type, abstract the input type -&gt; simpler, more reusable, easily changeable code; think the answer is pretty simple.</p>
<p>Goal doesn’t ask about the specifics of the input type, keep the input type concrete -&gt; more “complex”, less reusable, hard-to-change code; think the answer must be “complex” and try weird stuff.</p>
<p><strong>Hypothesis</strong>: The use cases are determined by the goal. If in no use case you will need part of the input, ignore it. Or if you can apply a function that will cover all of the uses cases for that part, use it.</p>
<hr />
<p>Test: Wanted to concatenate all the <code>Parser [a]</code> in a list <code>[Parser [a]]</code>. Was stuck for 24 minutes doing that because I got confused by the <code>Parser</code> bit and thought that the solution would be something “complex” like <code>(fmap . fmap . fmap ) concat pxs</code> (Yes, I actually tried that). – Got unnecessarily intimidated. Once you abstract <code>Parser</code> as <code>Monad m</code>, your job was much easier.</p>
<p>Test: But the moment I thought of the problem above as concatenating all the lists within <code>[m [a]]</code>, I got the answer immediately: <code>sequence</code>. – Felt pretty simple.</p>
<h2 id="minimum-interface-at-speed-more-hypotheses">Minimum Interface at Speed: More Hypotheses (??)</h2>
<p>want to handle a new input configuration (add a new feature) - get a failing test first -&gt; speed (no abstract thinking).</p>
<p>new feature, pure function, write automated failing test -&gt; speed.</p>
<p>new feature, impure function, manual failing test -&gt; speed.</p>
<p>failing test - pass it by writing a quick and dirty chain of function calls, no branches -&gt; correctness, speed.</p>
<p>test passed - refactor your code -&gt; speed, quality (more understandable, reusable, and modifiable).</p>
<p>manual test passed - write automated test -&gt; speed, quality. (??)</p>
<p>writing code - do you have a failing test for it? -&gt; write useful code.</p>
<p>question about one small part, write a test in a scratch file -&gt; get answer quickly (since you’re only changing a few variables instead of the whole original program).</p>
<h2 id="dry-dont-expose-irrelevant-things">DRY: Don’t Expose Irrelevant Things (??)</h2>
<p>Type: Change in interface -&gt; amount of work needed, amount of uncertainty (and thus possible errors).</p>
<p><strong>Hypothesis</strong>: Interface needed for goal, expose interface that’s just as small -&gt; have to change only when the interface changes; guaranteed to be consistent.</p>
<p>Interface needed for goal, expose interface that’s larger -&gt; have to change even when the change in the interface is outside the interface needed; outside changes may make things inconsistent.</p>
<hr />
<p>Test: Magic constant “1024” in paging - it has the same cause everywhere (it’s the size of a page and a page table and a page directory). – If that changed to 2048, I’d have to change a lot of code manually. (Ideally, I should have a separate variable for the size of a page, a page table, and a page directory and, if necessary, assert that they were all equal.) Here, it’s a value (1024) that has the same cause everywhere. Basically, the code doesn’t care about the actual value of the constant, but it uses it anyway. So, when the constant changes, the code has to as well. Also, I might forget to update the constant everywhere (maintain the correlation between all of the values) and thus introduce bugs.</p>
<p>Test: Function <code>spk-split-paragraph-by-semicolon</code> - if I repeat the algorithm in the doc string (split the string by “;” and then join with newlines), then if I have to change the algorithm for speed, then I would have to change the doc string as well. – duplication of effort because of same cause. Here, it’s the documentation and implementation that have the same cause (the algorithm). The algorithm is needed for the function implementation. Ideally, the documentation should not even know what algorithm is under the hood. But if it does, then it will have to change each time the implementation changes.</p>
<p>Test: For-loop to initialize a page table - caused by the structure of the page table. – If the structure changes, I’d have to update in a lot of places. The user code doesn’t need to know about the structure, but it does anyway. May set some values the wrong way - inconsistency and thus bugs.</p>
<p>Test: From The Pragmatic Programmer - line segment class with fields start, end, and length. – When a user changes the start and end of a line segment, he also has to change the length. So, you’re exposing too much information. The user code doesn’t need to know about all three (as fields). It should just have a constructor and a <code>length</code> method (or field - it shouldn’t know the difference). Also, may set length to an inconsistent value - bugs.</p>
<h2 id="toggle-behind-an-interface-no-need-for-fine-grained-feedback">Toggle Behind an Interface: No Need for Fine-Grained Feedback</h2>
<p><strong>Hypothesis</strong>: Change in the expected interface, have tests or type-checker that can validate each change, change all uses -&gt; feedback about every change -&gt; can change one at a time; no unnecessary changes; no inconsistent changes.</p>
<p>Change in the expected interface, no tests or type-checker that can validate each change, change all uses naively -&gt; you’re changing outside the interface you <strong>expected</strong> -&gt; have to change things unnecessarily; have to change everything before you get the correct output; may make inconsistent changes.</p>
<p>Change in the expected interface, toggle behind an interface -&gt; not changing the interface you expected -&gt; don’t have to change things; consistent; don’t need fine-grained feedback.</p>
<p><strong>Corollary</strong>: Change lots of things -&gt; need fine-grained feedback to reduce uncertainty.</p>
<p>Change behind an interface -&gt; don’t need fine-grained feedback.</p>
<p><strong>Corollary</strong>: Toggle behind an interface or have some other source of fine-grained feedback (like a type-checker) -&gt; don’t need a huge number of unit tests.</p>
<p>Don’t toggle behind an interface and don’t have some other source of fine-grained feedback (like a type-checker) -&gt; don’t need a huge number of unit tests.</p>
<p><strong>Hypothesis</strong>: Basically, you’re not changing the mechanism at all. So, you don’t need feedback to make sure you aren’t breaking it.</p>
<p><strong>Hypothesis</strong>: Least number of tests (feedback) needed - well-decoupled code.</p>
<hr />
<p>Test: Change 1024 to 2048 – have to change things unnecessarily. May miss some spots.</p>
<p>Test: Suppose the name of the function <code>foldr</code> is changed to <code>reduce</code> - how much work would you have to do? – assume <code>foldr</code> is now not even available. So, your type-checker will point out every place where you still use <code>foldr</code>. Easy enough. No inconsistent or unnecessary changes.</p>
<p>Test: Want to change page directory from the global page directory to a per-process page directory. Change the <code>get_page_directory</code> function to return the per-process page directory. – don’t have to change code; guaranteed to cover all the places where it is used.</p>
<p>Test: Want to change all uses of <code>initialize_page_directory</code> once you change its input parameters - can grep for the function – fine-grained feedback about every use.</p>
<p>Test: Ruby guys have tons of unit tests. – no type checker to warn you about inconsistently-used function names or arguments or return values - so changing a function’s type signature is pretty risky. (Can’t they toggle behind an interface? I guess you have to abstract things well for that. Not sure.)</p>
<p>Test: Haskell guys usually don’t have tons of unit tests. – type checker tells you about each use of a function; changing a function’s type signature is not risky. Can abstract well into conventional interfaces - <code>sort</code> wants just an <code>Ord</code>, <code>fmap</code> needs just a <code>Functor</code>, and most common functions deal with just lists. (Not fully sure of this.)</p>
<h2 id="minimum-interface-obsolete">Minimum Interface (Obsolete)</h2>
<p><strong>Hypothesis</strong>: Get just the relationship between the input and the desired output -&gt; minimum interface.</p>
<hr />
<p>Test: Lines from <code>BufferedReader</code> – don’t care about anything else it might produce.</p>
<p>Test: List of <code>TransactionOperation</code> from list of strings – don’t care about how to get a permutation of that list or whatever.</p>
<p>Test: Negative exemplar - have the raw <code>BufferedReader</code> itself – large interface.</p>
<h2 id="new-interfaces-considered-evil">New Interfaces Considered Evil</h2>
<p><strong>TODO</strong>: Write an essay on “New Interfaces Considered Evil”. (Reference Gabriel.)</p>
<h2 id="oop-gives-methods-too-much-information">OOP gives Methods Too Much Information</h2>
<p>Hypothesis: An object allows each method access to all its fields. That probably leads to large interfaces and too much information that makes the methods hard to reason about.</p>
<h2 id="lift-plain-functions-to-deal-with-legacy-code">Lift Plain Functions to deal with Legacy Code?</h2>
<p>Hypothesis: To change some legacy code, maybe write plain functions (in isolation) and then insert them where necessary.</p>
<hr />
<p>Test: [2018-07-30 Mon] Disable the submit button unless the form is valid - if I had plain types, I could say just <code>if(!isValid(form)) disableButton = true; else disableButton = false;</code> or whatever. But I don’t have plain types. I have legacy code.</p>
<p>First, I need to search for the part of the code that enables or disables the button. Then, I need to get into the branch that deals with my feature. And then I need to call the <code>isValid</code> function.</p>
<p>So, the pure part of the feature change is the <code>isValid</code> function. I can write that without reference to any of the legacy code. It then becomes a question of where to insert that function call.</p>
<h2 id="reversible-change-use-the-same-composition-operator-to-invert">Reversible Change: Use the Same Composition Operator to Invert</h2>
<p><strong>Hypothesis</strong>: What makes a change easily reversible: you should be able to reverse it without learning a <strong>new interface</strong>. Basically, you should be able to revert it using the <strong>same</strong> composition operator.</p>
<p>The key advantage of having an inverse is that a value <strong>within</strong> the same type is enough to invert your original value. You don’t need to create a new type. This is what you get when your operation is closed and invertible.</p>
<hr />
<p>Test: Positive exemplar - 1 + 2 = 3; 3 + -3 = 0. – you use the <strong>same</strong> composition operator to create or invert a value.</p>
<p>Test: Positive exemplar - <code>reverse . reverse == id</code> – same composition operator to invert.</p>
<p>Test: Early change - wanted to revert it. How? Removed the file alright, but I still had to run the rebuild command. Unnecessary new interface! (But that’s what I did to install it in the first place, so I can’t complain too much) – undecided.</p>
<p>Test: Negative exemplar - <code>push</code> 3 on top of the stack. To remove 3, you have to use <code>pop</code>. – different interface to invert a value.</p>
<p>What if you could use <code>push (inverse top)</code> or something? (But you would have to know the value on top to push its inverse.)</p>
<p>Test: <code>comment-dwim</code> . <code>comment-dwim</code> == id – easy to invert.</p>
<p>Test: What I’d like to invert effortlessly - added a bunch of debug statements. Now revert them all.</p>
<p>Similarly, tried out one CSS combination. Now, get back to the original.</p>
<p>Can’t you do that with version control?</p>
<h2 id="types-narrow-your-interfaces">Types Narrow your Interfaces</h2>
<p><strong>Hypothesis</strong>: Types narrow your interfaces.</p>
<p>They turn “don’t do that” into “can’t do that”.</p>
<p>For example, if all you know is that the React component tree is <code>Foldable a</code>, you can just fold over it with different monoids. That’s all. Can’t access just one part of the tree.</p>
<h2 id="why-novel-interfaces-proliferate">Why Novel Interfaces Proliferate</h2>
<p>Hypothesis: Because it gives you a competitive advantage over others and prevents you from becoming a commodity. And perhaps also because you can deliver new features.</p>
<h1 id="debugging-1">Debugging</h1>
<h2 id="debugging-look-at-the-diffs">Debugging: Look at the Diffs!</h2>
<p><strong>Hypothesis</strong>: don’t know the cause of something, have the source code and can run interventions (aka <strong>debugging</strong>), look at your <strong>diff</strong>, list all your assumptions or toggle your diff till you get a “yes” -&gt; figure out which assumption is causing your error.</p>
<p>debugging - read your diffs line by line -&gt; notice what changes you made that could have caused the error.</p>
<p>debugging - just try different inputs without looking at the diff -&gt; find it harder to come up with the right inputs.</p>
<p>Hypothesis: If you’re not sure where your program fails, set printfs at different points. That will narrow it down faster than one printf at a time.</p>
<hr />
<p>Test: Tried writing at an address but the CR2 value showed some other address. Turned out that I had interpreted the output as hex when it was actually a long int! – toggling my diff would have helped.</p>
<p>Test: Re-read my buggy page directory setup code - discovered my errors. – read the diff line by line.</p>
<p>Test: Process wasn’t receiving message from parent. Tried lots of variations. Finally realized that I wasn’t even resuming the process. – didn’t look at the diff.</p>
<h2 id="dont-debug-fall-back-to-a-positive-exemplar-duplicate">Don’t Debug: Fall back to a Positive Exemplar (duplicate)</h2>
<p><strong>Hypothesis</strong>: Test passes -&gt; positive exemplar (hopefully with all necessary causes).</p>
<p>Test fails, create a smaller exemplar that is positive and extend it to the larger exemplar -&gt; know what works (necessary causes) and what doesn’t; faster.</p>
<p>Test fails, debug by toggling here and there -&gt; don’t know what works (necessary causes) and what doesn’t; slow.</p>
<hr />
<p>Test: [2018-09-16 Sun] Spent half an hour debugging why I couldn’t clone a bare Git repository from the server. Turns out I used <code>/home/foo</code> instead of <code>/homes/foo</code>. Dammit! – A simple, detailed comparison with a past positive exemplar would have solved the problem.</p>
<h1 id="understanding-uncertainty-about-the-program-output">Understanding: Uncertainty about the Program Output</h1>
<h2 id="how-to-tackle-a-daunting-problem">How to Tackle a Daunting Problem</h2>
<p><strong>Hypothesis</strong>: Get as close a positive exemplar as you can and take a diff to do what you want to do. You will be able to solve your problem more easily than if you try to figure it all out from scratch (?).</p>
<p>I suspect you have to know how to change the input based on a change in the desired output.</p>
<hr />
<p>Test: Need to implement a bunch of classes and methods. Feel like it’ll take a ton of work to do it all. But I suspect that if I can do just one of them right, then the rest of them would be easy to do just by comparison. Also, I can get the first one done by comparison with the sample program mentioned in the wiki (even though I don’t have a executable program for that one). – get as close a positive exemplar as you can.</p>
<h2 id="complex-diffs-toggling-a-lot-of-variables">“Complex” Diffs: Toggling a Lot of Variables</h2>
<p><strong>Hypothesis</strong>: Diff toggles a lot of variables -&gt; hard to predict what the output will be.</p>
<p>Diff toggles a few variables -&gt; easier to predict what the output will be.</p>
<hr />
<p>Test: Lots of changes in my Emacs folder - don’t know what leads to what. – lots of variables changed - I took .emacs.d/ off the load-path, moved my personal elisp files into one folder, deleted the old lisp packages I was storing manually and instead got them from the package manager, and used <code>(require 'foo-feature)</code> instead of loading its file manually. Any of them in any combination could cause problems!</p>
<p>Test: Exactly one section changed in my one-button change essay - I know exactly what that does to the essay. – “look at diffs” - ok that affects my model of how to debug something, but not my ideas about refactoring or programming to an interface.</p>
<h2 id="confusion-look-at-the-diffs">Confusion: Look at the Diffs!</h2>
<p><strong>Corollary</strong>: Went from not confused to confused, get the specific changes (<strong>diffs</strong>) that caused the problem -&gt; need to learn about the effects of a very few variables.</p>
<p>Went from not confused to confused, don’t know which specific changes caused the problem -&gt; feel like you need to learn about a lot of variables.</p>
<p><strong>Lesson</strong>: Start with something you’re not confused about and take it from there.</p>
<p><strong>Hypothesis</strong>: Confused, ask for a positive and negative exemplar -&gt; get clear about the inputs and outputs.</p>
<hr />
<p>Test: Was following along the causal RL lecture till the q_i’s started coming in. Basically, I went from “not confused” to “confused”. Earlier, my mental model - my program - passed the tests of predicting the correct answer. But now, it couldn’t. So, I needed to look at the diff and figure out which change broke my model. – Got the specific diff that broke my model.</p>
<p>Test: Confused about all causality papers. Don’t think I’ve been un-confused about “all causality papers”. Feel like I will have to read a lot of papers to become un-confused about “causality papers”.</p>
<p>Test: OS HW3 - really, really confused about what to do. No clear idea about how to proceed. – Okay. Narrow down the diff. What worked, I think, was to have a concrete walk-through. That told me where there could be potential hotspots (for example, if there were no free frame available, I’d have to replace a page).</p>
<p>Test: Goals for 2018 - didn’t know what caused my indecisiveness. Tried to think of a case where I wasn’t indecisive. Got it. – Realized that I was changing too many variables.</p>
<h2 id="differing-predictions-well-look-at-the-diffs">Differing predictions: Well, Look at the Diffs!</h2>
<p><strong>Hypothesis</strong>: Don’t know the cause of something, don’t have the source code and can’t run interventions, come up with possible causes - get their differing predictions -&gt; figure out the right cause.</p>
<p>Want to know where I know more than others - get their differing predictions (by taking the diffs of our proposed explanations or just the books we’ve read) -&gt; figure out problems that they just can’t solve.</p>
<hr />
<p>Test: Why did Goldenfold say “5 more minutes of this and I’ll get mad”. Two possible causes. We can look at their differing predictions to get feedback. – don’t have the source code and can’t run interventions; but can look at differing predictions.</p>
<p>Test: What do I know about “cognitive psychology” that others don’t? How to get differing predictions? They talk about “complex neural networks” and “network of ideas”. I don’t (I know about how it’s cue-memory associations all the way down). They talk about how forgetful they are, I don’t (I know about the exponential decay curve). They think re-reading is good enough. I don’t (I know that you need to test for recall). – Their proposed explanations are different from mine in these ways. From these, I can come up with differing predictions - people who test themselves will actually learn things.</p>
<h2 id="understanding-testing-it-with-different-inputs">Understanding = Testing it with Different Inputs? (??)</h2>
<p><strong>Hypothesis</strong>: Some output depends on a lot of other variables or takes a long time to give the output or gives output that is hard to isolate -&gt; have to do a lot of work to test and understand it with different inputs (aka “understand” it).</p>
<p>Some output depends on just a few other variables and takes a short while to produce output and gives isolated output -&gt; have to do less work to test it with different inputs.</p>
<p><strong>Corollary</strong>: If that is true, then the explanations that will lead to a lot of understanding will be those that let you change inputs without much effort, get the output quickly, and isolate the cause easily. They would let you answer “what if” questions easily.</p>
<h2 id="large-diff---high-uncertainty-need-to-update-based-on-the-question">Large Diff -&gt; High Uncertainty! (?? need to update based on the question)</h2>
<p><strong>Hypothesis</strong>: Large diff (change a lot of variables), fail -&gt; think that any of those variables would make you fail; so, lots of possibly-wrong beliefs (high uncertainty).</p>
<p>Small diff (change one variable), fail -&gt; think that that one variable makes you fail, which is true; very few possibly-wrong beliefs (low uncertainty).</p>
<p><strong>Corollary</strong>: Keep your diffs small -&gt; have fewer possibly-wrong beliefs.</p>
<p><strong>Corollary</strong>: No positive exemplar, only negative exemplars -&gt; super-large diff -&gt; lots of possibly-wrong beliefs about what is possible.</p>
<p><strong>Corollary</strong>: Only positive exemplars, no negative exemplars -&gt; consider the opposite viewpoint that you’ve seen only negative exemplars for <em>beating</em> the thing and will thus think that anything untested will still not be able to beat it.</p>
<p><strong>Question</strong>: Large diff, correct output -&gt; will you think that all the variables in the diff were necessary? (when you haven’t seen any small diff work?). Think about how I got intimidated by big words.</p>
<hr />
<p>Test: Right now, when trying to test my representative test idea on causal decision theory, I was going for a massive negative exemplar and getting completely confused. – didn’t know which variable (difficulty, subject matter, amount of text, etc.) caused my confusion. Felt like “representative tests” were useless. Like they would fail on any input - no matter how small the text or what the subject matter or how difficult the topic. But I didn’t really have evidence for all of those other beliefs - they were possibly wrong.</p>
<p>Test: Ran on a treadmill when I was young. Completely out of breath. Felt like cardio was not for me. – Jumped to the conclusion that the target variable (me) could not do any cardio at all, even though I had changed other variables like difficulty, duration, etc. That is, [Pradeep + tough cardio -&gt; couldn’t do it] became [Pradeep + any cardio -&gt; can’t do it]. Felt that any type of cardio would be too hard for me.</p>
<p>Test: Now, I can do cardio for hours (and have actually done so). But I can’t quite stretch my legs or jog for long without losing my breath. – Came to the right conclusion that I could indeed do a lot of cardio. That is, [Pradeep + tough cardio -&gt; couldn’t do it; Pradeep + reasonably tough cardio -&gt; could do it] became [Pradeep + reasonably tough cardio -&gt; can do it]. Even now, I think that anything to do with long-distance running is too hard for me. That’s because I haven’t got any positive exemplars between hard cycling and running. Way lower uncertainty!</p>
<p>Basically, I need to look at the difference between the positive and negative exemplars. Earlier, it was [very, very easy cardio -&gt; can do it; very tough cardio -&gt; can’t do it]. But there are a lot of variables that differ between them. For example, the tough cardio involved running, which I had never done. It didn’t consider cycling, which I had done a lot of. Even with just running, I should have taken “running slowly” and “running a bit faster” and so on, till I found the breaking point.</p>
<p>Test: No positive exemplar - before the 20th century - going to Mars. Never even left the planet. Felt impossible. Now, have been to the moon, have sent probes past Pluto. Lot fewer possibly-wrong beliefs about what is possible. – earlier, very large diff; people thought anything extra-terrestrial was impossible (or at least very hard).</p>
<p><strong>Test</strong>: Only positive exemplars - saw TA answer all my questions better than I could - felt like he knew way more than me. Started going into research - even there, he seemed to know way more. But when it got deep, I could start to see mistakes. Fallible after all.</p>
<p>Look at it from the opposite angle. These are all negative exemplars for beating him. Slightly difficult question - couldn’t beat him. Much more difficult question - still couldn’t beat him. And so on. It’s like the scale is inverted. Earlier, it went from easy to hard, and all the positive exemplars were on the easy end and all the negative exemplars were on the hard end. Now, the scale goes from hard to easy, with the (potential) positive exemplars for beating him on the hard end and all the negative exemplars on the easy end. The aim is to go harder and harder till you get a positive exemplar for beating him.</p>
<p>So, as per my hypothesis, only negative exemplars means that you have a super-large diff (from the infinitely hard configuration - the “God” configuration) and so you think that a positive exemplar is completely impossible. That is, you can’t beat him.</p>
<p>How to remedy this? Get a small diff. From what? From a positive exemplar. That way, you will go from pass to fail and thus learn something useful.</p>
<p>(But the number of negative exemplars is way smaller than the number of positive exemplars. Shouldn’t you follow the logic of the earlier examples and toggle from the exemplar that is less numerous?)</p>
<p>The main question is why, here, you think everything untested is possible when, in general, you assume that everything untested is impossible?</p>
<p>Maybe the mechanism you’re trying to test is “what would beat him?”. So, anything untested is considered to be incapable of beating him. (Not exactly sure of this argument.)</p>
<p>Test: Only positive exemplars - undefeated team like Australia in the early 00s - feel like you would need to be a god to defeat them. – only negative exemplars for beating them. Felt like anything untested would also fail to beat them.</p>
<p>Test:</p>
<blockquote>
<p>“So you will risk becoming a Dark Lord, because the alternative, to you, is certain failure, and that failure means the loss of everything. You believe that in your heart of hearts. You know all the reasons for doubting this belief, and they have failed to move you.”</p>
<p>– <a href="http://www.hpmor.com/chapter/10">Chapter 10: Self Awareness, Part II, HPMOR</a></p>
</blockquote>
<p><strong>Explanation</strong>: The diff between himself and Dark Lords seemed so great that he expected that a lot of variables caused you to become a Dark Lord and thus that was unlikely to happen.</p>
<p>(Corollary: We might be making that assumption regarding war. We think there’s a hell of a difference between us and warring nations and leaders from the past and thus a lot would have to go wrong before we went to war. Not so.)</p>
<p>Test: On the other hand, greatness seemed to be within reach. He seemed to be just as smart as the “great” people he admired and just as motivated. All he needed, it seemed, was the right problem, a lot of perseverance, and a lot of hard work (along with a bit of luck). – small diff, low uncertainty.</p>
<h2 id="allow-only-short-diffs-using-close-exemplars">Allow only Short Diffs using Close Exemplars</h2>
<p><strong>Corollary</strong>: Compare between a positive and negative exemplar with few changed variables -&gt; short, specific diff -&gt; can narrow down the cause of the change.</p>
<p>Compare between a positive and negative exemplar with a lot of changed variables -&gt; large, vague diff -&gt; can’t narrow down the cause of the change.</p>
<p><strong>Lesson</strong>: Allow yourself to use only short diffs. No comparison between different people - there are too many variables that could be different. Comparison between two things that have few changes - his OS setup and mine.</p>
<hr />
<p>Test: “Linear programming and causal reinforcement learning” -&gt; “I’m confused” vs “I’m confused about X” – don’t know which specific things confused you. Don’t have a close positive exemplar.</p>
<p>Test: Asking smart questions - specify all kinds of details about your problem vs “Emacs keeps crashing. HELP!” – which branch failed? Otherwise you will think your entire system is broken. If you changed your Emacs version in the last week, that’s a strong clue. Need a close positive exemplar.</p>
<p>Test: “I had a blast in Europe” vs “I visited lots of cool ski resorts” - will think “Europe” will cause “great time” vs “going skiing with friends”. Were you happy or sad before Europe? Basically, was it Europe that did the trick or was it being with your friends? Saying that other people who are not in Europe are unhappy isn’t a helpful comparison - too many variable changes. Need a close negative exemplar.</p>
<p>Test: Compare with others - he could understand the lecture, I couldn’t. So, <strong>I</strong> am the cause for confusion. I suck. – vague high-level diff. Need a close positive exemplar.</p>
<p>Test: Compare with yourself - I could understand five minutes ago, now I can’t. So, something that happened in the last five minutes must be the cause. – specific low-level diff. Close positive exemplar.</p>
<p>Test: Someone wrote great code. Thought I couldn’t do it. But then a friend did it. Goddammit, if he can do it, so can I! – close positive exemplar to my negative exemplar of not making progress on a tough project.</p>
<h2 id="programming-vs-induction">Programming vs Induction (??)</h2>
<p>Question: How is programming different from induction?</p>
<p>In induction, you start from a positive exemplar and shave off variables using focus-gambling and accept necessary causes using conservative-focusing.</p>
<p>In programming, you start with a simple acceptance test, one that tests just one feature, and then add bigger tests and code that passes them.</p>
<p>Hypothesis: In induction, you have a mechanism that gives you the output for any input (though not always; sometimes you have to work with limited evidence, like astronomers studying the Big Bang).</p>
<p>You’re writing code in both of them.</p>
<hr />
<p>Test: Paging - start with just the global page directory, then add page fault handling, then per-process page directory, and so on.</p>
<p>Test: Induction - Semmelweiss - initially, any of the hospital location, the kinds of patients who came to that maternity ward, the other patients in the hospital, and so on could have caused “childbed fever”. But he narrowed it down to the doctor’s hands by looking at the doctor who died after getting nicked by the autopsy knife. At the end, he had a hypothesis - a function - that explained when somebody would get “childbed fever”.</p>
<h2 id="induce-necessary-causes-for-an-output-using-positive-and-negative-exemplars-basically-get-some-patterns-for-the-output">Induce Necessary Causes for an Output using Positive and Negative Exemplars (Basically, get some patterns for the Output)</h2>
<p><strong>Hypothesis</strong>: Look at different kinds of functions that satisfy contract X -&gt; induce necessary causes for X.</p>
<p><strong>Corollary</strong>: Have seen a positive exemplar for X that does not need a particular variable Y -&gt; Y is not a narrow cause of X.</p>
<hr />
<p>Test: Saw people do something to each element of a list using just <code>map f</code> – that became my necessary cause for transforming each element of a list; a for-loop became an unnecessary cause.</p>
<p>Test: Elisp regex - saw <code>(s-match regexp s)</code> – those are the two necessary causes for a regex match.</p>
<p>Test: Python regex - saw <code>self.assertIsNotNone(re.search(regex, s))</code> – felt like the <code>assertIsNotNone</code> was an unnecessary cause because there should be a function that simply returns true if the fucking regex matches the string.</p>
<p>Test: C regex - <code>r = regcomp(&amp;regex, regex_string.c_str(), REG_NOSUB|REG_EXTENDED)</code> and <code>regexec(&amp;regex, s, 0, NULL, 0)</code> – felt like the whole compiling regex thing and the matching flags and all the extra arguments to <code>regexec</code> were unnecessary. All I want is something that can tell me whether the string matches the regex!</p>
<p>Test: HTML output - have seen people get it without database access – database access is not a necessary cause.</p>
<p>Test: Negative exemplar - haven’t seen people get lines from a C++ socket without using a loop – feel like the loop is a necessary cause.</p>
<h2 id="log-note-the-configurations-for-each-output">Log: Note the Configurations for each Output</h2>
<p><strong>Hypothesis</strong>: Note the configurations when logging your output -&gt; can tell which configuration changes caused what.</p>
<p><strong>Corollary</strong>: Make your configuration a first-class variable -&gt; can print it easily, can change it with a single button.</p>
<p><strong>Corollary</strong>: Oh, and by the way, have a log file. It’s awesome. You don’t have to rely on just your memory for the past outputs of your program.</p>
<hr />
<p><strong>Test</strong>: ML - decision trees - helped to note down whether I was shuffling the data or not, whether I was using 80% of the training set or 90%, what the depth and size of the resulting tree was, the time taken, the timestamp, the test set accuracy (obviously), the training set accuracy, and the maximum depth allowed for the tree – could effortlessly see how accuracy decreased with increasing size and so on.</p>
<p>Test: Can toggle whether to shuffle the data or not by just toggling the configuration variable – easy.</p>
<p><strong>Test</strong>: Negative exemplar - didn’t note down the configuration information – had to remember what had happened with the previous runs; whether accuracy had gone up or down; couldn’t even tell whether my code gave the same results after a refactoring (no unit tests :P).</p>
<p>Test: Log file - decision trees – helped a lot, as mentioned above.</p>
<p>Test: Log file - XINU – helped a lot for me to keep track of what was going on. Had to save separate files, though, because the output was pretty huge. (Could have noted down only the variables I cared about.)</p>
<p><strong>Test</strong>: Negative exemplar - log file - didn’t have any for the IPL dataset – didn’t have a good idea of what was going on, especially when trying something new.</p>
<h1 id="high-level-design-decomposing-the-output">High-level Design: Decomposing the Output</h1>
<h2 id="programming-induction">Programming = Induction</h2>
<p>Hypothesis: Tests are positive exemplars. So, they allow you to easily eliminate irrelevant factors or figure out the effect of a change.</p>
<p>(h/t Michael Feathers’ Working Effectively with Legacy Code)</p>
<p>Refactoring is nothing but eliminating irrelevant factors. And that is why refactoring needs tests.</p>
<p>I suspect that category theory laws act as de facto tests. For example, I don’t seem to need a unit test to help me understand <code>fmap (+1) someMaybeValue</code>. Gabriel Gonzalez <a href>says</a> that he doesn’t usually write tests for his Haskell modules and yet his code works. When do you not need a unit test?</p>
<p>Code with minimum interface is basically code with all the irrelevant factors eliminated. It’s easy to understand because it has only the relevant factors. It’s easy to reuse because a smaller set of conditions means that more inputs will match it. And it’s easy to modify along the predefined axes. For example, it’s easier to change <code>map square</code> to <code>map cube</code> than to go into a for-loop and modify the function call.</p>
<p>Note that a “general” function isn’t one that can solve a ton of problems. It’s just the one with the minimum necessary factors for solving a particular problem. For example, <code>sort :: Ord a =&gt; [a] -&gt; [a]</code> is more general than <code>sortInts :: [Int] -&gt; [Int]</code> even though it solves the same problem. The latter was taking in unnecessary information (assuming that the sorting algorithm used just the ordering, not the integer values themselves).</p>
<h2 id="change-transforming-a-concept">Change: Transforming a Concept</h2>
<p>However, it’s harder to change minimized code when your purpose changes. For example, you turned a for-loop into a map because you assumed that you would just change each element of a list individually. Now if you want to also use the index variable in your calculation or, worse, refer to arbitrary elements in the list, you’re going to be screwed. You will have to use <code>zip [1..]</code> on the list first or do something else entirely. That’s the danger of premature optimization. Basically, there’s no possible configuration of the existing variables that will give you what you want. You have to include new variables like the index variable or the other elements of the list.</p>
<p>Hmm… You basically want to shift from one concept to another <strong>without</strong> having to induce each factor from scratch! Ideally, if you wanted to use a map function that uses the index, you’d just write a new version <code>imap</code> that also provided the index. You would want a separate function for every version that you write. However, we just update our function and throw away the previous version.</p>
<p>I suspect that you have transformed a concept when you have changed its type signature. For example, <code>map square</code> and <code>map cube</code> have the same type signature, whereas <code>map square</code> and <code>imap square</code> don’t.</p>
<p>Question: How do we usually transform our concepts and how can we do so efficiently?</p>
<p>For example, I changed Bird’s calculator to return a tree of rewrites instead of a chain. Most of the code, like the expression-parsing or the law-rewriting, remained untouched. All I had to change was the ultimate function <code>simplify</code>.</p>
<h2 id="clear-your-mind-and-see-the-matrix">Clear your Mind and See the Matrix</h2>
<p><strong>Hypothesis</strong>: We decompose an output in terms of input factors by first inducing away all irrelevant factors and then recognizing patterns we’ve seen before. Basically, we decompose by inducing and understanding.</p>
<p><strong>Corollary</strong>: You can’t decompose something you haven’t seen.</p>
<p>Corollary: You can’t decompose something if you haven’t cleared the noise.</p>
<p>Lesson: Think about each output variable in isolation and clear your mind of all irrelevant input factors.</p>
<p>Corollary: Tests help you decompose the output (in terms of the input factors).</p>
<p>Corollary: As do types.</p>
<p>Lesson: See the first-class output of whatever you’re doing so that you can decompose it and thus decompose the input.</p>
<hr />
<p>Test: Negative exemplar - Ents for tasks - I don’t have an idea of the Ent subgraph I want as output. – can’t decompose the output!</p>
<p>Test: Positive exemplar - I have an idea about the final product for the task planner – can decompose (???).</p>
<p>Test: <code>website-join-paragraphs</code> - had a clear idea of the input and output – could decompose the output in terms of the inputs.</p>
<p><strong>Test</strong>: Didn’t realize I could decompose - FB uses Duo Mobile - so that’s a state-of-the-art security system (at least for ordinary tech companies) - basically, I had seen a company that probably employs some of the best security guys out there and I had seen the security measures it uses. But I had failed to connect the two, to realize that this meant that two-factor authentication was probably a pretty strong security measure. – failure to induce. (I should have recognized the general pattern “Advanced tech company - whatever methods it uses are at least state-of-the-art for ordinary people”.)</p>
<h2 id="decompose-the-output-and-you-have-decomposed-the-input">Decompose the Output and You have Decomposed the Input</h2>
<p><strong>Hypothesis</strong>: Once you’ve decomposed your output in terms of the input factors, you know that you only have to implement whatever code is necessary to produce those individual pieces (and to put them together). Now you can tell how far behind you are and exactly what stuff you have to work on.</p>
<p>If you haven’t broken your output into pieces, you can’t tell how much work is left and will think you have to do a ton of work. So, you will probably procrastinate on it (because there are obviously too many constraints).</p>
<p><strong>TODO</strong>: Labels: “can tell how far behind you are”, “can narrow down the stuff you have to work on”, “think you have to do a ton of work”, “procrastinate” (how much?).</p>
<hr />
<p>Test: Negative exemplar - Ents for tasks - I don’t have an idea of the Ent subgraph I want as output. – So I can’t tell how far behind I am.</p>
<p>Test: Super Mario - can jump and run but can’t score points – you can tell how much of the “final product” is done.</p>
<p>Test: Negative exemplar - I have an idea about the final product for the task planner and I’m still stuck on the Ent design because I don’t have an idea about its final product (the Ent subgraph along with the privacy policies, etc.). – can’t see my lack of progress.</p>
<p>Test: <code>website-join-paragraphs</code> - had a clear idea of the input and output – easy to move ahead.</p>
<h2 id="figure-out-the-exact-part-of-the-output-you-want-to-change">Figure out the Exact Part of the Output you want to Change</h2>
<p><strong>Hypothesis</strong>: Figure out the exact part of the output you want to change, know the corresponding input factor -&gt; can get the change you want with little effort.</p>
<p>Figure out the exact part of the output you want to change (assuming you know the categories), can’t figure out the corresponding input factor (perhaps because it’s not written in terms of your intentions) -&gt; can’t get the result you want with little effort.</p>
<p>Don’t know the exact part of the output you want to change (because you don’t know the categories) -&gt; can’t get the result you want with little effort.</p>
<hr />
<p>Test: Wanted to add number of failures to my drill stats data. Once you realize that “[2018-05-20 Sun 13:33] 40 items reviewed. Session duration 0:10:53. (16 seconds per item)” consists of different parts and that you simply want to add one more part, you can focus on that part of the program. – less work.</p>
<p>Test: Negative exemplar - “add Ent schema for task planner” - don’t know which parts of the output I want change and thus which parts of the input I’ll have to modify. – stuck. Lots of “work”.</p>
<h2 id="to-know-what-to-change-get-fine-grained-tests-aka-controlled-experiments">To Know what to Change, get Fine-grained Tests (aka Controlled Experiments)</h2>
<p><strong>Corollary</strong>: If you can run a fine-grained test (toggle just a few variables) -&gt; small diff -&gt; know exactly which branch of my code to change -&gt; less work.</p>
<p>If you can run only a coarse-grained test -&gt; large diff -&gt; don’t know exactly which branches to change -&gt; more work; have to write multi-variable branches and later refactor.</p>
<hr />
<p>Test: Tried to do 5 things at the same time once my winter vacations started. Failed. Felt like none of those 5 things would work out. – coarse-grained test; have to do all 5 things correctly before I will tell myself “my plan succeeded”. Don’t get feedback about intermediate moves. Don’t know which one is actually causing the overall plan to fail - just see that I’m not making any progress. Don’t know what to change.</p>
<p>Test: Representative test idea - tried on a “complex” causal decision theory chapter - felt like I had to handle a lot of different variables at the same time (difficulty, equations, prose, background knowledge) before my idea would work. – coarse-grained test; don’t know exactly what to change about my idea to make the test pass; have to try lots of possibilities.</p>
<p>Test: pipgetc - worked for the non-blocking case; now added blocking - I felt like everything else worked and I just needed to support blocking on the pipe – fine-grained test; small diff (non-blocking vs blocking; everything else is the same); know exactly which branch to change.</p>
<h2 id="minimum-interface-gives-you-a-small-diff">Minimum Interface gives you a Small Diff</h2>
<p><strong>Hypothesis</strong>: Don’t think of the interface of each part -&gt; feel that you have to do a lot of things at once (large diff) -&gt; overwhelmed.</p>
<p>Think of the interface of each part -&gt; few things at a time (small diff) -&gt; can do it.</p>
<p><strong>Corollary</strong>: Have a detailed end-to-end acceptance test -&gt; can induce the interface of the different parts from it.</p>
<hr />
<p>Test: Struggled to write the get and put functions. Why? Got intimidated because I didn’t think of the interface for each part. In short, I didn’t use locality of causality. – I thought it had to be some big feature to be implemented all at once. It seemed like I had to implement a large diff before I could get any feedback.</p>
<p><strong>Test</strong>: Acceptance test for the get command (wow, I didn’t think even once about the actual flow of data) - they enter “get foo.txt” - you send that to the server - it checks the file, creates a new port, and sends it to you “get port: 13355 size: 205” - you then connect to that port and receive the contents and test whether you’ve got 205 bytes. You close the port (as far as this test is concerned). The end. – how fucking <strong>clear</strong> was that?!</p>
<h2 id="decompose-the-input-the-output-actually">Decompose the Input (??) (The Output, actually)</h2>
<p><strong>Hypothesis</strong>: Input, treat it like some monolithic data structure -&gt; have to deal with a lot of input configurations.</p>
<p>Input, treat it like some decomposable data structure (where the parts are decoupled) -&gt; fewer input configurations.</p>
<p><strong>Hypothesis</strong>: Sum-product type, decompose -&gt; easily done.</p>
<p>Some other type, decompose -&gt; pretty hard.</p>
<p><strong>Corollary</strong>: Decompose reality.</p>
<hr />
<p>Test: Guy <a href="http://www.jamesshore.com/Agile-Book/test_driven_development.html">talking about TDD</a> - <code>parseQuery</code> in Java took several red-green-refactor cycles. I did it in one line of Haskell and it was right too. Why? Why didn’t I need all the extra unit tests? I suspect that most of them were already covered by the functions I was composing. (The empty string one wasn’t.) – The guy was treating <code>QueryString</code> like some monolithic data structure that could have any number of possible configurations. I was treating it like a bunch of strings separated by “&amp;” and then separated by “=” within those.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import qualified</span> <span class="dt">Data.Map</span> <span class="kw">as</span> <span class="dt">M</span>
m <span class="fu">=</span> M.fromList <span class="fu">.</span> map ((\[x, y] <span class="ot">-&gt;</span> (x, y)) <span class="fu">.</span> splitOn <span class="st">&quot;=&quot;</span>) <span class="fu">.</span> splitOn <span class="st">&quot;&amp;&quot;</span> <span class="fu">$</span>  <span class="st">&quot;name1=value1&amp;name2=value2&amp;name3=value3&quot;</span></code></pre></div>
<p>Maybe these were well-worn paths that many programmers had already trodden. It would be a mistake to write fresh unit tests for them, as if you were completely uncertain as to their behaviour.</p>
<p>Observation: <code>parseQuery</code> is way too specific. What you really have is a bunch of a’s with delimiters. Writing a specific function for that is just stupid.</p>
<h2 id="chain-decompose-transform-compose">Chain = Decompose, Transform, Compose (??)</h2>
<p><strong>Hypothesis</strong>: Chain of functions -&gt; each function either decomposes the previous data structure or composes it into something bigger or transforms each part without composing it.</p>
<hr />
<p>Test:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">callGrepOnFile p <span class="fu">=</span> unlines <span class="fu">.</span> grep p <span class="fu">.</span> lines

<span class="co">-- Read the files, grep each of them, and combine the results.</span>
callGrep p fs <span class="fu">=</span> fmap (concat <span class="fu">.</span> map (callGrepOnFile p)) <span class="fu">.</span> mapM readFile <span class="fu">$</span> fs</code></pre></div>
<p><code>lines</code> breaks down the string into a bunch of lines (each of which is simpler than the whole file and is independent of the rest). <code>grep p</code> transforms the lines into some other set of lines (just a subset). <code>unlines</code> composes the bunch of lines into a string.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">mapM<span class="ot"> ::</span> (<span class="dt">Monad</span> m, <span class="dt">Traversable</span> t) <span class="ot">=&gt;</span> (a <span class="ot">-&gt;</span> m b) <span class="ot">-&gt;</span> t a <span class="ot">-&gt;</span> m (t b)</code></pre></div>
<p>Next, <code>mapM readFile</code> transforms a list of files into a list of monads and then composes those monads to get an overall monad. Basically, you can see it as composing a bunch of files. <code>fmap</code> transforms part of a structure without touching the rest. <code>map (callGrepOnFile p)</code> transforms each element of that part-structure using <code>callGrepOnFile</code>. Finally, <code>concat</code> composes those elements into a valid part-structure. ## Integration Test: Follow the Values to get the High-level Design</p>
<p>[2017-12-25 Mon] Go through Bird section 6.1 taking for granted whatever he claims.</p>
<p><strong>Hypothesis</strong>: Integration test, accept all the deductions (function calls) based on their given outputs, <strong>actually</strong> follow the values across steps from start to end -&gt; get the type signature of the high-level components, maybe even induce how it works based on the concrete values.</p>
<p>For example, if step 1 takes X and outputs Y, then you must ensure that step 2 takes Y and outputs Z.</p>
<p>Integration test, don’t have outputs for some deductions (function calls), follow the values -&gt; may get stuck on the type signature and working.</p>
<p>Question: Why would following values give the “high-level design”?</p>
<p><strong>Hypothesis</strong>: Follow the values -&gt; know what values each component of the program takes in and gives out -&gt; narrow down the causes of each value, can decouple the components.</p>
<p>Don’t follow the values -&gt; don’t know what values each component of the program takes in and gives out -&gt; don’t narrow down the causes of each value, can’t decouple the components.</p>
<p><strong>Hypothesis</strong>: Integration test, get inputs and outputs for all the function calls -&gt; decent representative tests for those functions, maybe even induce how they work.</p>
<p><strong>Question</strong>: What if you gave somebody a fully-representative test of paging or some other large problem? Would they be able to design it in a quarter of the time you took?</p>
<p>For example, consider a test that involved multiple processes accessing virtual memory as well as non-virtual memory and having page faults and needing to replace pages in FIFO order while using semaphores and so on. Assume that all output values are specified at each point.</p>
<hr />
<p>Test: I saw</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">=</span> [wrap, snoc] <span class="fu">.</span> (id <span class="fu">+</span> val<span class="fu">^</span>c x id) <span class="fu">.</span> [embed, op]<span class="fu">^</span>c
<span class="co">-- coproduct</span>
<span class="fu">=</span> [wrap, snoc <span class="fu">.</span> (val<span class="fu">^</span>c x id)) <span class="fu">.</span> [embed, op]<span class="fu">^</span>c</code></pre></div>
<p>and induced that “coproduct” simply meant taking <code>[a, b] . (c + d)</code> and returning <code>[a . c, b . d]</code>. That’s all there is to it, at least as it is used in this proof! – just followed the values; got how it worked!</p>
<p>Test: Not following values - I saw the long chain of equational reasoning. Kinda “followed” each step by assuming that its proof step actually did what they said it did. But couldn’t see the link between that whole chain and the final argument that digits = val^c and thus digits would convert a number to digits. I hadn’t followed the values from the chain to the final paragraph – didn’t get the type signature of the model; didn’t induce how it worked.</p>
<p>Test: Follow values closely - already realized that val takes a decimal representation of a number to the number itself, and that thus val^c is just trying to get at the inverse! Crystal by the end of it! (Took a bit of time, though. Still, I was <strong>guaranteed</strong> to understand it by the end.) – got the type signature of each component (such as val, val^c, and function refinement) and even induced how it works (want foo; can see that there is a bar that goes in the opposite direction; get a “functional refinement” of bar^c and define foo as that function.);</p>
<p>Test: MATLAB <a href="https://www.mathworks.com/help/stats/examples/selecting-features-for-classifying-high-dimensional-data.html">Cross-validation page</a> – Understood it in depth! (Took 24 minutes, though. Had 2.5k words. So, that’s 6.25k words per hour = 104 words per minute. Need to speed that up.) But it worked. Also learnt how to visualize things during feature selection (have a plot of MCE vs number of features, etc.). Got type signatures for the different parts of it (like holdout vs k-fold cross-validation, feature selection itself, ttest2, MCE, MCE with resubstitution - even though I’m not sure how it works, MCE vs number of features, how to judge whether you’re at a local minimum, etc.)</p>
<p>Test: Knaster-Tarski theorem 6.1 – took around 15 minutes. Not as crystal clear as the previous ones. But I did get the gist. However, I don’t understand the final point (equations 6.2 and 6.3). (5 minutes later, I still don’t get the last paragraph.) So, this technique isn’t infallible. But it’s better than nothing. Got the type signature. Got stuck because I didn’t understand the line “Each of the equations … has a least solution and these least solutions coincide.” and I needed it to understand the last paragraph. Don’t have the contract since I didn’t see any concrete values and didn’t understand the theorem statement.</p>
<p>Explanation: Didn’t have the output value for the unfamiliar function call “least solutions coincide” and couldn’t see a concrete example showing me the output value.</p>
<p>Test: Follow the values to decouple - paging - when switching processes, you need to have different page directories and page tables; when accessing a virtual memory address, you need to have a page fault handler that can get a new frame for that page (and possibly its page table); when replacing a page, you need to have a free frame list with FIFO information and a backing store that has the data for the incoming page and can store data for the evicted page. – know the causes of paging during process-switching, page-fault handling, and page replacement.</p>
<p>Test: How to create a one-to-one mapping (and more importantly, how to get <code>P(y = 0 | z = 0)</code> from <code>y = fy(z, uy)</code>) - test on Shpitser’s paper - got it. – technique: one-to-one mapping; known working example: Shpitser’s paper; clear feedback - what his proof said (as opposed to my vague incomplete attempts).</p>
<h3 id="minimum-interface-try-alternative-values-and-abstract">Minimum Interface: Try Alternative Values and Abstract (??)</h3>
<p><strong>Hypothesis</strong>: Follow the values, try alternative values (toggle it), no change -&gt; abstract that value; reuse known functions.</p>
<hr />
<p>Test: Want to convert roman numerals to decimals. Use Parser. – I broke down the concrete problem of reading a roman number to the known technique of parsing.</p>
<p>Test: Paging - broke it down to <code>get_new_frame</code>, <code>page_fault_handler</code>, <code>read_bs</code>, etc. – Well, get new frame needed to care only about the frame list and the replacement policy.</p>
<p>Test: ATM example - suppose you were given lots of extraneous details like the make of the card reader, the keyboard model, etc., how could you strip it down to the core problem of requesting money and getting it? – toggle the values and <strong>realize</strong> that the outcome would be the same [may not always be so].</p>
<h3 id="values-are-easier-to-understand-than-unfamiliar-types">Values are Easier to Understand than Unfamiliar Types</h3>
<p><strong>Hypothesis</strong>: Unfamiliar type or category -&gt; unfamiliar function calls; have to look them up.</p>
<hr />
<p>Test: Phone number problem - could follow the input values from start to finish because I saw them simply as strings. You received an input string like “10/783–5” and got a digit-only string like “107835” and then you broke it up into prefixes and suffixes and tried to match them with dictionary words and so on. – It was all simple and understandable; I know how Strings behave.</p>
<p>Test: Phone number problem - contrast that to my first attempt - look at the types: <code>DigitString, Dict, Token, NonDeterministicEncoding, Parser, PState, DictWord, PhoneNumber</code>. – You have to work pretty hard to understand all of them. And here’s the rub: you can’t fully understand the code unless you’ve understood them. I’d have to keep looking up the definition.</p>
<p>Test: Look at this code (from 2014 - I don’t think I would have written the same code now):</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">parse' ::</span> <span class="dt">Dict</span> <span class="ot">-&gt;</span> <span class="dt">PState</span> <span class="ot">-&gt;</span> [<span class="dt">PState</span>]
parse' _ ps<span class="fu">@</span>([], _) <span class="fu">=</span> [ps]
parse' dict ps <span class="fu">=</span> flip nextPStates ps <span class="fu">.</span> mapMaybe (lookupToken dict) <span class="fu">.</span> prefixSplits <span class="fu">.</span> fst <span class="fu">$</span> ps</code></pre></div>
<p>You can’t really understand that code if you don’t know what <code>PState</code> behaves like. – I can’t get started until I lookup <code>PState</code> or even <code>Dict</code>. Slow.</p>
<p>Test: Here’s another sample:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">nextPStates ::</span> [(<span class="dt">DigitString</span>, <span class="dt">Token</span>)] <span class="ot">-&gt;</span> <span class="dt">PState</span> <span class="ot">-&gt;</span> [<span class="dt">PState</span>]
nextPStates [] ps <span class="fu">=</span> nextPStatesWhenNoNewTokens ps
nextPStates ts' (_, ts) <span class="fu">=</span> map (fmap (<span class="fu">:</span>ts)) ts'</code></pre></div>
<p>Explanation: Can’t move forward until I know <code>DigitString</code> and <code>PState</code>. Slow.</p>
<p>Test: Contrast that to my current code (which isn’t beautiful or anything) TODO</p>
<p>Test: Reading Applied Behavioural Analysis - constantly got stopped in my tracks by the definitions they kept laying out - “respondent conditioning”, “modeling”, and other things. I didn’t <strong>know</strong> what those labels referred to and I had to struggle to figure it out. – can’t move forward without knowing those terms; hard to follow. Have to keep looking up the definitions.</p>
<p>Test: Category theory book or Bird book - full of unknown types like “initial object”, “group”, “product”, “coproduct”, “functional refinement”, “catamorphism”, etc. – can’t move forward unless you know; have to keep looking up the definition.</p>
<h3 id="types-prevent-you-from-following-values">Types prevent you from Following Values (??)</h3>
<p><strong>Hypothesis</strong>: Types -&gt; stop you from following values and thus stop you from inducing the types and mechanisms of different parts.</p>
<hr />
<p>Test: Trying to apply the “fusion law” for folds to a practical problem. Not able to get through because of the maddeningly-similar <code>fold</code> and <code>listFold</code>. They have the types <code>fold :: (a -&gt; b -&gt; b, b) -&gt; [a] -&gt; b</code> and <code>listFold :: LAlg a b -&gt; ListF a b -&gt; b</code>.</p>
<p>Note that I first have to unpack <code>LAlg</code>, which is <code>type LAlg a b = (a -&gt; b -&gt; b, b)</code>. So, the first arguments are <strong>literally</strong> the same type. Then, I have to unpack <code>ListF</code>, which is <code>data ListF a r = NilF | ConsF a r</code>. That just seems like the List type with extra steps.</p>
<p>I can’t see any substantial difference between <code>listFold</code> and <code>fold</code>. But the condition and result of the law include both, so there <em>must</em> be some difference.</p>
<p>Explanation: I can’t see any values passing around. Hard to induce the work being done.</p>
<p>I mean, take the fusion law itself:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">h <span class="fu">.</span> listFold f <span class="fu">=</span> listFold g <span class="fu">.</span> listMap h
<span class="fu">==&gt;</span>
h <span class="fu">.</span> fold f <span class="fu">=</span> fold g</code></pre></div>
<p>What is the type of h? What are the types of f and g? Are they of the same type? Not at all sure.</p>
<p>What I need is an actual concrete exemplar.</p>
<p><strong>Test</strong>: Let’s look at a concrete <a href="http://myhaskelljournal.com/an-optimization-using-foldr-fusion-law/">practical example</a>.</p>
<p>Immediately, I got some ideas.</p>
<p>(Paraphrased to name f, g, and h as per standard usage.)</p>
<blockquote>
<p>If we have the following properties:</p>
<ol style="list-style-type: lower-roman">
<li>h is a strict function.</li>
<li>h (f x y) = g x (h y), for all x and y in the appropriate ranges</li>
</ol>
<p>Put b = h(a).</p>
<p>Then: h . foldr f a = foldr g b.</p>
</blockquote>
<p>Not yet a concrete example, though.</p>
<p>Let’s try it with the ascending lists example.</p>
<p>Explanation: Could see what was happening to each element of the list being folded.</p>
<h3 id="follow-the-values-in-the-final-program-induce-program-design-principles">Follow the Values in the Final Program: Induce Program Design Principles (??)</h3>
<p><strong>Hypothesis</strong>: Follow the values in the representative test, follow the values in the final program, induce -&gt; model for representative test to high-level design.</p>
<p>Corollary: Get model for representative test to high-level design -&gt; store that technique on that concrete cue.</p>
<hr />
<p>Test: Paging - could see that page faults needed to go through the page fault handler, look up stuff in the page directory and page table, evict a page, and so on. Those concepts remained in the final program too. – So, I could have designed the system like that right from the beginning.</p>
<h2 id="abstract-from-concrete-representative-exemplars">Abstract from Concrete Representative Exemplars</h2>
<p><strong>Hypothesis</strong>: Start with a concrete example -&gt; know it will work; can abstract quickly.</p>
<p>Start with an abstract function -&gt; don’t know if it will work; slow.</p>
<hr />
<p>Test: Elisp function to compile and run this C/C++ file. – Took me 10 minutes. Writing the function itself took only 5 minutes or so. Binding the key took up the rest of the time. Helped to abstract my way to the ideal function. First, I simply ran “g++ popen-try.cpp &amp;&amp; ./a.out” by hand. That worked. Then, I wrote a simple function that did that. Worked. Then, I abstracted that function to work with arbitrary file names (and use the buffer file name if there was no argument). Worked like a charm. When the keybinding was giving me some trouble, I reverted to a simple non-Evil keybinding that worked, then tried an Evil keybinding that worked, and finally used my desired key.</p>
<h2 id="fast-index-for-your-techniques-integration-tests-categorize-the-output">Fast Index for your Techniques: Integration Tests (Categorize the Output)</h2>
<p><strong>Corollary</strong>: Real-world scenario, can’t remember which technique to use, look <strong>only</strong> at your integration tests for a similar scenario -&gt; have to remember just the integration tests and will automatically have concrete discriminating cues; quickly get the single function you want; guaranteed up-to-date since you will replace old techniques with better ones; DRY because you can’t have multiple hypotheses for the same scenario.</p>
<p>Real-world scenario, can’t remember which technique to use, no integration tests -&gt; have to remember a lot of context-less techniques for whom I don’t have discriminating cues; slow; may not be up-to-date; not DRY because I may see several techniques for the same (poorly-categorized) scenario.</p>
<p>New scenario that your past acceptance tests don’t cover, search your techniques (aka weapons) -&gt; hopefully respond correctly; add as an acceptance test.</p>
<p>Corollary: Scenario not in integration test, go online and add the technique to an integration test first -&gt; every technique you needed to look up will be in an integration test for easy lookup later; quicker way to test the new technique.</p>
<p><strong>Corollary</strong>: We can easily remember integration tests (even if we don’t remember the answers). We struggle to remember generic text.</p>
<p>Hypothesis: Maybe all you need are tests for real-world scenarios, even if they don’t make an end-to-end acceptance test. That way you can still look up what to do in any given situation. (But an end-to-end representative test lets you induce the whole function. Still useful.)</p>
<hr />
<p>Test: Want to use a pre-commit hook to run lint - look at the how the demo repo does it with Ruby. – done. quick - no need to search 30k words of my programming notes. got one single function - exactly what I wanted. up-to-date in terms of versions and quality; DRY - didn’t have to decide between two different techniques.</p>
<p>Test: No integration test - wanted to write OS HW3 paging faster. Didn’t know what to do. There were around 15k words of programming notes. Kind of stuck. – Could see that I would have to read through a lot to get back to my idea of toggling behind an interface and minimizing interface by coding everything in separate files and stuff. Saw lots of techniques like one-button change and minimum interface and one branch at a time and program to an interface and so on.</p>
<p>Test: Self-help books with a bunch of techniques (such as The Little Book of Talent: 52 Tips by Daniel Coyle, Writing Tools: 50 Essential Strategies for Every Writer by Roy Peter Clark, or Your Brain at Work by David Rock, which has 14 tips) - don’t know when to use what. I usually forget to use them. – have to remember a lot of context-less techniques (“Tip 45: For every hour of competition, spend five hours practicing.”); can’t find what I want; abstract scenario - may hit upon several seemingly-applicable techniques.</p>
<p>Test: Have to make a Beamer presentation using Org mode - look it up in my demo Org Beamer presentation, not online. – have a default Org Beamer template I can use anywhere; can experiment on a simple template.</p>
<p>Test: C pointer details - hard to remember the abstract knowledge about <code>p + i</code> and <code>(void *) p</code> and <code>(struct foo *) p</code> and so on. Easier to remember a test I ran on all these examples, from where I can easily get the answers I want. – done.</p>
<p>Test: New scenario - Milo against Avada Kedavra - none of his usual spells worked; use the <a href="https://www.fanfiction.net/s/8096183/25/Harry-Potter-and-the-Natural-20">Skeletal Troll</a>. – he probably searched the rule book for something like this. He could then use it against anyone who cast the killing spell against him.</p>
<p>Test: YBAW - overwhelmed by a project plan - use a story board to represent a few big ideas. – it’s not a full story, just a sketch.</p>
<h2 id="high-level-design-needs-an-integration-test-maybe-with-mocking">High-level Design needs an Integration Test (maybe with Mocking)</h2>
<p><strong>Corollary</strong>: Have integration test with expected output (maybe mocking out each lower-level function for the particular test input), get high-level design -&gt; low uncertainty.</p>
<p>Don’t have integration test, get high-level design -&gt; high uncertainty.</p>
<hr />
<p>Test: OS HW3 - change design of my paging code - don’t know which one will be better (and still pass all tests). Don’t know how to implement free-frame list in the best way or how to decouple the heap and backing store from the rest of the program, etc. – didn’t have any integration test, lots of uncertainty.</p>
<p>Test: OS HW2 - pipes - knew how the high-level pieces were going to fit together. Basically, didn’t have to do any <strong>high-level design changes</strong>. Just implement pipgetc, pipputc, etc. and the test code would simply use a pipe like a normal device. – didn’t need to change the high-level design.</p>
<p>Test: OS HW3 - tried one example of virtual memory page access - got the general idea of how control flowed. Got the high-level design (heap was used just to allocate memory, backing store was really used only when there were insufficient frames). – integration test helped me get the answer quickly.</p>
<h2 id="deployment-pipeline-flesh-out-the-integration-test-duplicate">Deployment Pipeline: Flesh out the Integration Test (?? duplicate)</h2>
<p><strong>Hypothesis</strong>: Deployment pipeline for hypotheses or programs = add a high-level integration test with function calls mocked out so that it all flows; fill out mocked-out functions using inputs and outputs from the integration test; release by running integration tests + unit tests; you’re done passing that integration test when you no longer have any mocks in the integration test -&gt; decoupled high-level design by following the values; isolated implementation for the inner functions by using real-world tests; working product at every point as certified by the integration test; frequent releases by implementing inner functions quickly and running the integration test + unit tests;</p>
<p>don’t have high-level integration test; add functions without an overarching test -&gt; may commit to poor design; isolated implementation for functions; won’t have a working product for a while since there are no integration tests passed; infrequent high-level releases.</p>
<p><strong>Corollary</strong>: Deploy using integration test -&gt; no duplicate or overlapping hypotheses because you can only implement something that has been mocked out in the integration test.</p>
<p>Don’t deploy using integration tests -&gt; duplicate or overlapping hypotheses.</p>
<p>Question: How does this make for small diffs?</p>
<hr />
<p>Test: Learning about myosin filaments and stuff - first took myosin filaments as black boxes just to make the high-level example flow, and then filled out my model of them using the next section. – high-level flow; inner definition; run integration test by checking if it fits in the overall flow (need to do it mentally); done when you can explain the whole integration test in detail -&gt; decoupled design (myosin filaments are at a lower level); isolated implementation (yup - you get feedback from the questions at the end of the myosin section); working product at any point because you know how the overall thing works; frequent releases (?).</p>
<p>Test: Bird - number to digits or Knaster-Tarski theorem - followed the high-level flow without knowing how the inner functions worked. Later, could fill them out - such as <code>coproduct</code> or <code>functional refinement</code>. – high-level flow; fill out inner functions, sometimes just by inducing using the high-level test (for example, coproduct); run tests by checking the overall flow -&gt; decoupled design because you learn each concept in isolation and then piece it together with the rest; working product at any point because I choose to skip some esoteric function definitions; frequent releases because you can run the integration tests.</p>
<p>Test: No high-level integration test - current refactoring of causal hypothesis essay. Just refactoring pieces here and there. – No idea how it all fits together and may have a poor design that isn’t related to any real-world problem. Definitely won’t have a working product for like 50 hours or so! Can’t test the overall picture.</p>
<p>Test: [2017-12-27 Wed] My one-button change essay. No real idea how it all fits together - the old random notes, the newer well-tested little ideas that still run up to a 11k-word tangle, and then some ideas from my journal and phone. – no high-level integration test; add new ideas like “follow the values -&gt; narrow the causes” without an overarching test -&gt; <strong>poor design for sure</strong>; won’t have a working product for a while since I’m not running any integration tests; infrequent release of integration tests (maybe when I write a 2-hour program like TicTacToe or something - which I approach intuitively anyway).</p>
<p>Test: Duplication - causal hypothesis - a bazillion explanations for how we understand things - hierarchical categories, stories, grammar, etc. – no integration test.</p>
<h2 id="spec-or-integration-test-quick-feedback-about-high-level-design-decompose-the-output">Spec or Integration Test: Quick Feedback about High-level Design (??) (Decompose the Output?)</h2>
<p><strong>Corollary</strong>: Writing a spec (or better, a prototype) = coming up with integration tests (with feedback from the user).</p>
<p><strong>Hypothesis</strong>: Spec or integration test, change your high-level design -&gt; can set the input configuration (aka your program) quickly and get feedback from user (who is the mechanism you’re testing).</p>
<p>Write fully-tested code, change your high-level design -&gt; lot of work to change the input configuration (your program).</p>
<p><strong>Hypothesis</strong>: Spec -&gt; list your high-level assumptions so that you can toggle them deliberately or test them against reality.</p>
<hr />
<p>Test: Joel Spolsky:</p>
<blockquote>
<p>Now, Mr. Rogers over at Well-Tempered Software Company (colloquially, “WellTemperSoft”) is one of those nerdy organized types who refuses to write code until he’s got a spec. He spends about 20 minutes designing the backwards compatibility feature the same way Speedy did, and comes up with a spec that basically says:</p>
<blockquote>
<p>When opening a file created with an older version of the product, the file is converted to the new format.</p>
</blockquote>
<p>The spec is shown to the customer, who says “wait a minute! We don’t want to switch everyone at once!” So Mr. Rogers thinks some more, and amends the spec to say:</p>
<blockquote>
<p>When opening a file created with an older version of the product, the file is converted to the new format in memory. When saving this file, the user is given the option to convert it back.</p>
</blockquote>
<p>Another 20 minutes have elapsed.</p>
<p>Mr. Rogers’ boss, an object nut, looks at this and thinks something might be amiss. He suggests a different architecture.</p>
<blockquote>
<p>The code will be factored to use two interfaces: V1 and V2. V1 contains all the version one features, and V2, which inherits from V1, adds all the new features. Now V1::Save can handle the backwards compatibility while V2::Save can be used to save all the new stuff. If you’ve opened a V1 file and try to use V2 functionality, the program can warn you right away, and you will have to either convert the file or give up the new functionality.</p>
</blockquote>
<p>20 more minutes.</p>
<p>Mr. Rogers is grumpy. This refactoring will take 3 weeks, instead of the 2 weeks he originally estimated! But it does solve all the customer problems, in an elegant way, so he goes off and does it.</p>
<p>– <a href="https://www.joelonsoftware.com/2000/10/02/painless-functional-specifications-part-1-why-bother/"></a></p>
</blockquote>
<p>Explanation: I suspect that a spec is just an integration test. You come up with a high-level input-output pair and go through the particular branch of (not-yet-existing) code that it exercises. – The key is that you can change the high-level design quickly and get feedback (about whether they do what the users wants and whether they will lead to good-quality code).</p>
<p>Test: PG on spec vs prototype:</p>
<blockquote>
<ol start="8" style="list-style-type: decimal">
<li>Start small. A program gets easier to hold in your head as you become familiar with it. You can start to treat parts as black boxes once you feel confident you’ve fully explored them. But when you first start working on a project, you’re forced to see everything. If you start with too big a problem, you may never quite be able to encompass it. So if you need to write a big, complex program, the best way to begin may not be to write a spec for it, but to write a prototype that solves a subset of the problem. Whatever the advantages of planning, they’re often outweighed by the advantages of being able to keep a program in your head.</li>
</ol>
<p>– <a href="http://www.paulgraham.com/head.html"></a></p>
</blockquote>
<blockquote>
<p>What and how should not be kept too separate. You’re asking for trouble if you try to decide what to do without understanding how to do it. But hacking can certainly be more than just deciding how to implement some spec. At its best, it’s creating the spec– though it turns out the best way to do that is to implement it.</p>
<p>– <a href="http://www.paulgraham.com/hp.html"></a></p>
</blockquote>
<p>Explanation: Write a prototype to pass one integration test (such as evaluating some small Lisp program) and then abstract your code into well-separated modules. – You can test different high-level design ideas using your integration test without much trouble (because you don’t have too many branches).</p>
<blockquote>
<p>The moral of the story is that when you design your product in a human language, it only takes a few minutes to try thinking about several possibilities, revising, and improving your design. Nobody feels bad when they delete a paragraph in a word processor. But when you design your product in a programming language, it takes weeks to do iterative designs. What’s worse, a programmer who’s just spend 2 weeks writing some code is going to be quite attached to that code, no matter how wrong it is.</p>
<p>– <a href="https://www.joelonsoftware.com/2000/10/02/painless-functional-specifications-part-1-why-bother/"></a></p>
</blockquote>
<blockquote>
<p>CORAL: All business plans for startups turn out to be wrong, but you still need them - and not just as works of fiction. They represent the written form of your current beliefs about your key assumptions. Writing down your business plan checks whether your current beliefs can possibly be coherent, and suggests which critical beliefs to test first, and which results should set off alarms, and when you are falling behind key survival thresholds. The idea isn’t that you stick to the business plan; it’s that having a business plan (a) checks that it seems possible to succeed in any way whatsoever, and (b) tells you when one of your beliefs is being falsified so you can explicitly change the plan and adapt. Having a written plan that you intend to rapidly revise in the face of new information is one thing. NOT HAVING A PLAN is another.</p>
<p>– <a href="https://intelligence.org/2017/11/26/security-mindset-and-the-logistic-success-curve/"></a></p>
</blockquote>
<h2 id="acceptance-test-talk-only-about-domain-variables">Acceptance Test: Talk only about Domain Variables</h2>
<p><strong>Hypothesis</strong>: Domain variables -&gt; necessary for all use cases; so start with this.</p>
<p>Fancy stuff like the type of messaging protocol or the database type -&gt; not necessary for all use cases; do it later.</p>
<hr />
<p>Test: Auction sniper example - “Given auction, when I join and don’t bid, then I will lose” - nothing about XMPP or Swing or anything else. – simple test; can change the protocol and such. Start with the domain stuff.</p>
<h2 id="acceptance-test-go-from-end-to-end-no-negative-exemplar">Acceptance Test: Go from End to End (?? no negative exemplar)</h2>
<p>Hypothesis: Acceptance test - must go from end to end, not merely test some intermediate state -&gt; fewer overall tests, more likely to cover highly-likely money-making paths, no unused paths.</p>
<hr />
<p>Test: “Journey test” - Jez Humble - shopping website - login, add 3 items to cart, checkout, add delivery address, pay, logout – highly likely path; one that actually makes the money; not unused.</p>
<p>Test: Could Gambling Save Science?</p>
<blockquote>
<p>NEUTRINO MASS Betting markets could also function in the absence of overt controversy, as in the following (hypothetical) story.</p>
<p>Once upon a time the Great Science Foundation decided it would be a “good thing” to know the mass of the electron neutrino. Instead of trying to figure out who would be a good person to work on this, or what a good research strategy would be, they decided to just subsidize betting markets on the neutrino mass. They spent millions.</p>
<p>Soon the market odds were about 5% that the mass was above 0.1eV, and Gung Ho Labs became intrigued by the profits to be made. They estimated that for about $300K spent on two researchers over 3 years, they could make a high confidence measurement of whether the mass was above 0.1eV. So they went ahead with the project, and later got their result, which they kept very secret. While the market now estimated the chance of a mass over 0.1eV at 4%, their experiment said the chance was at most 0.1%.</p>
<p>So they quietly bought bets against a high mass, moving the price down to 2.5% in the process. They then revealed their results to the world, and tried their best to convince people that their experiment was solid. After a few months they mostly succeeded, and when the price had dropped to 0.7% they began to sell they bets they had made. They made $400K off of the information they had created, which more than covered their expenses to get that information.</p>
<p>Or course if Gung Ho Labs had failed to convince the world of their results, they would have faced the difficult choice of quitting at a loss, or holding out for the long-term. No doubt a careful internal review would be conducted before making such a decision.</p>
<p>Gung Ho would be free to use peer review, tenure, and fixed salaries internally, if they are effective ways to organize workers. The two researchers need not risk their life savings to be paid for their efforts. But the discipline of the external market should keep these internal institutions from degenerating into mere popularity contests.</p>
<p>– <a href="http://mason.gmu.edu/~rhanson/gamble.html"></a></p>
</blockquote>
<p>Explanation: He actually walked through a concrete, made-up, end-to-end scenario, just like Joel Spolsky recommends:</p>
<blockquote>
<p>When you’re writing a spec, an easy place to be funny is in the examples. Every time you need to tell a story about how a feature works, instead of saying:</p>
<pre><code>The user types Ctrl+N to create a new Employee table and starts entering the names of the employees.</code></pre>
<p>write something like:</p>
<pre><code>Miss Piggy, poking at the keyboard with a eyeliner stick because her chubby little fingers are too fat to press individual keys, types Ctrl+N to create a new Boyfriend table and types in the single record &quot;Kermit.&quot;</code></pre>
<p>– <a href="https://www.joelonsoftware.com/2000/10/15/painless-functional-specifications-part-4-tips/"></a></p>
</blockquote>
<h2 id="acceptance-test-high-level-decoupling-refile-to-the-domain-variables-section">Acceptance Test: High-level Decoupling (?? refile to the domain variables section)</h2>
<p>Corollary: Acceptance test -&gt; you put the domain variables first -&gt; high-level decoupling; everything unmentioned gives you degrees of freedom as per your design choices.</p>
<hr />
<p>Test: ATM example - doesn’t say which model of the keyboard or monitor or card reader or even bank you’re using. You can vary that as you please. All that matters is that when I have $100 in my account and ask for $20, I should get $20 and have $80 left in my account. – your high-level design shouldn’t worry about the low-level model types. You have to assume that the use will have those high-level actions. For example, you can assume that the user can enter “$20” on any keyboard - whether it’s a touchscreen, a numeric keypad, or a QWERTY keyboard (or even that he can enter it via a voice-recognition machine).</p>
<h2 id="rapid-prototyping-figure-out-the-high-level-design-before-the-low-level-details-valuable-features-first-others-come-later-based-on-experience">Rapid Prototyping: Figure out the High-level Design before the Low-level Details (?? Valuable features first; others come later based on experience)</h2>
<p><strong>Question</strong>: Why is it better to pass one integration test with a 120-line program written in three hours than to pass all kinds of tests with a spec implemented in three weeks?</p>
<p>Observation: The differing variables are: number of tests passed, number of lines of code, and time taken. Also, the first one gets feedback about the design immediately.</p>
<p><strong>Hypothesis</strong>: You’re uncertain about the integration tests you actually want to pass. And even if you know precisely which tests you wanted to pass, you’re still uncertain about the high-level design you should use for your code.</p>
<p>If you write a lot of code to pass the tests you assumed were important, you have to do a lot of work to handle some other tests (plus you would have wasted all that time). Basically, the high-level design changes, and that costs you if you’ve already written much code.</p>
<p>Similarly, if you write a lot of code and then decide to change your high-level design, you have to do a lot of work. High-level design change always takes work when you have a lot of code. You may get it wrong in your spec, which makes it costly to change three weeks down the line.</p>
<p><strong>Corollary</strong>: It’s a mistake to write low-level code without getting the high-level design right.</p>
<p><strong>Hypothesis</strong>: Have working program (for at least one integration test) -&gt; can come up with new integration tests based on empirical usage.</p>
<p>Don’t have working program (for at least one integration test) -&gt; can’t imagine new integration tests.</p>
<hr />
<p>Test: PG on the Viaweb editor:</p>
<blockquote>
<p>The Viaweb editor must be one of the most extreme cases of incremental development. It began with a 120-line program for generating Web sites that I had used in an example in a book that I finished just before we started Viaweb. The Viaweb editor, which eventually grew to be about 25,000 lines of code, grew incrementally from this program. I never once sat down and rewrote the whole thing. I don’t think I was ever more than a day or two without running code. The whole development process was one long series of gradual changes.</p>
<p>– <a href="http://ep.yimg.com/ty/cdn/paulgraham/bbnexcerpts.txt"></a></p>
</blockquote>
<p>Explanation: His initial integration test was passed by a 120-line program. He then added more integration tests and improved the design of the program as needed. – He figured out exactly which pieces he needed - the high-level design - before he implemented them in detail. For example, he needed macros to wrap HTML code in different tags, etc.</p>
<p>Test: Haskell programmers use type signatures to do this kind of thing. Sudoku - get a matrix filled with possibilities for each cell, give each cell the possibilities of its row, column, and box neighbours, remove certain possibilities, repeat till you get either a solved matrix or a matrix that doesn’t improve anymore. Each of these steps is doable. – you’ve got the high-level design for passing the test of “solving a Sudoku grid”.</p>
<p>Test: PG web page generator - if it initially created just one set of web pages, he may want to have code that generates new pages on demand, based on clicks. That would be a new integration test that he may not have thought of beforehand. – empirical usage gives you new ideas.</p>
<h2 id="integration-test-followed-by-unit-tests-write-unit-tests-as-demanded-by-your-new-features">Integration Test followed by Unit Tests (?? write unit tests as demanded by your new features)</h2>
<p><strong>Corollary</strong>: Write one failing integration test that doesn’t have any branches anywhere, come up with high-level design, write unit tests for each module, put it together -&gt; high-level design at speed, module design at speed, correctness.</p>
<p>Write just the failing integration test, no unit tests -&gt; may not handle certain cases - errors, high uncertainty about modules - slow, hesitate to change code.</p>
<p>No integration test, write just unit tests -&gt; uncertainty about design - slow, don’t know how to proceed.</p>
<hr />
<p>Test: OS HW3 - obtaining a free frame - if page was dirty, write it to the backing store. – got the high-level design, but don’t know if my <code>get_new_frame</code> function handle possible cases well. Hesitant to make global changes like adding a new field to <code>invpt_entry</code>.</p>
<h2 id="explaining-to-others-makes-your-input-and-output-explicit">Explaining to Others makes your Input and Output Explicit</h2>
<p><strong>Hypothesis</strong>: Explain to others -&gt; force you to categorize your situation, i.e., label the input and output variables; know exactly which variables you’re uncertain about (by looking at the positive and negative exemplars); can toggle those variables in an experiment or learn about their behaviour online.</p>
<hr />
<p><strong>Test</strong>: Was going to post a question to the TA online. Was going to say “the program crashes in gdb after the strcpy call”. But then I thought, come on, maybe that’s not the case. Try stepping to the next instruction (didn’t work) or try setting a breakpoint after the call. And that worked! – that simple experiment fixed a lot of things. All because I made my hypothesis explicit - “strcpy makes my program crash”. Immediately, I could think, “what if it isn’t strcpy?” and test it.</p>
<p>Test: Another question to the TA - wrote down a <a href="https://stackoverflow.com/help/mcve">“minimum, verifiable, complete”</a> description of my problem. – made it easy to see that the main reason why my program worked in gdb (positive exemplar) but not in the terminal (negative exemplar) was because of the environment (the diff between the two).</p>
<p>Test: Another example - wanted to ask a question about how to get two addresses from a program. Realized that I just needed one address. – all because I wrote it out.</p>
<p>Test: Another question to the TA - how to get the same random number in Python as from C’s rand(). Search online several times. Didn’t get it. Typed my question into the forum and decided to search one last time. Got it! – making my question explicit seemed to help. My vague half-hour’s worth of struggles boiled down to one simple query - “how to get the output of rand() using Python?”. Google for it and get the answer. (Narrowed down my uncertainty to one variable.)</p>
<h2 id="representative-test-cannot-be-passed-by-any-existing-function">Representative Test: Cannot be Passed by Any Existing Function</h2>
<p><strong>Hypothesis</strong>: Representative test = something that cannot be passed by any existing function.</p>
<p>(What if it could be passed by some other function in the future? I suspect that function would be longer and thus have its prior probability penalized.)</p>
<p><strong>Hypothesis</strong>: Mechanism, representative test -&gt; good experiment that gives you strong evidence about your mechanism?</p>
<hr />
<p>Test: <code>dropEnd :: Int -&gt; Seq a -&gt; Seq a</code> – Testing it with a list is not good enough. You could have just used <code>drop</code>. You have to use something for which no existing function would work. example: a pipe (or something).</p>
<p>Test: Applicative laws proof for AT (which is just a binary tree with a type variable):</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- To prove:</span>
<span class="dt">Law</span> <span class="dv">1</span><span class="fu">:</span> fmap snd <span class="fu">$</span> unit <span class="fu">*&amp;*</span> x <span class="fu">==</span> x

<span class="kw">where</span> (<span class="fu">*&amp;*</span>) <span class="fu">=</span> liftA2 (,)
unit <span class="fu">=</span> pure ()

<span class="dt">Super</span><span class="fu">-</span>simple example <span class="kw">of</span> <span class="dt">AT</span> <span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))
<span class="dt">Representative</span> example <span class="kw">of</span> <span class="dt">AT</span> <span class="fu">=</span> <span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">3</span>) (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))) (<span class="dt">L</span> <span class="dv">8</span>)

unit <span class="fu">=</span> <span class="dt">L</span> ()

<span class="dt">LHS</span> <span class="fu">=</span> fmap snd <span class="fu">$</span> unit <span class="fu">*&amp;*</span> x
<span class="fu">=</span> fmap snd <span class="fu">$</span> <span class="dt">L</span> () <span class="fu">*&amp;*</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))
<span class="fu">=</span> fmap snd <span class="fu">$</span> liftA2 (,) (<span class="dt">L</span> ()) (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))
<span class="fu">=</span> fmap snd <span class="fu">$</span> (pure (,) <span class="fu">&lt;*&gt;</span> (<span class="dt">L</span> ())) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))
<span class="fu">=</span> fmap snd <span class="fu">$</span> <span class="dt">L</span> ((),) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))
<span class="fu">=</span> fmap snd <span class="fu">$</span> (<span class="dt">B</span> (<span class="dt">L</span> ((), <span class="dv">4</span>)) (<span class="dt">L</span> ((), <span class="dv">7</span>)))
<span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))
<span class="fu">=</span> x
<span class="dt">Hence</span>, proved<span class="fu">.</span>

<span class="dt">Law</span> <span class="dv">2</span><span class="fu">:</span> fmap fst <span class="fu">$</span> x <span class="fu">*&amp;*</span> unit <span class="fu">=</span> x (<span class="dt">Right</span> identity)
<span class="dt">Super</span><span class="fu">-</span>simple example <span class="kw">of</span> <span class="dt">AT</span> <span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))

<span class="dt">LHS</span> <span class="fu">=</span> fmap fst <span class="fu">$</span> x <span class="fu">*&amp;*</span> unit
<span class="fu">=</span> fmap fst <span class="fu">$</span> (<span class="dt">L</span> (,) <span class="fu">&lt;*&gt;</span> x) <span class="fu">&lt;*&gt;</span> <span class="dt">L</span> ()
<span class="fu">=</span> fmap fst <span class="fu">$</span> (<span class="dt">L</span> (,) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))) <span class="fu">&lt;*&gt;</span> <span class="dt">L</span> ()
<span class="fu">=</span> fmap fst <span class="fu">$</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>,)) (<span class="dt">L</span> (<span class="dv">7</span>,))) <span class="fu">&lt;*&gt;</span> <span class="dt">L</span> ()
<span class="fu">=</span> fmap fst <span class="fu">$</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>,) <span class="fu">&lt;*&gt;</span> <span class="dt">L</span> ()) (<span class="dt">L</span> (<span class="dv">7</span>,) <span class="fu">&lt;*&gt;</span> <span class="dt">L</span> ()))
<span class="fu">=</span> fmap fst <span class="fu">$</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>, ())) (<span class="dt">L</span> (<span class="dv">7</span>, ())))
<span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))
<span class="fu">=</span> x

<span class="dt">Law</span> <span class="dv">3</span><span class="fu">:</span> fmap assocTuple <span class="fu">$</span> x <span class="fu">*&amp;*</span> (y <span class="fu">*&amp;*</span> z) <span class="fu">=</span> (x <span class="fu">*&amp;*</span> y) <span class="fu">*&amp;*</span> z (<span class="dt">Associativity</span>)
<span class="kw">where</span> assocTuple (x, (y, z)) <span class="fu">=</span> ((x, y), z)

<span class="dt">Super</span><span class="fu">-</span>simple example <span class="kw">of</span> <span class="dt">AT</span> <span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))

x <span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>))
y <span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">1</span>) (<span class="dt">L</span> <span class="dv">2</span>))
z <span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">8</span>) (<span class="dt">L</span> <span class="dv">9</span>))

<span class="dt">LHS</span> <span class="fu">=</span> fmap assocTuple <span class="fu">$</span> x <span class="fu">*&amp;*</span> (y <span class="fu">*&amp;*</span> z)
<span class="fu">=</span> fmap assocTuple <span class="fu">$</span> x <span class="fu">*&amp;*</span> ((<span class="dt">L</span> (,) <span class="fu">&lt;*&gt;</span> y) <span class="fu">&lt;*&gt;</span> z)
<span class="fu">=</span> fmap assocTuple <span class="fu">$</span> x <span class="fu">*&amp;*</span> ((<span class="dt">L</span> (,) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">1</span>) (<span class="dt">L</span> <span class="dv">2</span>))) <span class="fu">&lt;*&gt;</span> z)
<span class="fu">=</span> fmap assocTuple <span class="fu">$</span> x <span class="fu">*&amp;*</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">1</span>,)) (<span class="dt">L</span> (<span class="dv">2</span>,)) <span class="fu">&lt;*&gt;</span> z)
<span class="fu">=</span> fmap assocTuple <span class="fu">$</span> x <span class="fu">*&amp;*</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">1</span>,)) (<span class="dt">L</span> (<span class="dv">2</span>,)) <span class="fu">&lt;*&gt;</span> <span class="dt">B</span> (<span class="dt">L</span> <span class="dv">8</span>) (<span class="dt">L</span> <span class="dv">9</span>))
<span class="fu">=</span> fmap assocTuple <span class="fu">$</span> x <span class="fu">*&amp;*</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">1</span>,) <span class="fu">&lt;*&gt;</span> <span class="dt">B</span> (<span class="dt">L</span> <span class="dv">8</span>) (<span class="dt">L</span> <span class="dv">9</span>)) (<span class="dt">L</span> (<span class="dv">2</span>,) <span class="fu">&lt;*&gt;</span> <span class="dt">B</span> (<span class="dt">L</span> <span class="dv">8</span>) (<span class="dt">L</span> <span class="dv">9</span>)))
<span class="fu">=</span> fmap assocTuple <span class="fu">$</span> x <span class="fu">*&amp;*</span> (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">1</span>,<span class="dv">8</span>)) (<span class="dt">L</span> (<span class="dv">1</span>,<span class="dv">9</span>))) (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">2</span>,<span class="dv">8</span>)) (<span class="dt">L</span> (<span class="dv">2</span>,<span class="dv">9</span>))))
<span class="fu">=</span> fmap assocTuple <span class="fu">$</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>)) <span class="fu">*&amp;*</span> (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">1</span>,<span class="dv">8</span>)) (<span class="dt">L</span> (<span class="dv">1</span>,<span class="dv">9</span>))) (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">2</span>,<span class="dv">8</span>)) (<span class="dt">L</span> (<span class="dv">2</span>,<span class="dv">9</span>))))
<span class="fu">=</span> fmap assocTuple <span class="fu">$</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>,)) (<span class="dt">L</span> (<span class="dv">7</span>,))) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">1</span>,<span class="dv">8</span>)) (<span class="dt">L</span> (<span class="dv">1</span>,<span class="dv">9</span>))) (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">2</span>,<span class="dv">8</span>)) (<span class="dt">L</span> (<span class="dv">2</span>,<span class="dv">9</span>))))
<span class="fu">=</span> fmap assocTuple <span class="fu">$</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>, ) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">1</span>,<span class="dv">8</span>)) (<span class="dt">L</span> (<span class="dv">1</span>,<span class="dv">9</span>))) (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">2</span>,<span class="dv">8</span>)) (<span class="dt">L</span> (<span class="dv">2</span>,<span class="dv">9</span>))))) (<span class="dt">L</span> (<span class="dv">7</span>,) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">1</span>,<span class="dv">8</span>)) (<span class="dt">L</span> (<span class="dv">1</span>,<span class="dv">9</span>))) (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">2</span>,<span class="dv">8</span>)) (<span class="dt">L</span> (<span class="dv">2</span>,<span class="dv">9</span>))))))
<span class="co">-- Wow. And this is for the simplest B-values for x, y, and z!</span>
<span class="fu">=</span> fmap assocTuple <span class="fu">$</span> (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>, (<span class="dv">1</span>,<span class="dv">8</span>))) (<span class="dt">L</span> (<span class="dv">4</span>, (<span class="dv">1</span>,<span class="dv">9</span>)))) (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>, (<span class="dv">2</span>,<span class="dv">8</span>))) (<span class="dt">L</span> (<span class="dv">4</span>, (<span class="dv">2</span>,<span class="dv">9</span>))))) (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">7</span>, (<span class="dv">1</span>,<span class="dv">8</span>))) (<span class="dt">L</span> (<span class="dv">7</span>, (<span class="dv">1</span>,<span class="dv">9</span>)))) (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">7</span>, (<span class="dv">2</span>,<span class="dv">8</span>))) (<span class="dt">L</span> (<span class="dv">7</span>, (<span class="dv">2</span>,<span class="dv">9</span>))))))

<span class="dt">RHS</span> <span class="fu">=</span> (x <span class="fu">*&amp;*</span> y) <span class="fu">*&amp;*</span> z
<span class="fu">=</span> ((<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">4</span>) (<span class="dt">L</span> <span class="dv">7</span>)) <span class="fu">*&amp;*</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">1</span>) (<span class="dt">L</span> <span class="dv">2</span>))) <span class="fu">*&amp;*</span> z
<span class="fu">=</span> ((<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>,)) (<span class="dt">L</span> (<span class="dv">7</span>,))) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">1</span>) (<span class="dt">L</span> <span class="dv">2</span>))) <span class="fu">*&amp;*</span> z
<span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>,) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">1</span>) (<span class="dt">L</span> <span class="dv">2</span>))) (<span class="dt">L</span> (<span class="dv">7</span>,) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">1</span>) (<span class="dt">L</span> <span class="dv">2</span>)))) <span class="fu">*&amp;*</span> z
<span class="fu">=</span> (<span class="dt">B</span> ((<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>, <span class="dv">1</span>)) (<span class="dt">L</span> (<span class="dv">4</span>, <span class="dv">2</span>)))) ((<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">7</span>, <span class="dv">1</span>)) (<span class="dt">L</span> (<span class="dv">7</span>, <span class="dv">2</span>))))) <span class="fu">*&amp;*</span> z
<span class="fu">=</span> (<span class="dt">B</span> ((<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">4</span>, <span class="dv">1</span>)) (<span class="dt">L</span> (<span class="dv">4</span>, <span class="dv">2</span>)))) ((<span class="dt">B</span> (<span class="dt">L</span> (<span class="dv">7</span>, <span class="dv">1</span>)) (<span class="dt">L</span> (<span class="dv">7</span>, <span class="dv">2</span>))))) <span class="fu">*&amp;*</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">8</span>) (<span class="dt">L</span> <span class="dv">9</span>))
<span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> ((<span class="dv">4</span>, <span class="dv">1</span>), )) (<span class="dt">L</span> ((<span class="dv">4</span>, <span class="dv">2</span>), ))) (<span class="dt">B</span> (<span class="dt">L</span> ((<span class="dv">7</span>, <span class="dv">1</span>), )) (<span class="dt">L</span> ((<span class="dv">7</span>, <span class="dv">2</span>),)))) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">8</span>) (<span class="dt">L</span> <span class="dv">9</span>))
<span class="fu">=</span> (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> ((<span class="dv">4</span>, <span class="dv">1</span>), ) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">8</span>) (<span class="dt">L</span> <span class="dv">9</span>))) (<span class="dt">L</span> ((<span class="dv">4</span>, <span class="dv">2</span>), ) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">8</span>) (<span class="dt">L</span> <span class="dv">9</span>)))) (<span class="dt">B</span> (<span class="dt">L</span> ((<span class="dv">7</span>, <span class="dv">1</span>), ) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">8</span>) (<span class="dt">L</span> <span class="dv">9</span>))) (<span class="dt">L</span> ((<span class="dv">7</span>, <span class="dv">2</span>),) <span class="fu">&lt;*&gt;</span> (<span class="dt">B</span> (<span class="dt">L</span> <span class="dv">8</span>) (<span class="dt">L</span> <span class="dv">9</span>)))))
<span class="fu">=</span> <span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> ((<span class="dv">4</span>, <span class="dv">1</span>), <span class="dv">8</span>)) (<span class="dt">L</span> ((<span class="dv">4</span>, <span class="dv">1</span>), <span class="dv">9</span>))) (<span class="dt">B</span> (<span class="dt">L</span> ((<span class="dv">4</span>, <span class="dv">2</span>), <span class="dv">8</span>)) (<span class="dt">L</span> ((<span class="dv">4</span>, <span class="dv">2</span>), <span class="dv">9</span>)))) (<span class="dt">B</span> (<span class="dt">B</span> (<span class="dt">L</span> ((<span class="dv">7</span>, <span class="dv">1</span>), <span class="dv">8</span>)) (<span class="dt">L</span> ((<span class="dv">7</span>, <span class="dv">1</span>), <span class="dv">9</span>))) (<span class="dt">B</span> (<span class="dt">L</span> ((<span class="dv">7</span>, <span class="dv">2</span>), <span class="dv">8</span>)) (<span class="dt">L</span> ((<span class="dv">7</span>, <span class="dv">2</span>), <span class="dv">9</span>))))

<span class="dt">Damn</span>, they're equal<span class="fu">.</span> <span class="dt">I</span> thought my definition <span class="kw">of</span> <span class="dt">AT</span> was wrong (because it seemed to nest the right<span class="fu">-</span>hand <span class="dt">B</span> <span class="kw">in</span> <span class="dt">B</span> <span class="fu">&lt;*&gt;</span> <span class="dt">B</span><span class="fu">.</span>)<span class="fu">.</span></code></pre></div>
<p>Observation: I didn’t even use the case where it’s B &lt;*&gt; B. But that isn’t part of the Applicative definition. It’s covered under the case <code>B fx fy &lt;*&gt; x</code>.</p>
<h2 id="fully-specified-representative-test">Fully-Specified Representative Test (??)</h2>
<p><strong>Hypothesis</strong>: Test that sounds simple enough, but the implementation is pretty “complex” &lt;- lots of other conditions not specified in the test.</p>
<hr />
<p>Test: Pipes for XINU - sounds simple enough - just send the output of the writer as the input of the reader. – Problem: conditions like writer may be killed at any time, as can reader, the buffer may become full, one of them may starve due to low priority, etc. Your pipes implementation must handle all of these cases.</p>
<h2 id="extend-representative-test-with-every-diff">Extend Representative Test with every Diff (??)</h2>
<p><strong>Hypothesis</strong>: Extend your representative test with every diff. Either the diff will extend a chain or it will add a branch (or do some other thing). Your representative test should capture that.</p>
<p>Test: Super Mario - v1.0 - just jumping around. Next, moving forward too. – initial representative test is whether you can jump around; next test checks if you can move forward too (which is a different branch).</p>
<h2 id="acceptance-tests-must-transform-input-to-output-for-a-positive-exemplar">Acceptance Tests must transform Input to Output for a Positive Exemplar (??)</h2>
<p><strong>Hypothesis</strong>: Start with a minimal positive exemplar where the input uses only one or two features -&gt; can get feedback quickly; know exactly what to change in your code, therefore quick.</p>
<p>Start with a positive exemplar where the input uses lots of features -&gt; can’t get feedback until you have all features working; don’t know what to change when debugging, therefore slow.</p>
<p>Positive exemplar where you can see how the input is transformed into the output -&gt; can use it as a fully-specified acceptance test that helps you design your code; takes long to get feedback; hard to debug; slow. However, this might give you function-wise tests that produce quick feedback.</p>
<p>Don’t know the output for some input -&gt; can’t use it as a test.</p>
<p><strong>Lesson</strong>: Don’t talk about a hypothesis until you have at least one positive exemplar (ideally a minimal positive exemplar).</p>
<hr />
<p>Test: Tried to get an integration test for my learning mechanism - “Digits of a Number section 6.1, Bird.” – I have the input. But I don’t have the output! Can’t use it as a test (and get a high-level design).</p>
<p>Test: Phone number problem - just <code>10/783--5</code> to <code>neu o&quot;d 5</code> isn’t enough. – You need to show how you remove the punctuation, split the string, and lookup words in the dictionary. (fully-specified acceptance test)</p>
<p><strong>Test</strong>: Minimal positive exemplar - just enable paging with a global page directory and five global page tables and no per-process page directory - simple program; useful feature. Hmm… The output of the paging program could be pretty “complicated”. It may have involved page-fault handling, per-process page tables, page replacement, FIFO, backing store, etc. But we chose to target a small subset of that.</p>
<p>So, the challenge was to come up with an input that didn’t invoke page-fault handling or per-process page tables or page replacement or backing store accesses. The input was a string of memory references.</p>
<p>I could see that accessing an address beyond the first 4096 pages would cause a page fault because it wouldn’t have been in the global page tables and would need to be handled by the page fault handler, which I didn’t have. So, that was out.</p>
<p>Similarly, switching between processes and writing to the same virtual memory address would need to lead to different values. So, that was out too.</p>
<p>Ditto for reading so many different pages that I had to replace one of them or for reading from some page that had been evicted (and presumably saved to the backing store).</p>
<p>Explanation: Program + simple input should give simple output. However, if it gives some other output, then you know that you have to change something about the program. And because you’re changing just one feature in the program, you know exactly what to change and so can quickly implement the feature. Also, you can tell what functionality is added by that feature alone.</p>
<p>Test: Mario MVP - just jumping and moving. No princess or turtles or spiky pits. – can get feedback about that feature alone; quick because you know that any problems with the output must be due to the one feature you changed.</p>
<p>Test: Lots of features - scheduler - tried to change lots of things and was mired in debugging output. – slow to get final feedback; hard to debug. Basically had to change all parts of the default scheduler, instead of changing one thing at a time.</p>
<h2 id="unify-interfaces-for-ease-of-use">Unify Interfaces for Ease of Use</h2>
<p>Hypothesis: Common interface and common syntax means that you don’t have to learn different interfaces.</p>
<p>Idiosyncratic interfaces mean that you have to keep learning superficially different interfaces for the same kind of thing.</p>
<p>Corollary: Why text editors and shells rock - they provide the same interface to a ton of programs!</p>
<p>Corollary: Why <strong>books</strong> rock - unified interface to a ton of different fields.</p>
<hr />
<p><strong>Test</strong>: Bunnylol - <code>id &lt;car-id&gt; | &lt;person-id&gt; | &lt;product-id&gt;</code> is super easy to use.</p>
<p>This wouldn’t have been:</p>
<p><code>car-id &lt;car-id&gt;</code> <code>person-id &lt;person-id&gt;</code> <code>product-id &lt;product-id&gt;</code></p>
<p>And somebody would have been tempted to add specialized flags for each one. So, you would have to learn a whole new interface for each object you wanted to inspect.</p>
<p>You want the same thing from - to observe their fields and edges - and you shouldn’t have to do anything different for each one.</p>
<p><strong>Test</strong>: Ditto for <code>t Foo.php</code> and <code>t Foo</code> and <code>t foo/bar/</code> and <code>t foo/*</code> – I don’t have to remember different interfaces. (And t for running Hack tests and Jest tests and Python tests and whatnot.)</p>
<p>They all provide the interface of a set of tests. Just run them!</p>
<p><strong>Test</strong>: Note the <strong>meta</strong> interface of accessing <strong>all</strong> these tools from the same Chrome location bar! After all, why not?! – They all share the interface of taking some text and returning a web response.</p>
<p><strong>Test</strong>: Emacs deals with ASCII key strokes as the unified interface to all kinds of editing tasks. Want to write code? Rebase your commit? Delete files? It can all be done with a few keystrokes! – unified interface.</p>
<p><strong>Test</strong>: The shell deals with ASCII commands as the unified interface to all sorts of programs.</p>
<p>Test: Negative exemplar - GUI - have to learn a <strong>new interface</strong> for each task you want to do! – lots of different interfaces.</p>
<p><strong>Test</strong>: JFC! <strong>Books</strong> provide a unified interface to all kinds of knowledge! Want to learn about economics? Psychology? Programming? You can do all of that from the interface of a simple book. – unified interface.</p>
<p>Test: Tasks for everything - coding projects, bugs, bike repair, facilities requests, bike loan. – Talk about a unified interface!</p>
<p>Test: Diffs for everything - want to edit a gatekeeper? Have to get that diff reviewed! Cool! – unified interface for getting approval for things and for making changes first-class.</p>
<p><strong>Test</strong>: [2018-07-31 Tue] Google Cloud printer - simple interface for uploading a file - just upload to <strong>the</strong> cloud (not to a particular printer near you, whose name you have to find out); simple interface for printing a file - just go to any printer and pick the file from <strong>the</strong> cloud (instead of going to the particular printer to which you sent the file).</p>
<p>Printing with a cloud = upload to the cloud (easy), go to any printer you want (easy), and download from the cloud (pretty easy).</p>
<p>Printing with a particular printer = search for that printer and download drivers if needed (pretty hard), go to that particular printer (ok if you’ve gone and found the name of the printer near you), and print whatever file you sent (easy).</p>
<p>Basically, with specific printers, you have to learn a new interface each time you come across a new printer. With a cloud, you can reuse the same interface every time.</p>
<p>Test: The same screen-sharing and video-conferencing software in every meeting room. Don’t need to learn new interface.</p>
<p>Test: The same laptops and phones for everybody.</p>
<p>Test: The same chat software throughout the organization.</p>
<h1 id="refactoring-imposing-structure-on-your-code">Refactoring: Imposing Structure on your Code</h1>
<h2 id="refactoring-write-direct-tests-before-you-refactor---lower-cycle-time">Refactoring: Write Direct Tests before you Refactor (- lower cycle time)</h2>
<p><strong>Hypothesis</strong>: Don’t have direct tests, refactor -&gt; may break the code; hard to debug.</p>
<p>Don’t have tests, refactor -&gt; reasonably confident; easy to debug (narrow causes).</p>
<hr />
<p>Test: Phone number - trying to refactor <code>g</code> (yeah). The overall tests for <code>encode</code> keep failing. That’s because I don’t know the contract for <code>g</code> - I don’t have direct tests for it. So, I should see what behaviour it currently produces before I try to clean it up. – broke the code; hard to debug.</p>
<h3 id="refactoring-make-the-types-compose">Refactoring: Make the Types Compose</h3>
<p><strong>Hypothesis</strong>: Type signatures -&gt; can see which functions you can compose (and which you can’t and must rewrite); doesn’t take a genius.</p>
<p>No explicit type signatures -&gt; hard to see which functions you can compose; feels like it takes a genius.</p>
<hr />
<p>Test: Type of g:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">g ::</span> [<span class="dt">String</span>] <span class="ot">-&gt;</span> <span class="dt">M.Map</span> <span class="dt">Char</span> <span class="dt">Char</span> <span class="ot">-&gt;</span> (<span class="dt">String</span>, <span class="dt">String</span>) <span class="ot">-&gt;</span> [<span class="dt">String</span>]</code></pre></div>
<p>It’s not composable at all. It’s just a jumble of types. Specifically, it’s not <strong>closed</strong>. But I’d like to use it over and over, so I want it to be closed (either in the category of functions <code>a -&gt; a</code> or in the category of monads <code>a -&gt; m a</code>). – You can’t compose it with the external type of any other function.</p>
<p>Test: Hmm… Haskell programs generally express one unit of computation with their function types.</p>
<p>Representing the whole computation of phrases as <code>(PrefixDigits, SuffixDigits) -&gt; [Phrase]</code> hides the inner computations. We don’t know what’s happening underneath.</p>
<p>What are we actually doing? We want (a) <code>PhoneNumber -&gt; [Phrase]</code>. So, we are (b) breaking it into <code>(PrefixDigits, SuffixDigits)</code> pairs and then (c) encoding <code>PrefixDigits</code> as a <code>Token</code> (which could be a <code>WordToken</code> or a <code>DigitToken</code>) and then (d) recursively encoding <code>SuffixDigits</code> as <code>[Phrase]</code> and then (e) combining the <code>Token</code> and the <code>[Phrase]</code> such that there are no consecutive digits.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- (a) and (c)</span>
<span class="ot">encode ::</span> <span class="dt">PhoneNumber</span> <span class="ot">-&gt;</span> [<span class="dt">Phrase</span>]
<span class="co">-- (b)</span>
<span class="ot">allSplits ::</span> <span class="dt">PhoneNumber</span> <span class="ot">-&gt;</span> [(<span class="dt">PrefixDigits</span>, <span class="dt">SuffixDigits</span>)]
<span class="co">-- (c)</span>
<span class="ot">encodeToken ::</span> <span class="dt">PrefixDigits</span> <span class="ot">-&gt;</span> <span class="dt">Token</span>
<span class="co">-- (e)</span>
<span class="ot">combineToken ::</span> <span class="dt">Token</span> <span class="ot">-&gt;</span> [<span class="dt">Phrase</span>] <span class="ot">-&gt;</span> [<span class="dt">Phrase</span>]</code></pre></div>
<p>See how much cleaner that is! And, of course, I would make the types abstract (for example, <code>allSplits</code> doesn’t need to know if the argument is a <code>PhoneNumber</code> or anything; it can work on a simple list).</p>
<p>You can follow the computation from the types. The only way to get a <code>[Phrase]</code> is through <code>combineToken</code>, which needs a <code>Token</code>. We get that from <code>encodeToken</code>, which in turn takes inputs from <code>allSplits</code>. – They compose well with each other.</p>
<h2 id="to-refactor-an-impure-function-make-it-pure">To Refactor an Impure Function, Make it Pure</h2>
<p>Inference: Refactoring needs tests.</p>
<p>Hypothesis: Make it a pure function, observe the inputs and outputs for a sample execution -&gt; acceptance test -&gt; can induce easily.</p>
<hr />
<p>Test: <code>my-org-drill-insert-last-session-data</code> – took half an hour but it was much cleaner once I made it a pure function.</p>
<h2 id="writing-essays-for-others-forces-you-get-feedback">Writing Essays for Others forces you get Feedback</h2>
<p><strong>Hypothesis</strong>: Write essay meant to be published -&gt; actually run over each line with a reader’s eye, have to explain everything in detail -&gt; actually specify your model, actually get feedback.</p>
<p>Write stuff just for “internal use” -&gt; just go with what you feel is the output of the mechanism, can hand-wave over details -&gt; don’t specify your model, don’t get the feedback you could have got.</p>
<p>So, writing for yourself is like writing a 200-line function that you’ve never been tested. Writing for others is like writing a function that you will test pretty soon.</p>
<p><strong>Lesson</strong>: Consider your casual judgment to be a poor source of feedback. Instead, prefer the feedback of a reader (even if it’s an imaginary one that pipes up as you’re writing). So, write as close to the final medium as possible. That’s how you’ll force yourself to think like a reader.</p>
<p><strong>Hypothesis</strong>: Publishing online differentially reinforces clean writing.</p>
<hr />
<p>Test: Surrogate endpoints - stuck for nearly six hours on the one-to-one mapping proof for a simple n=1 inducing path. Wrote about it in the report. Found out that I was <strong>not</strong> going into an infinite recursion as I had thought. My approach was actually right. Why did this work when I was writing it out? – When I was writing the report, I was looking at it from the viewpoint of my professor, who’d be reviewing it. So, I wanted to make everything understandable.</p>
<h2 id="have-working-code-at-each-point-no-unstructured-notes">Have Working Code at Each Point: No Unstructured Notes</h2>
<p><strong>Hypothesis</strong>: Have working code (passes tests and is well-refactored), add a test and then a feature -&gt; go from pass to fail, and then from fail to pass -&gt; know that the latest change passed the test.</p>
<p>Have a mess, add a feature -&gt; go from fail to fail -&gt; can’t narrow down the causes; can’t tell whether the latest change helped.</p>
<p>Corollary: Start a project from scratch without dumping unstructured stuff -&gt; pass tests at each point.</p>
<p>Start a project by dumping unstructured stuff from somewhere -&gt; don’t pass tests at each point.</p>
<hr />
<p>Test: [2017-12-12 Tue] My current presentation draft is a mess. No idea of how much work really remains and how much doesn’t. – Don’t know if my additions really cut through.</p>
<p>Test: Negative exemplar - CS373 HW3 - I initially dumped all the text from my notes and the past assignment - had a tough time deciding how to go ahead – hard to tell if you’re making progress (fail to fail).</p>
<p>Test: CS373 HW3 - when I removed the old stuff, I could tell what was happening and what needed to be done and whether I was making progress – pass to fail or pass to pass.</p>
<p>Test: Cleaned causal hypothesis - started from scratch - easy to tell how things fit together – pass to pass.</p>
<p>Test: Causal hypothesis - a giant dump of ideas - hard to tell how things fit together – fail to fail.</p>
<p>Test: Current notes in this essay - pretty unstructured - hard to tell how much I’ve improved by adding one more idea – fail to fail.</p>
<h2 id="remember-to-refactor">Remember to Refactor</h2>
<p><strong>Hypothesis</strong>: After passing the test, reminder to refactor -&gt; refactor.</p>
<p>After passing the test, no reminder to refactor -&gt; don’t refactor.</p>
<hr />
<p>Test: initialize_nullproc_paging remained ugly. I didn’t refactor it. – no reminder.</p>
<h2 id="dont-rewrite-from-scratch">Don’t Rewrite from Scratch</h2>
<p><strong>Hypothesis</strong>: Old code that kind of works but is messy, rewrite from scratch -&gt; lose hard-won information (fixes for unintuitive and hard-to-find bugs) stored in the ugly code.</p>
<p>Old code that kind of works but is messy, refactor or at least use as a testing model for your snazzy new function -&gt; keep the hard-won information.</p>
<p>Lesson: Feel like throwing away old code or prose -&gt; refactor or use as a model instead.</p>
<hr />
<p>Test: Joel Spolsky on rewriting (working but ugly) code from scratch -</p>
<blockquote>
<p>The idea that new code is better than old is patently absurd. Old code has been used. It has been tested. Lots of bugs have been found, and they’ve been fixed. There’s nothing wrong with it. It doesn’t acquire bugs just by sitting around on your hard drive. Au contraire, baby! Is software supposed to be like an old Dodge Dart, that rusts just sitting in the garage? Is software like a teddy bear that’s kind of gross if it’s not made out of all new material?</p>
<p>Back to that two page function. Yes, I know, it’s just a simple function to display a window, but it has grown little hairs and stuff on it and nobody knows why. Well, I’ll tell you why: those are bug fixes. One of them fixes that bug that Nancy had when she tried to install the thing on a computer that didn’t have Internet Explorer. Another one fixes that bug that occurs in low memory conditions. Another one fixes that bug that occurred when the file is on a floppy disk and the user yanks out the disk in the middle. That LoadLibrary call is ugly but it makes the code work on old versions of Windows 95.</p>
<p>– <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/"></a></p>
</blockquote>
<p>Explanation: Would lose bug fixes.</p>
<p>Test: Essay on understanding - 42k words as of December 23, 2017. Feel like just throwing it away and building a new model from scratch using my latest format for unit tests and such. Experimental method! - But no, that would make me forget or have to re-generate hard-won evidence from over the last 8 months. (Roughly 100 hours of work - 155 words in commit 5116ad9 took 22 minutes @ 422 words per hour - where I was exposed to a variety of information such as causality math, biology text, category theory proofs, programming experiments on myself and others, and my Purdue course work - most of which would be hard to reproduce.) You do <strong>not</strong> want to lose that processed evidence. – Better to use it as a reference model and assimilate its evidence into a new model.</p>
<h1 id="valuable-use-cases">Valuable Use Cases</h1>
<h2 id="scenarios-make-something-users-want">Scenarios: Make Something Users Want</h2>
<p>Hypothesis: Come up with scenarios (not input-output specifications) -&gt; make something users want.</p>
<p>Come up with input-output specifications -&gt; make something that works as per your specification but which nobody may want.</p>
<hr />
<p>Test: Joel Spolsky - talking about scenarios where a businessman would want to use his website. If he makes it correctly (and if the businessman really does want such a feature), he would have made something users want.</p>
<blockquote>
<p>Scenarios. When you’re designing a product, you need to have some real live scenarios in mind for how people are going to use it. Otherwise you end up designing a product that doesn’t correspond to any real-world usage (like the Cue?Cat). Pick your product’s audiences and imagine a fictitious, totally imaginary but totally stereotypical user from each audience who uses the product in a totally typical way. Chapter 9 of my UI design book (available online for free) talks about creating fictional users and scenarios. This is where you put them. The more vivid and realistic the scenario, the better a job you will do designing a product for your real or imagined users, which is why I tend to put in lots of made-up details.</p>
<p>– <a href="https://www.joelonsoftware.com/2000/10/03/painless-functional-specifications-part-2-whats-a-spec/"></a></p>
</blockquote>
<h1 id="refactoring-decoupling-the-problem">Refactoring: Decoupling the Problem</h1>
<h2 id="case-study-input-for-format-string-exploit">Case Study: Input for Format String Exploit</h2>
<p><strong>Hypothesis</strong>: Extract a function with explicit free arguments -&gt; encapsulate its contents, i.e., make it clear that its contents are decoupled from other things.</p>
<p>Hypothesis: Local variables clutter things up (h/t Martin Fowler). Not exactly sure why.</p>
<p>Hypothesis: Without local variables, a function is easy to parse. You know that you put all the inputs together using a final function call.</p>
<p>With local variables, however, a function gets harder to parse because there is no clear, final flourish.</p>
<p>(I suspect this also makes the code harder to invert.)</p>
<hr />
<p>Test:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">format_writes <span class="op">=</span> <span class="st">''</span>.join([p[<span class="dv">0</span>] <span class="cf">for</span> p <span class="op">in</span> pairs] <span class="op">+</span> [p[<span class="dv">1</span>] <span class="cf">for</span> p <span class="op">in</span> pairs])</code></pre></div>
<p>Need a better way to do that. (Can’t find any. <code>operator.add(*zip(*xs))</code> is too obscure.)</p>
<p>In Haskell, it’s <code>uncurry (++) . unzip</code>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">*</span><span class="dt">Main</span><span class="fu">&gt;</span> <span class="kw">let</span> xs <span class="fu">=</span> [(<span class="st">&quot;yo&quot;</span>, <span class="st">&quot;boyz&quot;</span>), (<span class="st">&quot;I&quot;</span>, <span class="st">&quot;am&quot;</span>), (<span class="st">&quot;sing&quot;</span>, <span class="st">&quot;song&quot;</span>)]
<span class="fu">*</span><span class="dt">Main</span><span class="fu">&gt;</span> unzip xs
([<span class="st">&quot;yo&quot;</span>,<span class="st">&quot;I&quot;</span>,<span class="st">&quot;sing&quot;</span>],[<span class="st">&quot;boyz&quot;</span>,<span class="st">&quot;am&quot;</span>,<span class="st">&quot;song&quot;</span>])
<span class="fu">*</span><span class="dt">Main</span><span class="fu">&gt;</span> uncurry (<span class="fu">++</span>) <span class="fu">.</span> unzip <span class="fu">$</span> xs
[<span class="st">&quot;yo&quot;</span>,<span class="st">&quot;I&quot;</span>,<span class="st">&quot;sing&quot;</span>,<span class="st">&quot;boyz&quot;</span>,<span class="st">&quot;am&quot;</span>,<span class="st">&quot;song&quot;</span>]</code></pre></div>
<p><strong>Test</strong>: Need to abstract every concrete value and every free variable in the expression.</p>
<p>For example, in</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">(<span class="st">'</span><span class="sc">%s%s</span><span class="st">'</span> <span class="op">%</span> (pack(<span class="st">'&lt;L'</span>, address), pack(<span class="st">'&lt;L'</span>, address <span class="op">+</span> <span class="dv">2</span>)), <span class="st">'</span><span class="sc">%%%d</span><span class="st">c</span><span class="sc">%%%d</span><span class="st">$n</span><span class="sc">%%%d</span><span class="st">c</span><span class="sc">%%%d</span><span class="st">$n'</span> <span class="op">%</span> (<span class="bn">0x00000</span> <span class="op">+</span> least_significant_half(value) <span class="op">-</span> <span class="dv">25</span> <span class="op">-</span> <span class="dv">12</span>, <span class="dv">344</span>, <span class="bn">0x10000</span> <span class="op">+</span> most_significant_half(value) <span class="op">-</span> least_significant_half(value), <span class="dv">345</span>))</code></pre></div>
<p>we have the value <code>0x00000</code>, the offset <code>-25 - 12</code>, the printf index <code>344</code>, and <code>0x10000</code>.</p>
<p>Test: I’m naming each part of the program the way I think about it in my mind.</p>
<p>Test: Type-checking errors or run-time errors tell you what dependencies you haven’t handled yet.</p>
<div class="sourceCode"><pre class="sourceCode zsh"><code class="sourceCode zsh">  File <span class="st">&quot;input-for-fsa2.py&quot;</span>, line 26, <span class="kw">in</span> get_format_string_setters
    setter_pairs, <span class="kw">(</span>[], initial_state<span class="kw">)</span>
NameError: global name <span class="st">'setter_pairs'</span> is not defined</code></pre></div>
<p>So I forgot to pass in the argument <code>setter_pairs</code> to <code>get_format_string_setters</code>.</p>
<p>Test: Overall, there are too many variables to pass around. Do I just create a first-class object containing all of them? They are uncorrelated. – it was tough. Still don’t know the best answer.</p>
<p>Test: Assumptions - least significant half is <code>(hexval % (1 &lt;&lt; 16))</code>; that <code>%n</code> is how you write to different locations; that <code>0x10000 + least_significant_half(value) - num_chars_so_far</code> will write the least significant bytes of the value to the given address; etc. (Wow. It’s been a long time since I’ve had the space to reflect on my code.)</p>
<p>Test: How would I test my code? What properties am I testing for? I’m testing that the final format string will write to the 12 bytes starting at RIP and that it won’t overwrite the stack cookie.</p>
<h1 id="algebra-of-programming">Algebra of Programming</h1>
<p><strong>Acceptance test</strong>: Algebra of programming - maximum segment sum (from Bird, Thinking Functionally with Haskell).</p>
<p>Given the problem statement “get the segment with maximum sum”</p>
<p>when I calculate the program</p>
<p>then I should get</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">mss ::</span> [<span class="dt">Int</span>] <span class="ot">-&gt;</span> <span class="dt">Int</span>
mss <span class="fu">=</span> maximum <span class="fu">.</span> map sum <span class="fu">.</span> segments
<span class="co">-- This is O(n^3).</span>
<span class="fu">=</span> maximum <span class="fu">.</span> map sum <span class="fu">.</span> concat <span class="fu">.</span> map inits <span class="fu">.</span> tails
<span class="co">-- map f . concat = concat . map (map f) [fusion law?]</span>
<span class="fu">=</span> maximum <span class="fu">.</span> concat <span class="fu">.</span> map (map sum) <span class="fu">.</span> map inits <span class="fu">.</span> tails
<span class="co">-- functor law</span>
<span class="fu">=</span> maximum <span class="fu">.</span> concat <span class="fu">.</span> map (map sum <span class="fu">.</span> inits) <span class="fu">.</span> tails
<span class="co">-- maximum . concat = maximum . map maximum [??; where the input is a non-empty list of non-empty lists]</span>
<span class="fu">=</span> maximum <span class="fu">.</span> map maximum <span class="fu">.</span> map (map sum <span class="fu">.</span> inits) <span class="fu">.</span> tails
<span class="co">-- functor law [this is O(n^3) because of map (map sum)]</span>
<span class="fu">=</span> maximum <span class="fu">.</span> map (maximum <span class="fu">.</span> map sum <span class="fu">.</span> inits) <span class="fu">.</span> tails
<span class="co">-- map sum . inits = scanl (+) 0 [scanl law]</span>
<span class="fu">=</span> maximum <span class="fu">.</span> map (maximum <span class="fu">.</span> scanl (<span class="fu">+</span>) <span class="dv">0</span>) <span class="fu">.</span> tails
<span class="co">-- scanl (@) e = foldr f [e] where f x xs = e:map (x@) xs [NOT SURE]</span>
<span class="co">-- So, maximum . scanl (+) 0 = foldr1 (&lt;&gt;) . foldr f [e] where f x xs = e:map (x@) xs</span>
<span class="co">-- fusion law calculation</span>
<span class="co">-- maximum . scanl (+) 0 = foldr (@) 0</span>
<span class="fu">=</span> maximum <span class="fu">.</span> map (foldr (<span class="fu">@</span>) <span class="dv">0</span>) <span class="fu">.</span> tails, <span class="kw">where</span> x <span class="fu">@</span> y <span class="fu">=</span> <span class="dv">0</span> <span class="ot">`max`</span> (x <span class="fu">+</span> y)
<span class="co">-- map (foldr f e) . tails = scanr f e</span>
<span class="co">-- O(n)</span>
<span class="fu">=</span> maximum <span class="fu">.</span> scanr (<span class="fu">@</span>) <span class="dv">0</span>, <span class="kw">where</span> x <span class="fu">@</span> y <span class="fu">=</span> <span class="dv">0</span> <span class="ot">`max`</span> (x <span class="fu">+</span> y)</code></pre></div>
<p><strong>Acceptance test</strong>: Algebra of programming - greedy algorithm.</p>
<p>Given the shortest path problem</p>
<p>when I try to use algebra to get the answer</p>
<p>then I should get Dijkstra’s.</p>
<h2 id="inverse">Inverse</h2>
<p><strong>Hypothesis</strong>: <code>unfoldr f' . foldr f z = id</code> when f’ can recover x and xs from the given value and replace f with <code>(,)</code>. Also f’ z must be the empty list.</p>
<p>Test: Basic - get inverse for <code>foldr (:) []</code> aka the identity function.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">*</span><span class="dt">Main</span><span class="fu">&gt;</span> <span class="kw">let</span> g [] <span class="fu">=</span> <span class="dt">Nothing</span>; g (x<span class="fu">:</span>xs) <span class="fu">=</span> <span class="dt">Just</span> (x,xs)
<span class="fu">*</span><span class="dt">Main</span><span class="fu">&gt;</span> unfoldr g [<span class="dv">1</span><span class="fu">..</span><span class="dv">5</span>]
[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>]</code></pre></div>
<p>Test: Get inverse for <code>foldr (+) 0 $ [1..5]</code>. The answer is 15. We need to recover the original list using that value. Can’t be done.</p>
<p>Explanation: Can’t replace (+) with (,) in 15 because it could be (3 + 12) or (8 + 7) or whatever.</p>
<p>Test: Get inverse for <code>foldr raiseAndAdd 0 $ [3, 8, 4]</code> (which converts the decimal representation of 483 (<code>[3, 8, 4]</code>) into the natural number 483.)</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">raiseAndAdd n d <span class="fu">=</span> <span class="dv">10</span> <span class="fu">*</span> d <span class="fu">+</span> n</code></pre></div>
<p>When it comes to raiseAndAdd n d = v, we need to replace raiseAndAdd with (,) using just v. Can we recover n and d from v? We know that n &lt; 10. And 10 * d is a multiple of 10, so we can get n using v % 10. And d = v / 10.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">*</span><span class="dt">Main</span><span class="fu">&gt;</span> <span class="kw">let</span> g <span class="dv">0</span> <span class="fu">=</span> <span class="dt">Nothing</span>; g v <span class="fu">=</span> <span class="dt">Just</span> (v <span class="ot">`mod`</span> <span class="dv">10</span>, v <span class="ot">`div`</span> <span class="dv">10</span>)
<span class="fu">*</span><span class="dt">Main</span><span class="fu">&gt;</span> unfoldr g <span class="dv">384</span>
[<span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">3</span>]</code></pre></div>
<p>Test: exponent - No idea.</p>
<p>Test: Sudoku</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">checkSudokuSolution mx <span class="fu">=</span> and <span class="fu">$</span> liftA2 notElem mx (peers mx)
(checkSudokuSolution <span class="fu">.</span> solveSudoku <span class="fu">$</span> inputMatrix) <span class="fu">==</span> <span class="dt">True</span></code></pre></div>
<p>We can infer that for every index x of the matrix, <code>notElem (at x mx) (at x (peers mx)) = True</code>.</p>
<p>Now, we need to get an equation for mx (which is the output of <code>solveSudoku inputMatrix</code>).</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">notElem x xs <span class="fu">=</span> foldr ((<span class="fu">&amp;&amp;</span>) <span class="fu">.</span> (<span class="fu">/=</span> x)) <span class="dt">True</span> xs</code></pre></div>
<p>We can tell that x must belong to <code>[1..9] \\ xs</code>.</p>
<p>That just gives us the brute-force combinatorial solution where we generate all possible Sudoku matrices.</p>
<p>No, wait. We get to choose which x gets assigned a value first. We can choose cells that have the least number of possible values (hopefully, just one) and go in increasing order of choices.</p>
<p>The above equation doesn’t actually capture the case where each cell has multiple choices filled in. (Basically, that would be the output of your Sudoku solver when there aren’t enough initial numbers.)</p>
<p>The real equation should consider your choices and your peers’ choices. For example, if you could have 2 or 3 but a peer has just one value 3, then you know your value is 2.</p>
<p>Not sure.</p>
<p><strong>Hypothesis</strong>: The property equation for f has both the input and the output -&gt; can get an inverse for f.</p>
<p>Test: <code>(checkSudokuSolution . solveSudoku $ inputMatrix) == True</code> - you don’t have an equation relating the input and output of <code>checkSudokuSolution</code>. – How are you supposed to get its inverse?</p>
<p>When it came to the phone number problem, I had <code>(foo . bar) xs = ys</code>. Then, I could say <code>xs = (foo . bar)' ys</code>.</p>
<p>Here I have only <code>True</code> on the RHS, which may not be enough.</p>
<p>Test: RPN calculator</p>
<p>Couldn’t get a property that the final solution must satisfy.</p>
<p>Hypothesis: Maybe use <code>f xs@(x ++ y ++ operator) = operator (f x) (f y)</code> where x and y are guaranteed to be in RPN. Solve for f.</p>
<p>One solution is to remove the operator from the end and try different splits for x and y such that they are well-formed and satisfy the equation. How to narrow that down to one solution?</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">f xs <span class="fu">=</span> head <span class="fu">.</span> map (\[x, y, operator] <span class="ot">-&gt;</span> apply operator (f x) (f y)) <span class="fu">.</span> filter (\[x, y, operator] <span class="ot">-&gt;</span> isOperator operator <span class="fu">&amp;&amp;</span> isRPN x <span class="fu">&amp;&amp;</span> isRPN y) <span class="fu">.</span> allSplits <span class="fu">$</span> xs</code></pre></div>
<p>This will work. However, we want something faster. Can we split such that the x, y, and operator are guaranteed to be in the desired format?</p>
<h3 id="inverse-reduce-duplication-of-work">Inverse: Reduce Duplication of Work</h3>
<p>Corollary: If inverse-oriented programming works out, then it would reduce a lot of our work.</p>
<p>Right now, we seem to be duplicating work instead of reusing old code.</p>
<hr />
<p>Test: We can see that <code>toNat = foldr raiseAndAdd 0</code>. Now, given that <code>toDec</code> is the inverse of <code>toNat</code>, why should we search anew for a function that exactly satisfies the equation <code>toNat . toDec = id</code>? – We are disregarding the valuable information we have in terms of <code>toNat</code>’s definition.</p>
<h3 id="inverse-algebra---solve-for-the-unknown-variables">Inverse: Algebra - Solve for the Unknown Variables</h3>
<p>Hypothesis: <code>f . g . foo . bar $ x = y</code> - you want to solve for <code>foo</code> and <code>bar</code>. But since you have only one equation, you can’t solve them uniquely. You need one more property.</p>
<p>Corollary: Programming becomes like algebra. Holy crap! Algebra of Programming!</p>
<hr />
<p>Test: Paging - <code>pageReplacement . pageFaultHandling $ addressStream = outputStream</code> - you have two unknowns. – One equation won’t suffice.</p>
<h3 id="inverse-implement-laws-as-functions">Inverse: Implement Laws as Functions</h3>
<p>Hypothesis: Implement laws as functions (like <a href="https://github.com/gbaz/works-in-progress/tree/master/algebra-of-programming">Bazerman</a>) -&gt; can understand them faster.</p>
<hr />
<p>Test: Saw functor algebra as <code>((+), 0)</code> – really easy to understand. Do one thing for each case of the ADT.</p>
<h3 id="inverse-resources">Inverse: Resources</h3>
<p>https://courses.cs.ut.ee/2006/algebraofprog/Main/HomePage</p>
<h3 id="inverse-interview-questions">Inverse: Interview Questions</h3>
<p>Test: Subset sums problem.</p>
<p>Property:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">all (\xs <span class="ot">-&gt;</span> ((<span class="fu">==</span> target) <span class="fu">.</span> sum) xs <span class="fu">&amp;&amp;</span> all (elem target) (nub xs)) <span class="fu">$</span> subsetsWithSum target candidates <span class="fu">=</span> <span class="dt">True</span></code></pre></div>
<h2 id="fold-fusion">Fold Fusion</h2>
<h3 id="my-attempts">My Attempts</h3>
<p>Hypothesis: Fold fusion law:</p>
<blockquote>
<p>If we have the following properties:</p>
<ol style="list-style-type: lower-roman">
<li>h is a strict function.</li>
<li>h (f x y) = g x (h y), for all x and y in the appropriate ranges</li>
</ol>
<p>Put b = h(a).</p>
<p>Then: h . foldr f a = foldr g b.</p>
</blockquote>
<p>Don’t know why h has to be a strict function.</p>
<p><strong>Hypothesis</strong>: <code>g x (h y) == h (f x y)</code> simply says that the outputs of (A) <code>h . foldr f a</code> and (B) <code>foldr g b</code> are the same for any suffix of the list.</p>
<p>Base case: When it’s just the empty list, A returns h a and B returns b, which we set as h a. So, the claim holds.</p>
<p>Induction step: Assume the claim holds for the suffix y, so that <code>h (foldr f a y) == foldr g b y</code>. When foldr moves to the first element x, A returns <code>h (f x (foldr f a y))</code> and B returns <code>g x (foldr g b y)</code>. The latter is <code>g x (h (foldr f a y))</code> by the induction hypothesis. By the second assumption, it becomes <code>h (f x (foldr f a y))</code>. Hence, proved.</p>
<p>So, the two assumptions are enough to prove the claim for any list.</p>
<p>Question: How to derive g?</p>
<p><strong>Hypothesis</strong>: You can simply set <code>g x y = h (f x y)</code>.</p>
<h2 id="fusion-law-bird">Fusion Law: Bird</h2>
<p><strong>Hypothesis</strong>: Fusion law: <code>f . foldr g a = foldr h b</code> where f is a strict function, <code>b = f a</code>, and <code>f (g x y) = h x (f y) for all x and y</code>.</p>
<p>Has to be strict because we need <code>f undefined = undefined</code>.</p>
<p><code>b = f a</code> is for the empty list case.</p>
<p>When the list is (x:xs),</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="dt">LHS</span> <span class="fu">=</span> f (g x (foldr g a xs))
<span class="dt">RHS</span> <span class="fu">=</span> h x (foldr h b xs)
<span class="dt">Assume</span> the induction hypothesis holds for xs
<span class="dt">So</span>, f (foldr g a xs) <span class="fu">=</span> foldr h b xs<span class="fu">.</span>
<span class="dt">Therefore</span>, <span class="kw">if</span> h x (f y) <span class="fu">=</span> f (g x y) for all x and y, the law will hold<span class="fu">.</span></code></pre></div>
<p><strong>Corollary</strong>: <code>foldr f a . map g = foldr (f . g) a</code>.</p>
<hr />
<p>Test:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">foldr f a <span class="fu">.</span> map g
<span class="fu">=</span> foldr f a <span class="fu">.</span> foldr ((<span class="fu">:</span>) <span class="fu">.</span> g) []
<span class="co">-- We want the output of the form `foldr h b`.</span>
<span class="co">-- (i) b = foldr f a [] = a</span>
<span class="co">-- (ii) foldr f a is a strict function (?).</span>
<span class="co">-- (iii) h x (f y) = f (g x y) for all x and y.</span>

<span class="co">-- We have handled the cases where the input is undefined or an empty list.</span>
<span class="co">-- Now for (x:xs).</span>
<span class="co">-- Condition (iii) means f (g x xs) = h x (f xs)</span>
<span class="co">-- foldr f a (((:) . g) x xs) = h x (foldr f a xs) for all x and xs.</span>
<span class="co">-- foldr f a (g x : xs) = h x (foldr f a xs) for all x and xs.</span>
<span class="co">-- (f (g x) (foldr f a xs)) = h x (foldr f a xs) for all x and xs.</span>

<span class="co">-- h x y = f (g x) y [Note: This f is different from the f in the equation.]</span>
<span class="co">-- h = f . g</span></code></pre></div>
<p>Test: double . sum = foldr ((+) . double) 0</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">double <span class="fu">.</span> sum
<span class="co">-- somehow (I'm guessing by a natural transformation, even though it's Num a, not a)</span>
<span class="fu">=</span> sum <span class="fu">.</span> map double
<span class="fu">=</span> sum <span class="fu">.</span> foldr ((<span class="fu">:</span>) <span class="fu">.</span> double) []
<span class="co">-- fusion law for foldr . map</span>
<span class="co">-- (i) sum is strict</span>
<span class="co">-- (ii) z = sum []</span>
<span class="co">-- (iii) sum (((:) . double) x xs) == g x (sum xs)</span>
<span class="co">-- WRONG =&gt; g x xs = double x : xs</span>
<span class="co">-- sum (double x : xs) == g x (sum xs)</span>
<span class="co">-- foldr (+) 0 (double x : xs) == g x (sum xs)</span>
<span class="co">-- double x + foldr (+) 0 xs == g x (sum xs)</span>
<span class="co">-- double x + sum xs == g x (sum xs)</span>
<span class="co">-- double x + ys == g x ys</span>
<span class="fu">=</span> foldr ((<span class="fu">+</span>) <span class="fu">.</span> double) <span class="dv">0</span></code></pre></div>
<p>Test: length . concat = foldr ((+) . length) 0</p>
<p>concat :: [[a]] -&gt; [a] length :: [a] -&gt; Int</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">length <span class="fu">.</span> concat
<span class="co">-- HOW?!</span>
<span class="fu">=</span> sum <span class="fu">.</span> map length
<span class="fu">=</span> foldr (<span class="fu">+</span>) <span class="dv">0</span> <span class="fu">.</span> map length
<span class="fu">=</span> foldr ((<span class="fu">+</span>) <span class="fu">.</span> length) <span class="dv">0</span></code></pre></div>
<p>Test: <code>length . cp</code></p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">length <span class="fu">.</span> cp
<span class="fu">=</span> length <span class="fu">.</span> foldr (liftA2 (<span class="fu">:</span>)) [[]]
<span class="co">-- fusion law</span>
<span class="co">-- (i) length is strict</span>
<span class="co">-- (ii) z = length [[]] = 1</span>
<span class="co">-- (iii) length (liftA2 (:) x xs) = g x (length xs)</span>
<span class="co">-- length x * length xs = g x (length xs)</span>
<span class="co">-- length x * ys = g x ys</span>
<span class="co">-- g = (*) . length</span>
<span class="fu">=</span> foldr ((<span class="fu">*</span>) <span class="fu">.</span> length) <span class="dv">1</span>
<span class="fu">=</span> foldr (<span class="fu">*</span>) <span class="dv">1</span> <span class="fu">.</span> map length
<span class="fu">=</span> product <span class="fu">.</span> map length</code></pre></div>
<p>Test: <code>maximum . map sum . subseqs</code></p>
<p>Naively - <code>subseqs</code> will take O(2^n) time. <code>map sum</code> will take O(2^n * n/2) time.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">maximum <span class="fu">.</span> map sum <span class="fu">.</span> subseqs
<span class="fu">=</span> maximum <span class="fu">.</span> map sum <span class="fu">.</span> foldr f [[]] <span class="kw">where</span> f x xss <span class="fu">=</span> xss <span class="fu">++</span> map (x<span class="fu">:</span>) xss
<span class="co">-- fusion law</span>
<span class="co">-- (i) map sum is strict</span>
<span class="co">-- (ii) z = map sum [[]] = [0]</span>
<span class="co">-- (iii) map sum (f x xss) == g x (map sum xss)</span>
<span class="co">-- = map sum (xss ++ map (x:) xss) == g x (map sum xss)</span>
<span class="co">-- Naturality of map!</span>
<span class="co">-- = map sum xss ++ map sum (map (x:) xss) = g x (map sum xss)</span>
<span class="co">-- = map sum xss ++ map (\yss -&gt; sum (x:yss)) xss = g x (map sum xss)</span>
<span class="co">-- = map sum xss ++ map (\yss -&gt; sum ([x] ++ yss)) xss = g x (map sum xss)</span>
<span class="co">-- = map sum xss ++ map (\yss -&gt; sum [x] + sum yss) xss = g x (map sum xss)</span>
<span class="co">-- = map sum xss ++ map ((sum [x] +) . sum) xss = g x (map sum xss)</span>
<span class="co">-- = map sum xss ++ map (sum [x] +) (map sum xss) = g x (map sum xss)</span>
<span class="co">-- = zss ++ map (sum [x] +) zss = g x zss</span>
<span class="co">-- g x xs = xs ++ map (sum [x] +) xs</span>
<span class="co">-- g x xs = xs ++ map (x +) xs</span>
<span class="fu">=</span> foldr (\x xs <span class="ot">-&gt;</span> xs <span class="fu">++</span> map (x <span class="fu">+</span>) xs) [<span class="dv">0</span>]</code></pre></div>
<p>This will take: O(1) time for the base case. T(n+1) = 2 * T(n) =&gt; T(n) = O(2^n). Not fully sure.</p>
<p>Bird to the fucking rescue:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="fu">=</span> maximum <span class="fu">.</span> foldr (\x xs <span class="ot">-&gt;</span> xs <span class="fu">++</span> map (x <span class="fu">+</span>) xs) [<span class="dv">0</span>]
<span class="co">-- fusion law</span>
<span class="co">-- (i) maximum is strict</span>
<span class="co">-- (ii) z = maximum [0] = 0</span>
<span class="co">-- (iii) maximum (f x xs) == g x (maximum xs)</span>
<span class="co">-- maximum (xs ++ map (x+) xs) == g x (maximum xs)</span>
<span class="co">-- maximum xs `max` maximum (map (x+) xs) == g x (maximum xs)</span>
<span class="co">-- maximum xs `max` (x + maximum xs) == g x (maximum xs)</span>
<span class="co">-- ys `max` (x + ys) == g x ys</span>
<span class="co">-- g x y = y `max` (x + y)</span>
<span class="fu">=</span> foldr g <span class="dv">0</span></code></pre></div>
<p>An O(fucking N) algorithm!</p>
<p>(And, as he notes, you can simply drop negative numbers :P - <code>sum . filter (&gt; 0)</code>).</p>
<h2 id="universal-property-of-fold">Universal Property of Fold</h2>
<p><strong>Hypothesis</strong>: <code>foldr f e (xs ++ ys) = foldr f e xs @ foldr f e ys</code></p>
<p>It holds when <code>f = (@)</code> with identity <code>e</code>.</p>
<p><strong>Corollary</strong>: When you have map f (xs ++ ys), you can simply distribute it: map f xs ++ map f ys.</p>
<hr />
<p>Test: <code>map sum (xss ++ map (x:) xss) = map sum xss ++ map sum (map (x:) xss)</code> – yeah.</p>
<h2 id="natural-transformation">Natural Transformation</h2>
<p><strong>Hypothesis</strong>: When the types are polymorphic, you can do stuff to the type before or after without affecting the result.</p>
<hr />
<p>Types:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">head<span class="ot"> ::</span> [a] <span class="ot">-&gt;</span> a
tail<span class="ot"> ::</span> [a] <span class="ot">-&gt;</span> [a]
concat<span class="ot"> ::</span> [[a]] <span class="ot">-&gt;</span> [a]
reverse<span class="ot"> ::</span> [a] <span class="ot">-&gt;</span> [a]</code></pre></div>
<p>Test: <code>f . head = head . map f</code> – yeah.</p>
<p>Test: <code>map f . tail = tail . map f</code> – yeah.</p>
<p>Test: <code>map f . concat = concat . map (map f)</code> – yeah.</p>
<p>Test: <code>map f . reverse = reverse . map f</code> – yeah.</p>
<p>Test: <code>concat . map concat = concat . concat</code> – yeah.</p>
<p>Test: <code>filter p . map f = map f . filter (p . f)</code> - don’t know how you came to that.</p>
<p>Test: <code>map (map f) . cp = cp . map (map f)</code> – ok. Understandable.</p>
<p>where <code>cp :: [[a]] -&gt; [[a]]</code>.</p>
<p>Test: <code>filter (all p) . cp = cp . map (filter p)</code> – did it by intuition.</p>
<h2 id="birds-approach-in-functional-pearls">Bird’s Approach in Functional Pearls</h2>
<blockquote>
<p>I was interested in the specific task of taking a clear but inefficient functional program, a program that acted as a specification of the problem in hand, and using equational reasoning to calculate a more efficient one.</p>
<p>– Bird, Preface, Pearls of Functional Algorithm Design</p>
</blockquote>
<p>I’d like to know how to derive a program using just the contract properties and not necessarily a working inefficient model.</p>
<p>For example, given <code>(checkSudoku . solveSudoku) grid == True</code> and the definition of <code>checkSudoku</code>, write <code>solveSudoku</code>.</p>
<p>And I know this can be done because we did it for the <code>toDecimal</code> problem using the definition of <code>toNaturalNumber</code> and the property <code>toNaturalNumber . toDecimal = id</code>.</p>

<div class="info">Created: October 20, 2017</div>
<div class="info">Last modified: October 26, 2018</div>
<div class="info">Status: in-progress notes</div>
<div class="info"><b>Tags</b>: notes, one-button</div>

<br />
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'spkrationalitytrainingground'; // required: replace example with your forum shortname
    var disqus_identifier = '/one-button-change.html';
    var disqus_title = 'One-Button Change';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
	var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
