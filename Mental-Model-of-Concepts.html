<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel="icon" type="image/png" href="./images/favicon-32x32.png" sizes="32x32" />
	<link rel="icon" type="image/png" href="./images/favicon-16x16.png" sizes="16x16" />
        <title>Mental Model of Concepts - SPK's Rationality Essays</title>
        <link rel="stylesheet" type="text/css" href="./css/default.css" />
        <link rel="stylesheet" type="text/css" href="./css/highlight.css" />

	<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script> -->
	<!-- <script type="text/javascript" src="/js/header-links.js"></script> -->
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

	<link href="atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed" />

	<!-- Google Analytics stuff -->
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-51321929-1', 'pradeep90.github.io');
	  ga('send', 'pageview');

	</script>

    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="./">Rationality Essays</a>
            </div>
            <div id="navigation">
                <a href="./">Home</a>
                <a href="./notes.html">Notes</a>
                <!-- <a href="/about.html">About</a> -->
                <a href="./archive.html">Archive</a>
		<a href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed">RSS</a>
            </div>
        </div>

        <div id="content">
          <h1 id="post-title">Mental Model of Concepts</h1>

            <!-- <center><img src="https://fbcdn-sphotos-d-a.akamaihd.net/hphotos-ak-prn1/t31.0-8/p600x600/10257116_10202295769100492_2438594605053717342_o.jpg" height="400" width="300" class="sujeet-pic" alt="Sujeet pic" /></center> -->

<p><strong>Key Question</strong>: What are the most valuable and surprising ideas I have?</p>
<hr />
<h1 id="overall-aim">Overall Aim</h1>
<p>I want to figure out ways to think better and then tailor them for humans. I want to install these techniques in my brain. This, of course, involves testing my skills empirically. And I want to do all this quickly, for which I need more mental control (via motivation) and efficiency (via cognitive psychology). I also need to take uncomfortable actions, which requires that I have good boundaries and a strong sense of worthiness.</p>
<p>In short, I want to practice and research epistemic rationality at speed.</p>
<h1 id="most-valuable-ideas">Most Valuable Ideas</h1>
<h2 id="concepts">Concepts</h2>
<p>Remember that these aren’t valid ideas unless you’ve published essays about them. Divide them into decoupled pieces and tackle them independently.</p>
<p>How to decouple them? Figure out your goals and ask if two parts might be used independently of each other. If so, separate them. For example, somebody can use the high-entropy advice without needing to know how to reduce information theory to probability theory.</p>
<p>Write them to answer the question: How can I use this idea to solve problems? Prioritize the most valuable ideas. Mere curiosities can wait.</p>
<p>Remember the fundamental rule: when stuck, use a concrete example! Take a concrete real-world information-processing problem - or even better, three - and show which of these “important” ideas you need. If you don’t need them, why are they on the list?</p>
<ul>
<li><p>Causal models - understand them better; learn to use them everywhere. (Why I only look at the minute hand of the wall clock when judging time spans: because the hour doesn’t matter! It’s conditionally independent. Similarly, why I never bothered to remember concrete details - I felt they didn’t have any value of information. They wouldn’t change my decisions.)</p>
<p>Think of everything in terms of hypotheses and evidence. Specifically, think in terms of causal models. Aim to reduce all your problems to causal models, variables, and evidence.</p>
<p>Even more specifically, identify your variables. Then, look at their immediate causes and get evidence (correlations and interventions) to build some causal models. Then, look at their differing predictions to run good experiments and get the right causal model.</p>
<p>TODO: What are the conditions for something to be a variable?</p>
<p>What does a JPD look for a system over time? I don’t know that yet. I think the different configurations in the JPD are the alternative timelines of the world. It’s like you have a program with three variables. If you don’t know anything else, then all their combinations seem possible: initially all are off; in the first second, A turns on; in the next second, B goes on and A turns off; then C becomes on; then A turns off; etc. However, if you refactor the code, you may find that C is always set based on A and B. Now, you can factorize the JPD, i.e., eliminate many of the possible timelines. This, by the way, is (a big reason) why duplicated code is evil - you have to deal with many more timelines aka code paths than are actually possible. If you don’t know that C is set by A and B, then you will assume that anything might happen, and you have to do costly analysis to prove your code is right.</p>
<p>TODO: Show using some example programs how the code paths are related to your JPD and uncertainty. Reduce common “software engineering principles” to probability theory.</p>
<p>Also, think about the difference between structure learning and parameter learning.</p>
<p>TODO: Later, bring in ideas from your journals.</p>
<p>Hypothesis: Defining categories is the major work in writing an essay (as in all human thinking). Coming up with good concrete examples (with lots of details) is the heavy lifting you have to do.</p>
<p>That is also why you have to write to a neutral smart reader, because then you’re forced to make your categories explicit and convey them, instead of assuming you just know them.</p>
<p>You can test this by looking at people’s essays and book chapters. Where do they spend much of the chapter? Could there be a good reason for that? At the end of the chapter, you can boil it down to a simple one-sentence causal model (poverty is what you want to attack, not economic inequality). But that’s only because you have learned the categories behind them (I theorize).</p>
<p>However, designing good abstractions and making the problem domain-independent is a huge deal too. It takes a while to peel off the jargon and get the problem to a simple model that even an outsider can understand.</p>
<p>Key question: How long does it take to learn a new category, of the sort that is in an essay or book chapter? You should be able to use it in your models comfortably, and recognize it in any situation (like supply vs demand).</p>
<p>Remember the skills of anticipation-constraints, etc. (from your journal notes).</p>
<p>Programmers worry about change because that defines the variables of interest. If the message string is going to change, then extract it into a variable of its own, so that the display function becomes decoupled from the message string.</p>
<p>Why are long functions bad? Because you could change any of the logic inside it. So what? Then, you would have to deal with a tangled mess and change a lot of the other parts. It’s hard to reason about such a function . In other words, you’re dealing with a raw JPD instead of factorizing it into orthogonal pieces.</p>
<p>Answer everything using “because”. Sheldon: “… because her face is too midwestern, etc.”</p></li>
<li><p>Decoupling and abstractions</p>
<p>You can break a complex task into decoupled pieces and tackle them independently. Nobody writes a song by searching within the space of all possible word combinations. That’s just inefficient.</p>
<p>Look at your stack notes.</p>
<p>Talk about rapid prototyping and the need for good abstractions.</p>
<p>The mathematical definition of good design. Look at journal notes.</p></li>
<li><p>Value of Information - show that information is useless unless it can change your decisions; apply this to various everyday sources of “information”; The hypothesis that simple abstractions are possible.</p>
<p>What is the VoI of academic research?</p></li>
<li><p>Locality of causality - generate alternative hypotheses for this variable by permuting its direct causes.</p>
<p>How do we handle causality when the JPD itself isn’t with us and the algorithm for finding conditional independence leads to combinatorial explosion? Massive reduction in uncertainty comes from locality of causality! Time and space to the rescue. Also, human categories do most of the work. Where did those “variables” come from? Then, human observations of correlations do some more work. Like noticing that overweight and internet are correlated, in the fictitious example. Lastly, and best, interventions give you the purest evidence about the causal structure.</p>
<p>Hug the Effects. Think in terms of direct causes. Exploit locality of causality.</p></li>
<li><p>Information and entropy - reduction to probability theory; look at things in terms of bits and learn quickly! Seek high entropy.</p>
<p>Remember conservation of expected evidence. Talk about when you win and when you change big (from notes).</p>
<p>Applications: for writing, convey only valuable surprises.</p>
<p>MCQs give you a ton of information by narrowing it down to just 4 options. That leaves a maximum of 2 bits of uncertainty. However, I suspect MCQs are bad (as retrieval tests) only when they fail to make you retrieve and just ask you to recognize the answer. The JEE questions forced you to retrieve plenty.</p>
<p>This resource - <a href="http://arxiv.org/abs/0808.0012">Lectures on Probability, Entropy, and Statistical Physics</a> - talks about Bayesian inference from different angles. Follows in the tradition of ET Jaynes. Basically says that probability theory and entropy is ideally all you need for reasoning. Also talks about entropy, but in an axiomatic way, because it satisfies certain desired characteristics.</p>
<p>Check out other Jaynes works on this site: https://derekelkins.github.io/readinglist.html</p>
<hr />
<p>Constraining your anticipation: if you’re so confident about your understanding of the fundamentals of problem-solving (Bayesian inference), make predictions about the future. If the ideas are so powerful, they should narrow your uncertainty about the future.</p>
<p>If processing information is what we need to do, then all the revolutions of the future, all the improvements in technology, all the insights will be Bayesian in nature. They will be about reducing uncertainty by decoupling things - finding conditional independences - and building better categories. Those that exploit locality of causality will win. Those that use causal models will win (I predict). Those that use value of information and entropy in guiding their search will win. Ditto for decision theory. For example, the better programming languages will be those that provide abstractions that enable you to decouple more things. You shouldn’t have to wrestle with a dozen variables to write a simple sorting function (I’m looking at you, C++).</p>
<p>To make it more vivid, you will never win (I feel) by changing to a way that does not decouple things or does not build better categories. Not seeking valuable information will not help you. Making claims about things that are far away from each other should serve you worse than talking about things that are closer, and so if your abstractions force you to talk about faraway stuff, you’re doomed (example?).</p>
<p>Also, the past should also have been about an increasing trend towards using Bayesian inference - decoupling more things, etc. Test that.</p>
<p>Essential question: What will the tools of the future look like? What about the domains of the future? What about the techniques in each field? What about the educational techniques? I’m not saying I know the answers to these questions. I’m just pointing out that if you claim to know fundamental properties about the nature of reasoning in general, human thinking in particular (cognitive psychology), and about taking the best actions (decision theory?), then you should be able to infer some things about the thinking techniques of the future, the teaching techniques, the work techniques, etc.</p>
<p>Trying to answer these questions should both show your idea’s limitations and make you aware of what you actually expect to see. If you believe it strongly enough, hopefully you can exploit it. After all, one way to success is to “Live in the future, then build what’s missing.” (from PG’s How to Get Startup Ideas)</p>
<p>I’m just ripping off PG’s thought-provoking question:</p>
<blockquote>
<p>What kind of programming language will they use to write the software controlling those flying cars? This is worth thinking about not so much because we’ll actually get to use these languages as because, if we’re lucky, we’ll use languages on the path from this point to that.</p>
</blockquote>
<hr />
<p>Maybe memorize a table of entropy contributions for any probability (p = 1/2 -&gt; contribution of -1/2 log(1/2) = 0.5 bits). This way you can estimate entropy very quickly.</p>
<p>TODO: Information can be cheap to transmit because it tells you how to construct an efficient code for any transmission medium - send the fewest messages. (Check out more on this <a href="http://www.extrafancy.net/bethany/chapter2.php">economics site</a>). Information by nature seems to be easy to duplicate (if your underlying medium is not costly). Perhaps this could be why music and software piracy is not easy to restrict. RMS’ Free Software solution really might be canonical.</p>
<p>Also look at <a href="https://en.wikibooks.org/wiki/Communication_Theory/Uncertainty_Reduction#C._Criticisms_of_URT">uncertainty reduction theory</a>.</p>
<hr />
<p>Language is a means of storing and communicating information. It’s not something innocent or coincidental. Does it decide the cues you will use to store memories? Does it decide the shape of those memories? In short, if you don’t store direct probabilities in your mind (the way we don’t use probabilities in our prose), then the quality of the language may decide the amount of information you store. (Or it could be that you store probabilities some other way and cues and memories have nothing to do with it.) Remember that we use words and phrases to describe categories.</p>
<p>TODO: Writing an optimizing compiler seems to be about minimizing the expected running time of the code. For that, you need to have valuable information about what’s going to happen next. That way, you can optimize the cache and have the right answers ready when you need them. I suspect that if you have lower uncertainty about the code, you will have lower expected running time. Not sure exactly how this would work.</p>
<hr />
<p>Information-processing when you’re fully uncertain about all the hypotheses is nothing but search within a space of hypotheses.</p>
<p>Hypothesis: Information-processing, in general, is nothing but searching within a space where the density of the hypotheses is proportional to your prior probability for them (or equivalently, you’re likely to hit an item proportional to your probability for it). So, if you have four hypotheses with probabilities 25%, 20%, 10%, and 45%, then you can imagine a space of 100 items with 25 of them being of type A, 20 of type B, 10 of type C, and 45 of type D. You pick up one item at a time and test it with your criteria.</p></li>
<li><p>Categories - remember the three tasks of scientific thinking - design categories (in some format that scales to lots of domains), recognize them, and reason using them. This is how you get variables, I suspect. Design categories that have low entropy, somehow.</p>
<p>Why keeping your top ten problems or concepts in mind can help (as per Feynman): because you get to change your perception of problems. You pay selective attention to different details and thus form more informative categories, instead of just missing them totally.</p>
<p>Seeing with fresh eyes is (I suspect) nothing but paying selective attention to different things. When that girl in Pirsig’s story was trying to write about Bozeman, she was paying selective attention to nothing in particular and was coming up blank. But then, she started paying selective attention to one little brick… and suddenly there was no stopping her. She got a ton of information this way.</p>
<p>Why do concrete examples help break through thinking blocks? Because they make you pay selective attention to different things and thus build categories and actually move forward in your modelling. What happens when you don’t pay selective attention to different things? Why are you stuck then? Somehow your brain returns a total of zero solutions when you ask it (why?). For example, right now I’m asking my brain “why do you get stuck when you don’t pay selective attention to different things?” over and over again. But it doesn’t have an answer for that. So, I don’t make progress.</p>
<p>I think it’s because in that moment you don’t have enough evidence to chew on. Your mind can only work with evidence that is actually at the front of it (I think). Otherwise, it halts like a car out of fuel, even if you have a can of fuel in the trunk of your car. The fuel needs to actually be inside the engine for things to work. So, I guess using different categories (via selective attention on other features) lets you access memories that your mind can use as fuel.</p>
<hr />
<p>Your worldview changes after certain events, like before and after your first drink, cigarette, or lover. Before, you classify things using a black or white category - for example, “smokers are bad people”. But after you’ve done it yourself, you start to see a lot finer distinctions. Collect these kinds of worldview changes.</p>
<p>Have categories for consequentialist reasoning. You need to categorize things by their consequences, not by their random features. One of the diagnostic features should be: Is this valuable? Will it create different consequences?</p>
<p>Ask: what does a category forbid? How does it focus your uncertainty?</p>
<hr />
<p>Questions I still want to answer: How exactly do we categorize? What features do we use? How can we change those features? Who decides the diagnostic features for a category? Importantly, how many concepts can we learn in an hour?</p>
<p>Get prototypical examples for each important concept you have. Also, identify or design good diagnostic keys for those categories.</p>
<p>Going from a concept to concrete examples seems like a separate skill from the other way around. How can you improve your performance? Much of the difficulty in writing a publishable essay seems to be in getting good (or just any) concrete examples.</p>
<p>“A wise man learns from other people’s mistakes” - Most of the time, the only evidence we have is our own past experience. For a social skill like public speaking, I draw lessons only from my (meagre) past speeches - “simplify the slides more than you think you will need to; make an effort to speak loudly; lift your head and look past the first row”. I don’t use the example of others (except for spectacular failures maybe - “don’t mumble throughout the speech; don’t keep looking back at your slides”). This is inefficient. If we don’t accept concrete examples from others’ lives, we are limited in the concepts that we understand. We have only got so many examples that we can recollect.</p>
<p>Perhaps this is why we have role models. It’s difficult to learn from abstract maxims (“always ask people for evidence behind their statements”) perhaps because we don’t know <strong>when</strong> to apply them. But when we see it in action (Draco claiming that Lucius really loves him and Harry responding with “how do you know that?”), we get a much better feel for it. Plus, you can have a role model for every trait you want develop, the way Harry in HPMOR has in his mind Ravenclaw for cleverness, Gryffindor for courage, etc.</p>
<p>Corollary: So it’s not silly to have role models. But everybody seems to be ridiculing everybody, so it doesn’t feel safe to have anyone as our role model. For example, I respect the heck out of Alain de Botton. He’s taught me many valuable things about living well. However, he’s obviously not a scientist or even a very empirically minded person (he accepts outdated psychological theories from people like Freud or theories of genetic inheritance from Schopenhaeur).</p>
<p>He’s given some (what seem to me like) spot-on hypotheses about status anxiety, romance, atheism, fame, pessimism, art, work, difficulties, etc. The man’s a genius, as far as I’m concerned. But he’s also dead wrong about a few specific things. Why should that be a problem?! Why is it so hard to accept something that is mostly great but has a few flaws?</p>
<p>I think it’s because I fear that people will zoom in on those flaws and denigrate me for associating with such an obviously “unscientific” person like Alain. It’s as if saying that he has some great ideas means that I’m endorsing everything he says! Nobody is perfectly smart, or the world wouldn’t be the way it is. So, if you can’t have a role model unless he is perfect, then you can’t have role models at all.</p>
<hr />
<p>Chiefly, the specific seems inferior to the general. It feels silly to try to solve <em>only</em> this one little problem when I could be trying to solve all problems of this type. Yes, in a sense, the general solution for this class of problems is superior to the specific solution for this problem. You have strictly more power in the former case. However, humans apparently can’t reason well with general ideas. We need exemplars for our mind to chew on before we can infer general solutions.</p>
<p>So, focus on specific problems first, then generalize. For example, I’m wondering how we can build categories for a particular domain, like photography. Instead of musing about the theory, I should actually go and ask how to take a good outdoors shot. Only then will my brain <em>actually</em> make the effort to get the necessary evidence.</p>
<p>It is in the gap between your slow logic and your fast categories that <strong>naive realism</strong> creeps in. You have some logical definition in your mind, which may or may not correspond to reality, but you think it works well. But you can’t use it to solve any practical problems at all! For that, you need to break through the illusion of knowledge and <em>actually</em> interact with reality. You need to <em>actually</em> build categories using examples and realize several things that you were just not paying attention to. Only once you pick up a ton of such dead-obvious but hitherto invisible information can you make a justified leap to logic. Until then, keep yourself grounded in reality.</p>
<hr />
<p>Once you realize that this is an algorithm, not magic, you feel more confident. You feel more in control. It’s the difference between a strategy and a plan. In the former, I can actively manipulate the system and get results, instead of praying for good things to happen.</p>
<p>Prediction: When you have just one hypothesis, you make all your judgments using it. You act like there are no other hypotheses at all. When you get one more hypothesis, I think you’re forced to generalize. (Like in the 2-4-6 task. When you see 1-3-5, you realize that it’s not just about even numbers. And so on.) You need to see more than one exemplar hypothesis.</p>
<p>Look at the complexity essay for notes on how cached thoughts (however they work) and the slowness of the brain makes it impossible to think up great original thoughts on the spot. You have to work up to a solution. (Or do you? Are there tricks like finding good abstractions?)</p>
<p>Release a rough end-to-end model of human thinking.</p>
<p>Epistemic rationality seems to be mainly about metacognitive strategies. These are the thought equivalents of “code smells”: thought smells. Look at “try”, “impossible”, argument - anticipated consequences, “mystery”, “it <em>is</em> like that” - mind projection fallacy, Fundamental Question of Rationality, etc.</p>
<p>Mirror neurons - I bet you can explain it in terms of cues.</p>
<p>Comedy seems to be all about setting up expectations and defeating them. For example, some interviewee was making random statements about her state (“It’s a real state and the people are very real…”) and the interviewer (John Oliver) said “Could you be any more generic?”. You expect the interviewer to go along with the platitudes, but instead he calls it out. I think there’s more to it than just defeating expectations - not all unexpected things are funny (like Sheldon dropping his pants in an attempt to be shocking and funny). I think it’s about surprise, not unexpected behaviour. All surprises are unexpected things, but not all unexpected things are surprises, thanks to human cognitive quirks.</p>
<p>Anyway, my point here is that we humans use a few cues to identify a category - like big plus stripes plus yellow colour implies a tiger. We can infer the other characteristic like big claws, high speed, dangerous, etc. And finally my hypothesis is that comedians use these diagnostic cues, which are perfectly good enough to identify the probable category (tiger), to instead talk about something else that also fits those cues (like a giant wasp!).</p>
<hr />
<p>Consequentialism in terms of human cognition: What is the opposite of consequentialism? Lost purposes. Why does that happen?</p>
<p>Hypothesis: Because we judge our <em>success</em> using measurements other than actual success.</p>
<p>We look at the concrete cues and build an abstract cue of our “success”, just that we choose the wrong cues. Like number of hours at work, number of advanced degrees, or the impressiveness of your startup’s office.</p>
<p>We need to build a set of associations like “profit -&gt; success” or “number of hard problems I can solve -&gt; math ability” and remove the existing misguided ones. Professor Quirrell calls this “intent to kill” - judging yourself <em>only</em> by the final goal.</p>
<blockquote>
<p>To him, any idea which fell short of [his standard of killing the enemy] was not worth considering. This reflects a quality that we might call intent to kill.</p>
</blockquote>
<p>This is why we need to use a dashboard measuring the important end variables, just as (I think) was prescribed by the book Continuous Delivery.</p>
<hr />
<p>When will your writing suck? When you don’t write in a decision-oriented manner and don’t specify your cues and responses in detail, especially with exemplars. Then, you’re just talking in abstract, floating labels. Like in my post on <a href="./Resolving-Confusion.html">resolving confusion</a> - “More Predictive Power means more Win”, “When you are Confused, you won’t even realize what the events in the Territory are”, etc. You don’t have any clear way to identify “confusion” in reality nor to apply these ideas and test them.</p></li>
<li>Relation between goals, queries, and abstraction levels; compile-time costs vs run-time costs; no fully-general models.</li>
<li><p>Need to design a step-by-step, start-to-end algorithm for learning, research, and problem-solving (using empirical examples).</p></li>
</ul>
<h2 id="techniques">Techniques</h2>
<p>Only practice techniques that you’ve written essays about. I need to start using the above ideas on themselves. For example, decouple parts of my tasks, seek high-entropy experiments when figuring out what to do, etc.</p>
<ul>
<li><p>Empiricism and Naive realism - actually do stuff! #counter</p>
<p>Mainly, do something 25 times, not just once or twice! That’s what it means to actually apply it.</p>
<p>Fundamental question of rationality: What do you think you know and how do you think you know it? Make your claims explicit and ask whether you’ve given evidence to support them.</p>
<p>For example, when I saw Eliezer’s causal model post and thought that you could get Bayesian networks from the JPD and so we could all use causal models everywhere. But I didn’t know how to do that. I didn’t ask how you would get the JPDs (or how big they would be). And I didn’t ask how to get the Bayesian network from the JPD. Part of this was that I saw the exercise-overweight-internet example and thought that it should be doable. I didn’t probe the essay to see exactly what algorithm he used to get the conditional independence. The whole thing hinged on finding conditional independence and I didn’t know how to do that (mathematically)!</p>
<p>I trusted there would be some practical algorithm out there somewhere. I knew that AI people used Bayesian networks in several places, so it couldn’t be completely impractical. I think I made the right prediction. Eliezer and other high-profile researchers wouldn’t back this idea so much if it couldn’t be applied fruitfully.</p>
<p>The key message of the post - the biggest surprise - was that you could talk about cause and effect meaningfully using math (not just correlation, as was thought) and that you can infer causation from correlation (using certain assumptions). For the first claim, you could see that once you had a causal model, you could predict all kinds of things in line with our causal intuitions.</p>
<p>The second claim was where I fell down. I didn’t understand the subtlety or take it to its logical conclusion. Checking all the possible combinations for even a single conditional independence would be tiresome. The JPD is so damn big. And, most importantly, you don’t even have it in most cases - it really is too big. So, the claim is not that you can practically infer correlations from a JPD, it is that you can infer causation from <em>correlation</em> (using certain assumptions). Humans still have to notice and supply the correlation themselves (plus design the variables).</p>
<p>In short, the claim is that you can practically infer causation from correlation, not from JPDs.</p>
<p>I failed to notice the feeling of confusion when I worked on a concrete example. I didn’t realize that finding even a single conditional independence was beyond tedious. (Concrete examples rock once again, btw).</p></li>
<li>Taboo - (what informational work are you doing when you taboo?)</li>
<li>What are the alternative hypotheses (causal models)?</li>
<li>Look only at the differing predictions.</li>
<li>Think only in terms of causal models and evidence, or information. What are the immediate causes? Use this skill everywhere! Remember, locality of causality is a massive source of conditional independence!</li>
<li>What would falsify your hypothesis? (I think this opens a new category in our minds. Else, we’re always focussed on what it predicts, not what it forbids. They are duals of each other, sure, but our brain doesn’t see it that way.)</li>
<li><p>Start from the evidence. Don’t privilege any hypothesis.</p></li>
</ul>
<h2 id="techniques-for-control-and-efficiency">Techniques for Control and Efficiency</h2>
<ul>
<li><p>Deliberate practice - actually apply those principles; do thousands of reps.</p>
<p>I think varied reps are for soft skills - where you have to be able to recognize and react to unknown stimuli (like the curve ball vs fast ball example in Make it Stick). For hard skills, I think it’s more important to practice the same thing over and over till it becomes automatic. (Not sure about this.)</p></li>
<li>Boundaries and Worthiness (boundary for revise and refactor time. Maybe 15m everyday to refresh my memory on the important problems and make drills for things I forgot.); set deadlines - allot a certain number of days to a project.</li>
<li><p>Deep thinking - no distractions, full focus; Remember, I believe that you can solve any problem with deep thinking. (What are its limits, though?)</p>
<p>Most of the time, I don’t think deeply. What are the causes of deep thinking?</p>
<p>PG says, and I agree, that it takes at least an hour before you can come up with new insights. So, work in long, uninterrupted sessions.</p>
<p>Focus on one problem at a time. Solve it completely before you move on. This way you make visible progress and, most importantly, you force yourself to work harder.</p></li>
<li>Cognitive psychology - simplify, chunk, and always think in terms of <em>concrete</em> examples (remember what <code>2 + 2 = 4</code> did?). Plus categorization and deep thinking. Plus, sustainable hard work, repeated fresh attacks, and compounding of daily results over time. And spaced repetition.</li>
<li>Write essays - It’s not a real idea unless you’ve published an essay about it. So, my aim is to publish an essay about each of the concepts here.</li>
<li>Continuous Delivery</li>
<li>After-Action Report</li>
<li>Commentary for Causality and other resources</li>
<li><p>Motivation equation, willpower, gamification - satisfying work, fun failure, etc.</p>
<p>Design your tasks with the motivation equation in mind. Distinguish between satisfying work and problem-solving - you don’t have to work with completely unfamiliar problems all the time. Sometimes, you can do stuff that you know <em>how</em> to do.</p>
<p>The key constraint on number of hours of deliberate practice per day is about 3-5 hours. Check out <a href="http://cogsci.stackexchange.com/questions/4514/what-is-the-most-effective-maximum-work-duration-per-day">this page</a> for Ericsson’s statements on hours per day, and also other research relevant to effective work durations. However, this is for deliberate practice. You can spend much of the remaining time doing satisfying work, with the extreme being game-playing. So, do some “busy” work that needs to be done - stuff like testing yourself on old ideas, reading books, refactoring existing essays, etc.</p></li>
<li><p>Reading books and not surfing the web or watching videos (to build up linear, deep thinking - as opposed to scattered internet thinking)</p>
<p>Reading principle: Don’t highlight more than one phrase per page. Also, aim to breeze through the chapter once and write down your notes and then highlight phrases, etc. on the second pass (if there is one).</p></li>
</ul>
<h1 id="where-to-go-from-here">Where to go from here</h1>
<p>Write essays about the important concepts above. Practice the techniques like hell. Test them empirically (and locally) - seek a lot of information about their worth. Also, implement techniques that boost your control and efficiency. Once you’ve explained your concepts so far, figure out better ones. Finally, decide the relative importance of these aspects and divide your time accordingly.</p>
<p>My six hours everyday belong to the above goals. I should do nothing else in that time. Take two hours for writing an essay everyday. Perhaps half an hour for implementing some principles and the rest of the time for practice.</p>
<h1 id="miscellaneous-concepts">Miscellaneous Concepts</h1>
<p>Prediction Book - apply information theory here - seek high entropy, etc. Look at the difference between calibration and discrimination. Also, what skill are you trying to practice? Predicting correctly in the heat of the moment, or just before you do something, or days before, or weeks in advance? Also test how your predictions are affected by evidence. Look at your old essay about making predictions effectively.</p>
<h1 id="notes">Notes</h1>
<p>I need to organize my concepts well so that I can recall them easily.</p>
<p>In fact, I need to start with a simple structure and improve it over time.</p>
<h2 id="the-question-you-really-want">The question you really want</h2>
<p>The question I really want answered is: how do I split up my daily working time? That’s why I want to collect my ideas, so that I can spend time working on them. It doesn’t matter (here) whether I have a giant list of all my concepts. The only thing that matters is whether I spend my time on the right stuff.</p>
<p>Lesson: Don’t ask <em>what</em> you need to write; ask <em>why</em>. What will you do with it?</p>
<p>So, what stuff do I need to work on? Where will I get the most value?</p>
<p>I seem to know an ordering among my ideas but not on a relative scale; I can tell which ideas are more important than others but not how much more important they are. So, given that any idea needs a minimum time investment to pay off, the best I can do is to fit in ideas that are most valuable till I have no more time. Therefore, think about how much time you need to spend on the top ideas over the next one month and stop when the needed daily time exceeds my current budget (6 hours).</p>
<p>6 hours per day for the rest of this month makes for around 160 hours. How will you spend your next 160 hours?</p>
<hr />
<p>Actually, see through even the need to split up time. What I actually want to know is which essays to write (and thus which concepts to figure out), which techniques to practice, and which principles to implement. These are the three kinds of tasks I will do. The only questions are the order in which I will give them inputs and the proportions of these three tasks.</p>
<p>I need only specify 3-4 essay topics. The rest will follow naturally. Plus, I will collect, revise, and refactor my scattered ideas on a topic when I write an essay about it. So, no sweat.</p>
<p>Similarly, I need only practice 2-3 techniques right now. However, with principles, there’s no set limit. Still, it takes time to implement and tweak them based on the evidence. So, let’s restrict it to 3 principles.</p>
<h1 id="short-and-sweet">Short and Sweet</h1>
<p>Name your chunks well. I found that having one phrase to capture each of the three conditions for a Causal Bayesian Network helped me remember them effortlessly (“no screw, ideal, and narrow interventions”). I suspect this is a very powerful technique. Exploit it to remember everything important. Also, find out exactly how it works. Do you need to be able to say the chunk out loud within two seconds? How do we design the hierarchy of chunks?</p>
<h1 id="thirty-sseven-ruless">“Thirty-sseven Ruless”</h1>
<p>Make a prototype list of inviolable rules from important domains, like Professor Quirrell. Brain Rules, Your Brain at Work, etc. should help.</p>

<div class="info">Created: August 25, 2015</div>
<div class="info">Last modified: April 19, 2016</div>
<div class="info">Status: in-progress</div>
<div class="info"><b>Tags</b>: memory</div>

<br />
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'spkrationalitytrainingground'; // required: replace example with your forum shortname
    var disqus_identifier = '/Mental-Model-of-Concepts.html';
    var disqus_title = 'Mental Model of Concepts';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
	var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
