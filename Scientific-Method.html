<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel="icon" type="image/png" href="./images/favicon-32x32.png" sizes="32x32" />
	<link rel="icon" type="image/png" href="./images/favicon-16x16.png" sizes="16x16" />
        <title>Scientific Method - SPK's Rationality Essays</title>
        <link rel="stylesheet" type="text/css" href="./css/default.css" />
        <link rel="stylesheet" type="text/css" href="./css/highlight.css" />

	<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script> -->
	<!-- <script type="text/javascript" src="/js/header-links.js"></script> -->

	<!-- Google Analytics stuff -->
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-51321929-1', 'pradeep90.github.io');
	  ga('send', 'pageview');

	</script>

    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="./">Rationality Essays</a>
            </div>
            <div id="navigation">
                <a href="./">Home</a>
                <!-- <a href="/sequences.html">Sequences</a> -->
                <a href="./notes.html">Notes</a>
                <!-- <a href="/about.html">About</a> -->
                <a href="./archive.html">Archive</a>
            </div>
        </div>

        <div id="content">
          <h1 id="post-title">Scientific Method</h1>

            <!-- <center><img src="https://fbcdn-sphotos-d-a.akamaihd.net/hphotos-ak-prn1/t31.0-8/p600x600/10257116_10202295769100492_2438594605053717342_o.jpg" height="400" width="300" class="sujeet-pic" alt="Sujeet pic" /></center> -->

<p><strong>Questions</strong>: How can we think scientifically?</p>
<p>Instead of trying to find the perfect description of the scientific method, let’s start with a simple, inefficient process and improve it based on feedback. Judge each version only using empirical evidence; don’t theorize idly.</p>
<hr />
<h1 id="aim-obtain-a-good-model">Aim: Obtain a good model</h1>
<p>We are uncertain about the outcomes of various scenarios. We need to predict what will happen, so that we can make good decisions. We have questions we want to answer, problems we want to solve. So, we use a model of the domain to help us answer those questions.</p>
<p>The better our model, the better our predictions will be. Wait. In what sense will our predictions be better? Well, it is a matter of induction. We humans believe that if we process the evidence we have by using Bayes Theorem, we will get the most accurate predictions overall. Yes, a mythical hypothesis that made exactly the right predictions for everything you see would be great to have, but you don’t know what it is in advance. So, it doesn’t help you make future predictions. The best you can do is use Bayes Theorem constantly.</p>
<p>So, our one and only aim is to use Bayes Theorem to get a model with high posterior probability.</p>
<h1 id="goal-of-this-essay">Goal of this essay</h1>
<p>Right now, the term “causal model” is a black box to me. I don’t understand exactly how it works inside. But I need to. I want to get a complete understanding of how causal models work.</p>
<p>First, I want to know about causal models (aka hypotheses) and predictions. What does a causal model look like (and what does it not look like)? What do predictions look like (ditto)? How does a model help you make predictions? How can you find out which experiments it talks about? For how many experiments does it make predictions?</p>
<p>Next, I want to know about alternative hypotheses. How do models differ from one another? How would a model differ from an improved version of it? How do independent and dependent variables enter the picture? What do scientific experiments look like?</p>
<h1 id="causal-models">Causal Models</h1>
<p>How do we get or create a causal model? What is a causal model? What isn’t a causal model? It is pointless to say “everything is a causal model”.</p>
<p>Give me three examples of things that are causal models and three examples of things that are not.</p>
<h2 id="say-no-to-definitions">Say No to Definitions</h2>
<p>Definitions aren’t causal models. “A generous person is someone who shares his wealth with others”. Well, say John shared $5 equally with his four friends when he was a kid. Is he a “generous person”? Well, according to the definition, yes. But, after ten years, will he share the $5000 he gets in a lottery? The definition doesn’t help you make future predictions. If you do make predictions, it would be because of the evidence you saw (him sharing $5 as a kid), which is quite weak evidence, especially when it comes to what he will do for big amounts of money when he is much older. The definition is nothing but a label - “generous” - and just knowing the label doesn’t help you make narrow predictions.</p>
<p>Basically, when should you agree that a definition applies to a person? If John shared $5 with his friends when he was a kid, does that make him a “generous person” and thus likely to share even $5000? Or would you wait for more evidence? Why should you wait? Isn’t the definition clear? The definition is only as good as the criteria you use to apply it.</p>
<p>John shared $5 with his friends. Ok, as per the definition, he now has the label “generous person”. Big deal. So what? The word “generous” doesn’t mean anything by itself. We only care about the predictions that it allows us to make.</p>
<p>To assure yourself of this, let’s say someone argues that the definition is not “air-tight” enough. They say we should label someone “generous” only after they have done a hundred deeds of wealth-sharing. Ok, assume John shares $5 everyday, does that make him “generous”? Now, they say it must be significant percentage of his wealth.</p>
<p>What if he does that on a hundred (or a thousand) occasions - somehow replenishing his wealth afterwards - but then one day doesn’t share even when his close friend is in dire need? Is he still “generous”? More pertinently, what do you predict he will do tomorrow when another friend is in need? Will you say that he won’t help the friend? But, he is “generous” according to the definition, right? Or, will you say that he will help the friend? But, he might have turned cold and therefore stopped helping anyone.</p>
<p>Anyway, the lesson is: don’t argue using definitions.</p>
<p>Then, what do you argue using?</p>
<p>What is it that definitions don’t have? Well, they don’t let you make predictions about specific experiments.</p>
<h2 id="sine-qua-non">Sine qua non</h2>
<p>What is the smallest thing that can still be called a causal model?</p>
<h2 id="compression">Compression</h2>
<p>A causal model is a compressed version of all the predictions it makes. It is useful only insofar as it makes predictions. We don’t need it for anything else. We could write out each prediction it makes and use that, but that hypothesis would be penalized according to Occam’s Razor.</p>
<p>However, we can’t deal with the expanded list of predictions by itself. That’s too much detail to hold in our heads. Instead, we must chunk it up hierarchically so that we can comprehend it.</p>
<p>How do we compress all the predictions we want to make?</p>
<p>I think we break the system into parts, model each of those parts, and put them together to model the system as a whole. This gives us the questions: How do we split up the system? What is the smallest part we model directly? How do we put together different models? Further, I suspect that we carve the system at the points where we can manipulate or observe it.</p>
<p>Wait. We probably also abstract the system using different layers. How is each layer expressed in terms of the layer below it? Do we need to care about the lower layers at all? What are the criteria we need to meet in order to use some abstraction?</p>
<p>Well, what decides the abstraction layers? What decides the parts into which you break the system? Give me concrete examples of each.</p>
<h2 id="cause-and-effect">Cause and Effect</h2>
<p>One form of “cause” that scientists talk about is some independent variable that changes one or more dependent variables when you manipulate it, keeping everything else constant. Ok. But what happens when other things are not constant? What happens when you change some of the other independent variables? Rather, if you figure out the isolated effect of each independent variable, how do you put together those effects?</p>
<p>For one, we get to know that the independent variable does have some effect on our dependent variables. It may have well have been that changing the variable does nothing, like when changing the colour of paint on a car does pretty much nothing to make it move faster.</p>
<h1 id="predictions">Predictions</h1>
<p>Is it that a causal model is just about making predictions for specific experiments? I think we get confused by the words that are part of the model. We should treat the causal model purely as a source of predictions for experiments. Give it an experiment, and ask it for the prediction. That’s all. Nothing else about it matters.</p>
<p>Also, note that there may be nothing vague about an experiment. We can give it a very precise question, like how will it take a small round pebble of a given weight to reach the bottom of a building if you throw it from the fifth floor?</p>
<p>Hmmm…. so that’s another variable - the precision of the experiment. Sometimes, you care about very sharp answers - like how many minutes will the ambulance take to reach this accident victim? Other times, you care about vague answers - will I be able to return from the bathroom before this commercial break ends?</p>
<p>Are all experiments of this form: “given a configuration of independent variables, what will the values of the dependent variables be”?</p>
<p>What does a variable look like? What values can it take? Let’s collect some variables, values, experiments, and predictions.</p>
<h2 id="how-does-a-model-make-predictions">How does a model make predictions?</h2>
<p>Does it explicitly name the variables? How else can it talk about them?</p>
<h1 id="problems-in-figuring-out-causal-models">Problems in figuring out Causal Models</h1>
<p>The main difficulty I’m having in getting a concrete feel for causal models is that I’m not able to bring up real examples of causal models. I get the feeling that most causal models are too big and vague [citation needed]. For example, in books, the whole chapter seems to be the causal model - it’s hard to analyze.</p>
<p>Plus, it seems like we humans use our mind to make the predictions, based on the words given in some book. “There are two ways of reducing economic inequality” - I use my mental model of “economic inequality” to imagine the distribution of wealth among the populace. I see the pie chart showing how much each strata of society owns in wealth. Remember, though, that what’s happening inside our head isn’t magic. We can taboo the terms - replace them by what they represent - and make the model more precise.</p>
<p>Maybe figure out the <em>exact</em> questions you want to answer and then take it from there. Enumerate the possible answers.</p>
<p>What else could a causal model be?</p>
<h1 id="causal-model-finally">Causal Model, finally</h1>
<p>Here’s my model about how causal models work.</p>
<h2 id="hierarchy-of-variables">Hierarchy of variables</h2>
<p>In some field, we have instruments for observation and manipulation. Call the things we can observe as dependent variables, and the things we can manipulate as independent variables. Note that when you don’t manipulate its value, an independent variable X would be set by the value of some other independent variable Y. So, in that model, you would treat X as a dependent variable.</p>
<p>A causal model tells you (perhaps incompletely) what values the dependent variables will take for some configuration of the independent variables.</p>
<p>This much seems implied by the form of Bayes Theorem, which asks you make predictions for any configuration of the system, i.e., predict the value of a dependent variable for some configuration of independent variables. If your model didn’t make any predictions for some scenario, then it would be held to make a random prediction, and thus most likely penalized in its posterior probability.</p>
<p>One of the main things that a model will do, is group the variables. It will assert which dependent variables will change for a change in an independent variable. So, I think you will end up with a hierarchy of independent variables, with dependent variables forming the leaves.</p>
<p>This tells us how to split the system into parts, model the parts, and glue them together.</p>
<p>Can a model omit some dependent variables? A complete model would talk about every variable for every configuration. A partial model, though, could just handle a few configurations of the independent variables. Also, it could talk only about a small group of variables - basically, one or more independent variables, and some dependent variables that they affect. That is, I hypothesize, essentially the smallest possible causal model.</p>
<p>Note that you could postulate some hidden variables that you can’t observe right now. However, at least in theory, you should be able to create tools to observe them.</p>
<h2 id="layers-of-abstraction">Layers of Abstraction</h2>
<p>Now, how do we deal with layers of abstraction? Maybe you get different layers of abstraction when you have different instruments for observing or manipulating the system. Really? Can’t you have lower-level instruments but still model the system at a higher-level, based on its regularities?</p>
<p>For example, binary code is the lowest level of abstraction we use in a computer (you could go into NAND gates or raw atoms, but let’s stop it here). How do we build abstractions of assembly language and successions of higher-level languages? We sacrifice a bit of inefficiency to capture common patterns and make it easier to write bigger programs. We remove duplication, in other words.</p>
<p>Why do we create abstractions? So that we can make useful predictions. For example, you can analyze binary code to come to perfectly legitimate conclusions about the behaviour of a program, but it would be tedious and error-prone. So, whenever you have a theoretical model of some system, but it’s too painful to reason about, you abstract it so that it becomes easier to see the consequences you care about.</p>
<p>What does an abstraction layer look like? Maybe the dependent and independent variables will just represent a clump of lower-level variables, and we can simply use the same hierarchy of variables idea as above. So, we need to create higher-level dependent variables such that the value we observe here is made up of the values of some lower-level dependent variables, but using a more convenient tool. Similarly, we need to create higher-level independent variables whose values we can change using a convenient tool, which would in turn change the values of some lower-level independent variables.</p>
<p>How exactly, though? And how can you manipulate the independent variables or observe the dependent variables if you don’t have high-level tools? If you’re going to design the tools, how will you design them?</p>
<p>Perhaps I can figure out the abstraction if I taboo the important terms.</p>
<h2 id="asking-how-and-why">Asking “how” and “why”</h2>
<p>When we ask “why” a model makes a certain prediction, we really want to know the values of dependent variables that come between the independent variable and the dependent variable. We want to know how it happens. We want to make the chain of reasoning more detailed.</p>
<p>To be precise, when we ask why X causes Y, we want to get a detailed chain of reasoning between X and Y. When we ask why X came about, we want to know what caused X in the first place. So, the first question is really “how” and the second one is “why”.</p>
<p>Make sure it handles changed conditions. If you say variable A causes variable B, ensure that for every value of A, you can determine the value of B. This is one of the main advantages of a cause - once you know the value of the independent variable, you don’t care about any of its ancestors or other variables.</p>
<p>Importantly, vary the other independent variables too. Example: food makes snails move faster. What if we have the smell of food, but not the food itself?</p>
<p>Also, try different ways of manipulating the independent variable. For example, to get aspirin to the brain (or whatever), directly take aspirin pills, or dissolve it in water and drink it, or inject it, or something.</p>
<p>Remember that time is a key independent variable.</p>
<p>Test the causal link in other scenarios. For example, if you say natural selection has made some gene more prevalent in some populations, check whether it increases the inclusive genetic fitness of those humans; otherwise natural selection won’t increase its relative frequency in the next generation.</p>
<p>Why do you predict this particular outcome? How come X leads to Y, and not Z? Why would an electrical field change the foraging behaviour of an insect?</p>
<h2 id="further-notes">Further notes</h2>
<p>Note: I need to handle feedback loops sometime. For now, we’ll just go with the hierarchy of variables.</p>
<p>I was stymied by the apparent impenetrability of the “models” I saw all around because they used symbols to represent previously-specified sub-models. That’s why it felt like they didn’t follow the model above.</p>
<h2 id="testing-my-hypothesis">Testing my hypothesis</h2>
<p>So, my above model suggests that you cannot have a causal model that doesn’t deal with a hierarchy of variables and layers of abstractions.</p>
<p>Specifically, what do we predict from the hierarchy-of-variables model? That a model will predict what will happen for some (or all) configurations of the independent variables in some domain. And that it will specify a hierarchy by grouping related variables. Sometimes, it may only talk about a few of the independent variables and the variables dependent on them.</p>
<p>What do we predict from the layers-of-abstraction model? That a model will talk about dependent and independent variables, just like above, but that they will represent lower-level dependent and independent variables respectively.</p>
<p>Let’s look at 10 hypotheses I have so far.</p>
<h2 id="probabilistic-models">Probabilistic Models</h2>
<p>I think Bayesian Networks work by starting with a hypothesis and then creating new hypotheses based on the evidence. Every piece of information received shifts the belief strengths of the links. The network essentially represents a new hypothesis at each point.</p>
<p>The way I was imagining hypotheses was that you have a space of hypotheses, each of them making different predictions, and that you update their posterior probabilities using the evidence. In science, for example, you create experiments that test the differing predictions of two or more hypotheses, and thus eliminate at least one of them.</p>
<p>So, are we saying that every hypothesis - every causal model - will be in the form of a Bayesian belief network? Well, yes, it will have the tree structure, but it will be fixed. You won’t change the network or update the parameters based on new evidence. If it can’t predict some evidence, its posterior probability will go down. That’s all.</p>
<p>Note that the variables in the tree need not all be observable. You could postulate some hidden variables to make the math work right.</p>
<h2 id="testing-further">Testing further</h2>
<p>I need to check whether the prose examples of hypotheses conform to my idea of a causal tree. I should be able to easily convert prose hypotheses into causal trees.</p>
<p>Also, I need to check whether the predictions they make are in the form of independent and dependent variables.</p>
<p>Let’s do that for 10 concrete prose hypotheses.</p>
<p>Later, we can work on alternative hypotheses (which I suspect are different causal structures with maybe extra dummy variables) and experimentation.</p>
<p>Results: I think prose really is a succinct way of expressing causes. Sure, you may be more precise with a causal tree, but it really is already very compressed in prose form.</p>
<p>To avoid duplicating effort, I suspect I must aim to make the prose form work better, instead of overthrowing it and installing a new form in place. For one, most of the world’s hypotheses seem to be expressed in prose form. (What about programs? What about math?)</p>
<p>In short, if the causal tree format is the bee’s knees, I want to know how well I can approximate it using prose, because that seems to be the only thing that scales. Plus, human minds have lots of limitations, and prose really may have lasted this long because it is best suited for our brains. Also, good luck describing a complicated causal tree without graphing software. (Wait. Test: How exactly do you describe a complicated causal tree using prose, then?)</p>
<p>Another test is: how do you describe a cause when there are multiple independent variables causing a dependent variable? Like, acceleration of a body depends on its mass and the net force applied to it.</p>
<p>Test whether the above model is expressive enough to cover the workings of a state machine.</p>
<p>Test your model of the scientific method on Mysterious Answers to Mysterious Questions.</p>
<p>Release the scientific method. Take a half-baked version of causal models and look to generate alternative hypotheses and experiments.</p>
<h1 id="collecting-models">Collecting models</h1>
<h2 id="pgs-inequality-and-risk">PG’s Inequality and Risk</h2>
<p>Only two ways to reduce economic inequality - give money to the poor or take it from the rich.</p>
<p>[Translation: give money to poor -&gt; wealth of poor; take it from the rich -&gt; wealth of rich; wealth of poor, wealth of rich -&gt; economic inequality]</p>
<p>If you want to give money to the poor, you have to get it from somewhere; you can’t get it from the poor, so you have to get it from the rich.</p>
<p>[Translation: get money from rich -&gt; give money to poor; get money from poor -&gt; give money to poor (not much money here)]</p>
<p>Therefore, giving money to the poor means taking it away from the rich, and vice-versa.</p>
<p>[because there are no other causal links from get money from rich or to give money to poor.]</p>
<p>If you help the poor become more productive, they would become richer, but the rich wouldn’t become poorer.</p>
<p>[Translation: do stuff (education, etc.) -&gt; productivity of poor -&gt; wealth of poor]</p>
<p>However, making the poor more productive won’t reduce economic inequality, because it makes the rich richer too. Why? Because if there are more rich poor people, there are more workers and customers for the rich people.</p>
<p>[Translation: productivity of poor -&gt; more workers -&gt; wealth of rich; wealth of poor -&gt; customers -&gt; wealth of rich;]</p>
<h2 id="steve-yegges-the-emacs-problem">Steve Yegge’s The Emacs Problem</h2>
<p>When you write in Lisp, you don’t need to have configuration files that need special-processing. You can write them in Lisp, and use the full power of the language.</p>
<p>Why do people rave about the power of separating code and data? Because they’re using languages that can’t do a good job of representing code as data. (why can’t those languages do that?)</p>
<p>[Translating the above into variables: language -&gt; how well they represent code as data -&gt; do you feel like raving about the power of separating code and data.</p>
<p>He says that most current languages can’t do a good job here, and so that means their users will rave about the power of separating code and data. But why? It can’t be that if your product doesn’t do a good job of something you will rave about the opposite (or can it)? I think we need to specify some more variables between the not-good-job bit and the raving bit. Maybe it’s to do with the commitment and consistency effect - where you start valuing something more just because you’re doing it (though I’m not sure of the precise relationship).]</p>
<p>Why does he say people really want to represent code as data? Because the half-languages for configuration are all creeping towards Turing-completeness.</p>
<p>[Translation: how expressive you want the configuration language to be (A) -&gt; Turing-completeness of configuration language (B); A -&gt; representing code as data or not.]</p>
<h2 id="steve-yegges-practicing-programming">Steve Yegge’s Practicing Programming</h2>
<p>Don’t read this blog if someone is insisting that you read it. Wait until you really think you want to get better at programming. Why? Homework just seems to kill the desire to learn. (why?)</p>
<p>[Translation: homework -&gt; read blog, desire to learn; desire to learn -&gt; read blog; desire to learn, read blog -&gt; how much you learn;]</p>
<p>Merely doing your job everyday doesn’t qualify as real practice. Because you have to set aside some time once in a while and do focused practice in order to get better at something.</p>
<p>[Translation: how you do your job -&gt; time, focussed practice -&gt; performance]</p>
<p>Why are the great engineers as good as they are? Because they practice all the time.</p>
<p>[Translation: how much they practice -&gt; skill level of the great engineers]</p>
<h2 id="defining-property-by-paul-graham">Defining Property by Paul Graham</h2>
<p>People are enjoying music and movies without paying for them. The record labels and the movie studios argue that they own the music and that thus people are stealing the music and movies.</p>
<p>[pay -&gt; get goods and services “steal” -&gt; get goods and services “own music”, pay -&gt; should get money from it (how much?) “own music” and people “steal” -&gt; you won’t get much money You aren’t getting much money, but you “own” the music; therefore, people are “stealing”; But, another possibility is that you don’t “own” the music. ]</p>
<p>Thinking of treating smells as property sounds ridiculous to PG. Why? Because it “won’t work” to treat smells as property. Why?</p>
<p>When could we charge for smells?</p>
<p>If it works to treat something as property, you may count it as property.</p>
<p>Hunter gatherers didn’t treat land as property the way we do. (why?)</p>
<p>The definition of property changes very slowly (why?). So, people think it has a single, unchanging definition.</p>
<p>With the arrival of networks, data moves much faster and cheaper (how?).</p>
<p>Wishful thinking and short-term greed -&gt; labels and studios are accusing us all of stealing (as opposed to accepting it and doing something else with the new technology; but will any business owner really do that?)</p>
<p>driven by bonuses, not equity; therefore, try to extract money from stuff they do already.</p>
<p>are you saying that if they were driven by equity, they would behave otherwise? What about newspaper owners and stuff?</p>
<p>When people can charge for content without “warping society” to do it, we should allow them to charge for it.</p>
<p>The crazy legal measures that the labels and studios have been taking seem like warping society. What newspapers and magazines are doing don’t.</p>
<p>if you’re using a definition of property that doesn’t work you would be lobbying for laws that would break the internet, etc.</p>
<p>if you have working democracies and multiple sovereign countries, people can’t easily buy laws making the definition of property whatever they want it to be; not so with a single, autocratic government.</p>
<p>No single point of attack for people trying to warp the law -&gt; people running the US don’t like it; but it’s in our interest. Why? Because private property is an extremely useful idea - arguably one of our greatest inventions. (but exactly how useful is it?)</p>
<p>So far, each new definition of private property has brought more material wealth. (why?)</p>
<p>seems reasonable to suppose that new ones will too - why? Because things that have happened regularly before will probably continue</p>
<p>if just a few powerful people were too lazy to upgrade, we would have to keep running an obsolete version, which would be a disaster (how?)</p>
<hr />
<p>My analysis: You treat something as private property when it is rival and excludable (why should it be rival?). However, you can enact laws to artificially make something excludable - like in the case of piracy laws - even when the service is no longer intrinsically excludable (music and movies after data transfer became cheap). So, now what? Should you allow artificial exclusion or not? What are the costs and benefits?</p>
<h1 id="future-ideas">Future ideas</h1>
<p>I want to understand how a model makes predictions. So, after asking why, ask what other consequences this cause has.</p>
<p>What’s the bare minimum we can do to use Bayes Theorem in a domain?</p>
<p>Guess a model for how things work. Then, think hard to guess another way it could be. Look at their differing predictions and observe the actual outcome. How does this help get a model with high posterior probability? By looking at the differing predictions, we get strong evidence one way or another. We will reject one of the two hypotheses and become more confident in the other.</p>
<p>I think we should aim to run experiments next - manipulate some independent variables to see what happens. Always be looking for ways to test your beliefs.</p>
<p>Look for surprises. They are places where your current model is wrong. Note that this is basically a recipe for doing research.</p>
<blockquote>
<p>Surprises are things that you not only didn’t know, but that contradict things you thought you knew. And so they’re the most valuable sort of fact you can get.</p>
<p>– Paul Graham, <a href>The Age of the Essay</a></p>
</blockquote>
<p>How do we “learn” a causal model from some resource? What would that look like? Would we memorize the predictions or the core engine that generates those predictions? I need concrete examples for this.</p>
<p>In cases where the resource provides both the causal model and some tests, you can check for yourself if you can generate predictions correctly. In more vague cases, you would need to build the precise causal model yourself based on the evidence provided.</p>
<p>When you taboo some term (like “causal model”), provide three concrete examples to really drive it in.</p>
<p>Don’t just ask what something is. Also ask what it is not! Look at what could falsify your hypothesis. If you say “if Y, then X”, think of some Y that doesn’t lead to X.</p>
<h1 id="how-to-learn-a-causal-model">How to learn a causal model</h1>
<p>Maybe take some resource, maybe a book chapter or essay, and condense it till you have the shortest amount of words that can still make the same predictions as the original.</p>
<h1 id="satisfying-work">Satisfying Work</h1>
<p>Do I have satisfying work for my scientific method missions? Why not?</p>
<p>I need to have a clear goal, step-by-step instructions (so that it’s work, not problem-solving), and continuous feedback.</p>
<h1 id="notes">Notes</h1>
<p>Identify the variables you care about. What can you observe? These are your dependent variables. What can you manipulate? These are your independent variables. Your job is now to find out what will happen for different values of the independent variables.</p>
<p>How do we improve our models? Remember, you have to predict the existing evidence as well as the previous model, and then some. Maybe you can think of this as a branching out - the old model plus two or more different changes.</p>
<p>Note that we usually employ our minds at some step when using causal models. If we knew the subject well enough, we would be able to describe it to a computer (like stock-market analysis programs that choose which stocks to buy, according to our specifications). Ideally, we want to capture the model in explicit terms, so that we can sub out the work to computers. But, sometimes, we may be forced to use the poorly-understood capabilities of our own brain. Like in Psychology where we judge how angry a person seems upon getting hit on the head - we can’t quite tell a computer to do that as accurately.</p>
<h2 id="posterior-probability">Posterior probability</h2>
<p>I was confused about our actual aim. Did we want to get a hypothesis with high predictive power (one that makes accurate, narrow predictions for a lot of experiments) or one with high posterior probability (one that has a lot of evidence backing it)?</p>
<p>Well, how would you find out if it has high predictive power? Only by testing its predictions in a variety of situations. Which would be counted as evidence in updating the posterior probability. Actually, no. To compute the posterior probability according to Bayes Theorem, you need to know the other hypotheses in play, whereas you can compute predictive power by looking at one hypothesis alone. But, predictive power only calculates the quality of your predictions on the few experiments you have observed. It tells you nothing about the other experiments.</p>
<p>I got confused by this vague concept of “predictive power”. It seems like it makes sense, but it actually doesn’t.</p>
<p>You want to know how much to believe a model. And the way to do that is to use Bayes Theorem.</p>
<h1 id="the-scientific-method-v1.0">The Scientific Method v1.0</h1>
<p>Let’s theorize about causal models based only on hardcore empirical evidence. We’ll look at causal models of different shades of accuracy - some that are mathematically precise, others that are vague and hand-waving. We’ll talk about consequences, alternative hypotheses, differing predictions, experiments, and other such scientific things by looking at concrete examples. Let’s not build castles in the air.</p>
<p>Mission: Get three concrete examples of “causal models”, along with three experiments each.</p>
<p>How will I know I’ve done it right? You should be able to use the models to make predictions for the experiments.</p>
<p>Okay. Go.</p>

<div class="info">Created: August 18, 2015</div>
<div class="info">Last modified: September 24, 2015</div>
<div class="info">Status: in-progress</div>
<div class="info"><b>Tags</b>: scientific method</div>

<!-- <div id="sequence-navigation" style="text-align: right"> -->
<!--   <p>Part of <a href="./sequences.html"><i>No Sequence</i></a> -->

<!--   <p>Previous post: "<a href="">Start of Sequence</a>" -->

<!--   <p>Next post: "<a href="">Head of Sequence</a>" -->
<!-- </div> -->

<br />
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'spkrationalitytrainingground'; // required: replace example with your forum shortname
    var disqus_identifier = '/Scientific-Method.html';
    var disqus_title = 'Scientific Method';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
	var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
