<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel="icon" type="image/png" href="./images/favicon-32x32.png" sizes="32x32" />
	<link rel="icon" type="image/png" href="./images/favicon-16x16.png" sizes="16x16" />
        <title>Scientific Method - SPK's Rationality Essays</title>
        <link rel="stylesheet" type="text/css" href="./css/default.css" />
        <link rel="stylesheet" type="text/css" href="./css/highlight.css" />

	<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script> -->
	<!-- <script type="text/javascript" src="/js/header-links.js"></script> -->

	<!-- Google Analytics stuff -->
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-51321929-1', 'pradeep90.github.io');
	  ga('send', 'pageview');

	</script>

    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="./">Rationality Essays</a>
            </div>
            <div id="navigation">
                <a href="./">Home</a>
                <!-- <a href="/sequences.html">Sequences</a> -->
                <a href="./notes.html">Notes</a>
                <!-- <a href="/about.html">About</a> -->
                <a href="./archive.html">Archive</a>
            </div>
        </div>

        <div id="content">
          <h1 id="post-title">Scientific Method</h1>

            <!-- <center><img src="https://fbcdn-sphotos-d-a.akamaihd.net/hphotos-ak-prn1/t31.0-8/p600x600/10257116_10202295769100492_2438594605053717342_o.jpg" height="400" width="300" class="sujeet-pic" alt="Sujeet pic" /></center> -->

<p><strong>Questions</strong>: How can we think scientifically?</p>
<p>Instead of trying to find the perfect description of the scientific method, let’s start with a simple, inefficient process and improve it based on feedback. Judge each version only using empirical evidence; don’t theorize idly.</p>
<hr />
<h1 id="summary">Summary</h1>
<h2 id="causal-models">Causal Models</h2>
<p>I want to get a causal model with high posterior probability. Causal models are causal Bayesian networks. We use locality of causality (temporal and spatial) to factorize and simplify our uncertainty about the world.</p>
<p>Use observed correlations and experimental evidence to pin down the causal structure. You need to include every observable in your model, else you will be penalized by Bayes Rule. See nothing but causal models, experiments, precise predictions, and outcomes. Think in terms of anticipated consequences - what are the causes and effects? Exercise all the different values of the cause to see what effects you get. Ask how some cause leads to its effect; also ask why the cause came about in the first place.</p>
<p>Summarizing is about abstracting some important causal links. Controlled experiments help you figure out the active ingredients in some system. However, you need further evidence to know how the ingredients combine. I feel causal models aren’t as expressive as a process description of the system (a program).</p>
<h2 id="goals">Goals</h2>
<p>Goals: Explain in your own words precisely what a causal model is. How can you falsify a causal model? By positing alternatives?</p>
<p>Next, what is the scientific method? How do you get to a good causal model when doing <em>original research</em>? How do you get to a good causal model when you’re <em>learning</em>? In which domains can I get good feedback about the predictive power of my model? How is scientific thinking different from ordinary thinking? Where exactly will you behave distinctly?</p>
<p>The way I see it, science is all about generating alternative hypotheses that explain the current evidence equally well, and using further evidence to narrow it down. Fundamental belief of a scientist: how can I test or falsify this hypothesis? That is, generate alternative hypotheses that explain the current evidence equally well.</p>
<p>When I’m completely ignorant about a topic, I would have a chance to guess alternative hypotheses based on very little evidence, which is something I want to train for. Otherwise, I have too much evidence to really come up with alternatives. I think I have trouble coming up with alternative hypotheses when I have too much implicit evidence about the domain. I suspect I can get practice examples containing little evidence from textbooks and journals in unfamiliar sciences. You can test how good your alternative hypotheses are by seeing how many causal links you got right.</p>
<p>However, we aren’t working in a complete vacuum. We have background knowledge about the domain. We should use them in formulating detailed models.</p>
<p>Problem statement: Given existing evidence, come up with hypotheses that explain it equally well.</p>
<h2 id="minimum-viable-product">Minimum Viable Product</h2>
<p>What is the bare minimum I can do to start using the scientific method? Generate alternative hypotheses for some given evidence?</p>
<p>Collect concrete examples of causal models, alternative hypotheses, and experiments so that you can refine your understanding.</p>
<p>Finally got a good handle on alternative hypotheses (I think). Think locally!</p>
<h2 id="ideas-for-practice">Ideas for practice</h2>
<p>Look for surprises. Use the experiments in some domain to test your grasp of the model. Taboo the major words. Think only in terms of models and variables.</p>
<p>Seek to explain phenomena using the base model of the domain.</p>
<p>Only accept a causal model insofar as your evidence uniquely supports it. Keep the equally supported alternative hypotheses in mind at all times.</p>
<p>Focus on maximizing the number of <em>reaches</em>, not just mere repetitions.</p>
<p>Think in terms of the variables. Don’t deal in abstract concepts. Ask for precise predictions: “A often leads to B” - exactly how often? Specify the exact effect of some cause.</p>
<hr />
<h1 id="aim-obtain-a-good-model">Aim: Obtain a good model</h1>
<p>We are uncertain about the outcomes of various scenarios. We need to predict what will happen, so that we can make good decisions. We have questions we want to answer, problems we want to solve. So, we use a model of the domain to help us answer those questions.</p>
<p>The better our model, the better our predictions will be. Wait. In what sense will our predictions be better? Well, it is a matter of induction. We humans believe that if we process the evidence we have by using Bayes Theorem, we will get the most accurate predictions overall. Yes, a mythical hypothesis that made exactly the right predictions for everything you see would be great to have, but you don’t know what it is in advance. So, it doesn’t help you make future predictions. The best you can do is use Bayes Theorem constantly.</p>
<p>So, our one and only aim is to use Bayes Theorem to get a model with high posterior probability.</p>
<h1 id="asking-how-and-why">Asking “how” and “why”</h1>
<p>When we ask “why” a model makes a certain prediction, we really want to know the values of dependent variables that come between the independent variable and the dependent variable. We want to know how it happens. We want to make the chain of reasoning more detailed.</p>
<p>To be precise, when we ask why X causes Y, we want to get a detailed chain of reasoning between X and Y. When we ask why X came about, we want to know what caused X in the first place. So, the first question is really “how” and the second one is “why”.</p>
<p>Make sure it handles changed conditions. If you say variable A causes variable B, ensure that for every value of A, you can determine the value of B. This is one of the main advantages of a cause - once you know the value of the independent variable, you don’t care about any of its ancestors or other variables.</p>
<p>Importantly, vary the other independent variables too. Example: food makes snails move faster. What if we have the smell of food, but not the food itself?</p>
<p>Also, try different ways of manipulating the independent variable. For example, to get aspirin to the brain (or whatever), directly take aspirin pills, or dissolve it in water and drink it, or inject it, or something.</p>
<p>Remember that time is a key independent variable.</p>
<p>Test the causal link in other scenarios. For example, if you say natural selection has made some gene more prevalent in some populations, check whether it increases the inclusive genetic fitness of those humans; otherwise natural selection won’t increase its relative frequency in the next generation.</p>
<p>Why do you predict this particular outcome? How come X leads to Y, and not Z? Why would an electrical field change the foraging behaviour of an insect?</p>
<h1 id="sine-qua-non">Sine qua non</h1>
<p>What is the smallest thing that can still be called a causal model? Well, that would be a single causal link.</p>
<h1 id="further-notes">Further notes</h1>
<p>Note: I need to handle feedback loops sometime. For now, we’ll just go with the hierarchy of variables.</p>
<p>I was stymied by the apparent impenetrability of the “models” I saw all around because they used symbols to represent previously-specified sub-models. That’s why it felt like they didn’t follow the model above.</p>
<h1 id="summarizing">Summarizing</h1>
<p>What about summarizing? Actually, what is summarizing? If you need each causal link in the tree, how can you compress it even further? I need to look at concrete examples of uncompressed and compressed causal models. How do they differ? Is it to do with a layer of abstraction? Are you perhaps encapsulating some parts of the model? I mean, it can’t literally be about having fewer causal links, can it? Because we’re assuming that each causal link is from an independent variable to a dependent variable. So, you have to account for the value of every variable. How can you do that with fewer causal links?</p>
<p>Maybe you summarize by abstracting common links. That is probably the same as using higher-level variables. You start to see the patterns. However, be careful to specify all the possible values of the abstract variables. Be precise.</p>
<h1 id="ingredients">Ingredients</h1>
<p>I suspect that each piece of advice you get from a book is just an abstract causal link, hopefully backed by controlled experiments. However, you usually don’t know exactly how the different pieces of advice will combine. That’s why you need domain expertise to figure out how complex scenarios play out. This holds for every piece of advice ever - just having evidence from controlled experiments is not enough. They are just the ingredients; you need to know how they combine.</p>
<p>What does a controlled experiment really tell you? I think it just hints at the causal structure, plus a bit about the strength of the causal link.</p>
<p>Your diary summaries are examples of succinct but predictive models. Study them. They probably will have very few, abstract causal links. To test this, look at them and see if they form abstract causal links.</p>
<h1 id="causal-diagram-vs-process-description">Causal Diagram vs Process Description</h1>
<p>I somehow feel uncomfortable with this idea of causal links between variables. It seems unsatisfactory to me.</p>
<p>What I really want is a description of the underlying process that reality is using to generate what we see. I want to know the program that reality is running. That is what programs are - descriptions of processes. And that is, I think, what hypotheses are too.</p>
<p>The idea of isolating all the variables (independent or dependent) and looking at their relationships seems too low-level to me, like I’m missing the forest for the trees. I want to know the deep process that generates those surface phenomena. Plus, the variables seem quite fragile; they seem to be based on your current tools for observation or manipulation. I want to go beyond current tools. I want to know “how the universe works on such a deep level that you know exactly what to do to make the universe do what you want”. I want an in-depth understanding of the domain, dammit.</p>
<p>I believe that is what I did instinctively when I summarized book chapters or PG essays - I came up with some simple, sweeping model that could explain all of the observations and more.</p>
<p>You need to use your model of the process to say how the system will proceed given the initial state. That is all. Wait. Also, you need to infer what happened earlier using the evidence.</p>
<p>The domain of programming really helps cement this intuition, because you can’t get away with simplistic relationships between variables. You absolutely <em>have</em> to talk about the program in its vast complexity (?). It defies easy summarization. You can see the difference in predictive power between a person who knows the program inside-out and somebody who is just making a few surface relationships. This is the power of reductionism! Once you know the actual program being executed, you can see everything! There is no question of probabilities or anything. You know damn well exactly what is going to happen at each point.</p>
<p>This is why I feel queasy about using probabilities within a hypothesis. That’s the ultimate sign that you don’t understand the domain too well - you’re basically guessing at what will happen (and will thus get a lower posterior probability than someone who makes sure predictions). If you know the exact model that underpins a domain, you will be able to predict exactly what will happen, no two ways about it.</p>
<p>Maybe we can have probabilities to represent our confidence in different hypotheses (their prior probabilities), because we don’t know which hypothesis reality is using, but within the hypothesis, we should be sure of what we expect.</p>
<p>In short, a tree belief network is just not expressive enough, I think. You need a better language with which to describe processes.</p>
<h1 id="do-some-scholarship-dude">Do some Scholarship, dude</h1>
<p>Eliezer already covered all this in his Epistemology sequence. There’s a well-understood field that studies the area of causal models - in a very rigorous, mathematical way.</p>
<h1 id="what-ive-learned-so-far">What I’ve learned so far</h1>
<h2 id="diffs">Diffs</h2>
<p>How has my understanding of the scientific method improved over the last month?</p>
<p>The main leap so far is the notion of a causal model, in terms of a Causal Bayesian Network. It’s no longer a black box to me. I have a good idea of the pieces inside.</p>
<p>Also, I no longer talk about the whole state of the world. We assume the temporal and spatial locality of causality, so we can break the world into chunks and deal with the chunks independently. So, exploit your knowledge of which things happen close together to simplify your model.</p>
<p>One more thing I learned was to identify correlations first, and then posit causal explanations.</p>
<p>I’m convinced that you need to answer “how” by bringing in as many variables as you can between cause and effect. Otherwise, your model can’t answer questions about those variables and will thus be marked down by Bayes Theorem.</p>
<p>Ah! You’re not done when you just include a few variables in your model. You need to accommodate every variable that you can observe or manipulate. Also, you must be able to answer low-level questions after tabooing the abstract words.</p>
<p>Also, you need to answer “why” for every top-level variable - what causes it to be so?</p>
<h2 id="to-do">To-do</h2>
<p>What do I still need to do? I need to resume collecting concrete examples of causal models, differing predictions, experiments, etc. so that I can test my understanding. If Causal Bayesian Networks are truly capable of expressing any model, then you should be able to use them to describe all the scientific models around you, big or small.</p>
<p>How will we get differing predictions if we just build one causal model from the data? Or, maybe we posit alternative causal models, with varying causal structures and parameter values. Test this by looking at alternative hypotheses from the scientific world - do they fit the pattern of different causal structures governing the same variables?</p>
<p>I don’t fully understand what a causal link actually means. What can’t it be?</p>
<p>Now that we deal in causal models, I’m not sure what it means to extend a model. If it is about adding new causal links to constrain new variables, that’s fine, I guess.</p>
<p>Tests that remain: Can a causal model in the above style forbid outcomes and otherwise focus your uncertainty, as required by Mysterious Answers to Mysterious Questions? How does it help you ask questions like “what can’t it be”?</p>
<p>How would you go about trying to test or falsify a causal model? For example, take my beliefs about the world. How to test them efficaciously? If you posit that A causes B, then if you intervene at A, then B should take the predicted value. Otherwise, if you’re just observing A, then B should be independent of its non-effects given A.</p>
<p>Also, I need to test the causal model idea on multivalued variables.</p>
<p>I’m still not sure about latent variables. I suspect that they come in when you’ve not really understood the domain well, because if you’ve captured the system in detail, you won’t need any extraneous variables. Reductionism means that you can explain stuff in terms of smaller stuff. All virtual or latent variables should just be labels for some configuration of stuff.</p>
<p>I’m uncertain about using causal models to help in designing programs or art or whatever. I don’t know if they scale well to such complex endeavours. Perhaps a formal system (or language) is more suited to the task? How so?</p>
<h2 id="remember-this">Remember this</h2>
<p>See nothing but causal models, experiments, outcomes, and predictions.</p>
<p>I must obtain precise causal models.</p>
<p>Think in terms of anticipated consequences. In terms of causes, what that means is look at the current state and ask what effects you expect to see, as per your causal model. You’re not allowed to make predictions about the future without talking about the causes that will take the world from now to then.</p>
<p>Play around with a bunch of concrete causal models. See what happens when you have a bunch of causes for some variable - how do their conditional probabilities interact? Maybe get software for this (R, perhaps?). Check out UNBBayes or SamIAm simulation software.</p>
<h1 id="goals-revisited">Goals, revisited</h1>
<p>Explain precisely what a causal model is. Show me some examples. Talk about the implications of a causal link from A to B. Specify exactly what evidence you need to posit a causal link. There’s the causal Markov assumption - A causes B means that, given A, any other X will be uncorrelated with B. You could set A, and then try to set everything else, B should not change.</p>
<p>How do you falsify a causal model? I think you test whether the necessary conditions for each causal link are satisfied.</p>
<p>Talk about the exact process you need to use to get from zero to a good causal model (whatever that is). What is the scientific method that I’m supposed to be using here? It’s so vague right now. I need clear step-by-step actions.</p>
<p>Also, enumerate domains where you can get feedback about the quality of your causal model. You need to show that your causal model formulation performs better than any other. Start with a couple and improve as you go along.</p>
<p>Talk about alternative hypotheses.</p>
<p>Where does scientific thinking differ from ordinary thinking? Is it mainly in seeking out differing predictions and trusting only the experimental results? Also, how does Bayesian thinking differ from Traditional Rationality? Now, how can we exploit these differences to test our understanding of causal models?</p>
<p>Most importantly, how is my understanding of the scientific method falsifiable right now? How can I test it so that the world will come out one way if it is correct and another way if it is wrong? This, I think, is the fundamental thought process of a scientist: how can I falsify or test my beliefs? Practice it.</p>
<p>Remember, my aim is not to prove to others that the scientific method can be very useful. It is to test for <em>myself</em> whether the scientific method is as powerful as I think it is. I really don’t know. I get the feeling that it can be very useful as a problem-solving tool, but in the end that’s just a hunch. I need to find out for sure.</p>
<p>For that, I must learn how to formulate causal models, as taught in the domain of causality, and test my understanding on real-world problems. Only when I can solve real problems as well or better than current standards can I say that the scientific method, as I have understood it, is powerful.</p>
<p>If the causal model you get at the end is the best hypothesis among all the others, then every other hypothesis must be wrong somehow. Make a list of all the wrong hypotheses ever and show how you could have done better.</p>
<h1 id="the-scientific-method">The Scientific Method</h1>
<p>As I understand it, the way to get a good causal model of a system is to list the variables you care about, and use evidence to arrange them into a good causal structure. To help with that, manipulate some of the independent variables to see which variables get affected by them. Also, test the differing predictions between the alternative models to eliminate some of them. Observe correlations to pin down the structure. These include correlations of time and space to rule out more models (for example, A can’t cause B if A comes after B).</p>
<p>So, alternative hypotheses are just different causal structures involving the same variables. Also, sometimes you may have models with the same structure but different parameters (say, A makes B more likely vs A makes B less likely).</p>
<p>Science is all about generating alternative hypotheses and using evidence to narrow down the right ones.</p>
<h1 id="a-version-1.0">A Version 1.0</h1>
<p>What’s the bare minimum I can do to use the scientific method?</p>
<p>The core of science seems to be in testing differing predictions between alternative hypotheses, either by experiment or observation. It’s all about testing or falsifying your hypotheses. So, let’s do just that.</p>
<p>Let’s try to come up with alternative hypotheses for some system. Later on, we can get evidence to eliminate some of them.</p>
<h2 id="ignorance-is-bliss">Ignorance is Bliss</h2>
<p>Well, I want practice in organizing variables in different ways, but I need to make sure I don’t already know what the answer looks like.</p>
<p>Basically, causal structures about which I’m completely ignorant, variables -&gt; chance to organize variables in truly different structures; if I know about the structure, then I would stick close to the correct answer and thus won’t realize how I would have thought in complete ignorance.</p>
<p>In short, real-life situations of uncertainty would be like this: I would have no real idea about the actual causes and effects. I would have to guess different possible structures and observe correlations and run experiments to narrow them down. So, I want to learn the skill of generating alternative causal structures and narrowing them down using evidence.</p>
<h2 id="generating-alternatives">Generating Alternatives</h2>
<p>So, to learn to generate alternative hypotheses when I’m ignorant, I must practice in domains where I have little or no idea what’s going on. I should give myself just the variables and see what possibilities I come up with.</p>
<p>How will I know I’m doing well? For one, I should have generated the correct model as one possibility. I may not know it for sure, but I should at least be considering it. Also, I should probably generate all the alternative hypotheses that those in the field have discarded along the way - like the sun going around the earth, in astronomy. They probably had good reasons for believing those alternatives and it wasn’t until they did some definitive experiments that they rejected them.</p>
<p>Also, remember, it’s not about getting the entire causal model exactly right. It’s about getting the individual causal links correctly. So, the more causal links you guess correctly, the better you’re probably doing. That’s the power of locality of causality: once you know the direct cause, you don’t care about the other things in the system, you know what the effect will be. Therefore, for each causal link in the correct answer, aim to guess it right in at least one of your alternatives. If the anatomy textbook says that your heart will be on the left side of your body, you should have generated at least one hypothesis of the human body with the heart on the right side (er… the left side), even if it’s all over the place in the other models.</p>
<p>For practice examples, I can take on causal models from unfamiliar sciences (like anatomy or astronomy) and give myself just the variables from their textbooks or science journals. I would have to generate various possibilities and check myself.</p>
<h2 id="narrowing-it-down">Narrowing it down</h2>
<p>How do I learn to use evidence to narrow down my hypotheses?</p>
<p>Well, given the plethora of alternatives I come up with in the previous exercise, I should give myself morsels of evidence from the textbooks or journals with which to locate the right hypotheses.</p>
<p>How will I know I’m updating correctly on the evidence?</p>
<h2 id="experimenting">Experimenting</h2>
<p>Well, one of the most powerful and irreplaceable sources of evidence is the scientific experiment. There is just no other way to discover causal structures without actually intervening in the system and seeing what happens.</p>
<p>How will I practice that?</p>
<p>Maybe I can allow myself a peek at the manipulation instruments available in the domain (a knife in anatomy or heat and chemicals in chemistry) and guess at what experiments I could use them to do. Then, I can compare my answers to the experiments actually run in the field to see how close I was. If my experiments are truly informative - if they distinguish between hypotheses that are not ruled out by observational evidence - then they must have been done in the field (else, I’m on track for scientific glory!).</p>
<h2 id="everyday-trial-and-error">Everyday Trial and Error</h2>
<p>Does my learning have to be monolithic? Do you have to do all your practicing and experimenting in one domain? Why not do it in bits and pieces in different areas?</p>
<h2 id="test-it-out">Test it out</h2>
<p>You think you have a good idea for learning the scientific method.</p>
<blockquote>
<p>Now when you’re dealing with a confusing problem and you have no idea what’s going on, the smart thing to do is figure out some really simple tests, things you can look at right away. We need fast tests that distinguish between these hypotheses.</p>
<p>– Harry Potter to Draco Malfoy, Chapter 22: The Scientific Method, HPMOR</p>
</blockquote>
<p>Go test it out right away. Take three concrete unfamiliar examples and generate alternative hypotheses for them.</p>
<p>Right now, I don’t have another person who can act as an oracle and answer my queries about the domain. I have to get the evidence myself, which compromises my ignorance about the topic. Let’s try to do it anyway, and if I seriously can’t get evidence without peeking at the actual answer, then I’ll just have to employ someone else or wait till I’ve forgotten the data.</p>
<p>Step one is to look at the final causal model and list the variables it talks about. This should ideally be done by somebody else.</p>
<p>Step two is to organize the variables into different causal structures, as best as I can.</p>
<p>Step three is to get a little evidence from the domain and eliminate a few of the causal models. What kind of evidence will this be? Observed correlations and experimental evidence. Repeat until you have less than three hypotheses.</p>
<p>Step four is to check each causal link of your models against the correct model.</p>
<p>Time: 30 minutes.</p>
<p>Result: Didn’t do anything in the last hour. I wasn’t able to find any accessible causal models from some unfamiliar domain.</p>
<h2 id="truly-confused">Truly Confused</h2>
<p>Manufactured alternatives somehow seem lame to me because I already have evidence that rules them out. That’s why I feel it’s pointless to construct them. However, in more complicated scenarios, where I don’t have nearly enough evidence, I will need to create fine-grained models.</p>
<p>Ah! That’s the problem! I have the luxury of too much evidence. That’s why I don’t see the point in creating alternative models. I will be pushed only when I am lacking evidence. I must <em>genuinely not know</em> what the right answer is. That’s when I will hunt down alternative models with zeal - the answer could be any one of them!</p>
<p>One way could be to scramble the “correct answer” shown to me. I usually discount alternatives because, in the face of the right answer, they all look silly. However, if I am given a plausible-sounding wrong answer, I would be champing at the bit to find the correct model. I suspect I will only then be truly curious. I wouldn’t sit complacently thinking that I have an explanation.</p>
<p>I will be genuinely curious, I suspect, when I don’t know the actual outcomes and have to guess from thin air. It’s easy to come up with plausible explanations after the fact. It’s when you really have no clue what the hell happened that you need to think carefully. You can achieve this by either withholding the correct outcome, or by presenting random false answers. For example, cook up some stat like “teenagers are 20% happier after arriving at college” - “Oh! So college freedom really must make you happier”. But, no, “teenagers were 35% less happy”- “Oh! So maybe they miss their family”. Or maybe…</p>
<p>Suddenly, you’ve created an atmosphere of chaos and confusion. It could really go either way now. You become acutely aware of the need to weigh your evidence carefully. You now need to consider a lot more possible hypotheses.</p>
<p>So, look at areas where you really don’t know what the correct model is, where you very little evidence with which to reason.</p>
<h2 id="blind-data">Blind data</h2>
<p>How do I get information from the resource without learning the final causal model itself? If I see the correct hypothesis, I will inadvertently get a huge amount of evidence and thus won’t be able to generate plausible alternatives.</p>
<p>What kind of evidence do I want? I want time and space correlations (A happened before B), other correlations (parent height vs children height), data points (when A was 7 units, B was 13.5 units), and experimental evidence (change A and B changes too).</p>
<p>So the problem is to get the above evidence from a resource without getting the causal model itself. How do I get the above evidence alone? People in a field probably won’t store the historical data that led them to formulate the correct answer. They just store the causal model because it’s an efficient summary of all the evidence so far.</p>
<p>What kind of evidence do you expect to find in real-world scientific research? Mimic it using the final causal model. How?</p>
<h2 id="test-v2.0">Test v2.0</h2>
<p>Take an existing causal model and generate as many alternative models as you can. Don’t constrain yourself in any way. Just go with the flow.</p>
<p>Later on, we can learn how to use existing observations to shape our models. That is, given a few observations, what possible models can explain them?</p>
<p>That seems to be the essence of science: using existing data to build a few matching models, and then using experiments to rule out most.</p>
<p>For example, say you have just one causal link “A causes B”. You formulated it to explain the correlation that A and B are found high or low together. The only other simple models are “B causes A” and “X causes A and X causes B”. You can eliminate them by, say, observing the time relation. Does B happen after A? Then, B can’t cause A. Next, you could manipulate A and see what happens. If B changes, then you can conclude that A is a cause of B, directly or indirectly.</p>
<hr />
<p>Let’s test it out.</p>
<blockquote>
<p>Requirement for exit poll accuracy: no correlation between voting and willingness to talk (A), guessing for non-respondents -&gt; random sample; random sample, exit polls -&gt; accurate predictions</p>
<p>More conservative than they care to admit: Many Americans are more conservative than “elites”. your opinions, elite opinions, keep opinion to themselves -&gt; no nervousness when they differ (however, if they express their opinion to strangers, they will feel nervous);</p>
<p>Inaccurate polls: Bush voters -&gt; more likely not to respond -&gt; correlation in (A) -&gt; exit polls will be inaccurate</p>
</blockquote>
<p>Variables: who you vote for, willing to talk, guessing for non-respondents, random sample?, accuracy of polls, average American opinions, elite opinions, do you share your opinions, nervousness.</p>
<p>Time correlations: you vote before you are polled. Pollsters guess after you decide not to respond. Randomness of sample comes after you get the sample of voters. average American and elite opinions don’t happen before or after one another. share opinions happens after you have opinions. nervousness happens after you have opinions, and may be before or after you’re asked for your opinion.</p>
<p>Timeline: vote, poll, respond or not, guess for non-respondents, randomness of sample, exit poll accuracy; average American opinions and elite opinions, share opinions or not, asked by stranger and nervousness.</p>
<p>One way we can test for causal links is to take a variable that happens before and manipulate it to see what else will change.</p>
<p>Anyway, what are some alternative models that use these variables and satisfy the timing data? Just go ahead and create models at random.</p>
<p>H1: vote -&gt; poll -&gt; respond -&gt; guess -&gt; randomness -&gt; exit poll accuracy; average and elite opinions -&gt; share, asked by stranger -&gt; nervousness</p>
<p>First, for each causal link A -&gt; B, we expect to see a correlation between the values of A and B. Also, A should have happened before B and near B. Crucially, if we manipulate A to take a certain value, then B should be set regardless of any other variables. That should hold even if we turn A off; B should be set appropriately.</p>
<p>So, in “poll -&gt; respond”, if you aren’t polled, you obviously won’t respond. However, if you are polled, we can’t say with what probability you will respond. That depends on other factors like your attitude, etc. So, no model can have poll as the sole cause of respond. However, polling is a necessary condition for responding, so it has to be one of the parent causes, because if you aren’t polled, you will not respond, regardless of other variables.</p>
<p>It is useful, therefore, to look at the necessary conditions for some variable. For you to become nervous, you have to satisfy some conditions probably understood in psychology. For you to feel like sharing or not sharing some opinions, you need to again satisfy some conditions in psychology. Note that these will hardly ever be black and white. Human minds are very complex and you usually can’t predict exactly how a person will behave in any specific situation. Ditto for how opinions of average citizens get formed - social psychologists have been studying that, I suppose. Similarly, when will you not respond to a poll question?</p>
<p>Whatever the necessary conditions be, the cause you’re positing must satisfy all of them if it has to produce the desired effect.</p>
<p>In short, it seems like you already have a wealth of causal links from existing sciences. So, if you’re positing some higher-level causal links, they must be in line with the underlying links.</p>
<h2 id="lots-of-variables">Lots of variables</h2>
<p>Coming up with causal models isn’t just about rearranging a few given variables till you get something good. You have to consider variables that are not even in the picture right now. And for that, you need to respect the knowledge base of the domain and let it guide you.</p>
<p>If we are to get detailed and highly predictive models, then we must hew as closely to the domain as possible. We can’t just deal with a few abstract variables that seem to go well together without referring to the mechanisms that actually constrain them.</p>
<p>In essence, we don’t create causal models in a vacuum. If we say that A causes B, we must show that we can reach B from A using the causal links in the domain. Maybe A causes X1, and X1 causes X2, and so on till we get B.</p>
<p>Why isn’t a blank causal link saying “A causes B” good enough? Because it doesn’t say anything about the values of the intermediate variables, and will thus be penalized by Bayes Theorem. The moral of the story is to have as detailed a causal model as you can afford, given the evidence.</p>
<h2 id="what-now">What now?</h2>
<p>Where does that leave us now? We need to use existing causal links in positing a new high-level hypothesis. Ok. But how do we generate alternative hypotheses?</p>
<p>Perhaps, in cases where you have no clue at all what could affect a variable B, you could postulate various guesses - like A causes B, or C causes A and B, etc.</p>
<p>But, if you know some causal link that affects B, then you must make sure to use that when talking about the effects of A: maybe A causes X and X causes B. You shouldn’t just try to guess causal links from first principles when you already have some causal links for B.</p>
<p>I suspect that you will rarely if ever have to posit new causal links using raw data. Most of the time I think it’s somehow about putting existing causal links together in the right way. I don’t know if this is correct.</p>
<p>I think I’ve lost my way about scientific thinking. I am not thinking in terms of the desired outcome. I need to reformulate my ideas and aim squarely at getting hypotheses with high posterior probabilities.</p>
<p>As always, look to the data for inspiration. Get concrete examples of causal models, alternatives, etc.</p>
<h2 id="problem-statement">Problem Statement</h2>
<p>Problem statement: Given a sensible causal model, what are some other sensible models?</p>
<p>For example, you will usually have timing data. So, if you say A -&gt; B -&gt; C -&gt; D, you can’t have another model saying D -&gt; A, because D probably comes after A. Therefore, you get some timing information from a causal model, and you need to leverage that to constrain your search for alternatives.</p>
<p>What kind of constraints does that place? Maybe if we have C -&gt; D, then we can say that D happens after C, and so either C must cause D or they must both be caused by something else. And so on.</p>
<p>Basically, enumerate the constraints you have observed so far - the evidence - and then generate other causal models that also match. The only time you won’t be able to generate any plausible causal models at all will be when you have had enough evidence to nail down every aspect of the model. Deal in evidence, not in models. At each point, keep a list of the evidence you’ve obtained so far.</p>
<p>The problem statement now becomes: Given an amount of evidence, what different causal models can you come up with?</p>
<h2 id="reflect-real-world-science">Reflect real-world science</h2>
<p>I want to practice solving problems similar to those that I would face in the real world. The worth of my training is decided by how well it equips me for real-world problems. I suspected that these problems would require me to think up alternative hypotheses and conduct experiments, so that’s why I was struggling to find out practice exercises for that.</p>
<p>However, I now wonder, what are these real-world problems that I’m so confident the scientific method will help me with? Why exactly do we need the scientific method? Yes, it’s all very well to say that anywhere you’re uncertain, you need to use science to reduce your ignorance. But, where exactly is that?</p>
<p>Name three concrete problems you want to solve.</p>
<p>For one, I want to understand precisely how motivation works - why we procrastinate, what we can do to avoid it, etc. Also, I seek to know exactly how to increase any particular skill. I also want to learn how to write powerful programs without too much trouble.</p>
<p>Basically, I want to solve various problems in life, for myself and for others. And for that, I believe that I would need to figure out the truth about those things aka get a good causal model of them.</p>
<p>The thing is, for research problems in psychology or the natural sciences, you need a lot of evidence. In psychology, you need to test your theories on a wide variety of people before you can be reasonably confident. In physics, you usually need heavy equipment to test your ideas. So, I can’t hope to do original research in these areas, not without joining some university. The best I can aim for is to gather the technical resources laid out by the researchers and using it to build an accurate causal model in my head.</p>
<p>So, there are two kinds of problems: those I must solve by doing original research, and those I can solve by learning from others’ work.</p>
<p>Ok. Name five concrete problems of each type.</p>
<p>The problems I mentioned earlier were of the scholarship type - I had to learn a precise model using existing research. Other examples include sleep schedule (how can I wake up early everyday?), writing (how can I write more engagingly?), self-esteem (how can I feel better about myself?), etc.</p>
<p>Problems where I would have to obtain evidence myself: writing a program, designing a plan for some project, etc. Basically, where can I run experiments or observe things on my own? Social interactions, personal health, programming, writing, math problems, beliefs about the world, etc. As I’m learning a model from some resource and trying to apply it to my life, I need to test how well I’ve understood it.</p>
<p>How are people solving these problems in the real world? How can the scientific method help me learn or create good models?</p>
<p>For now, we can assume that I’m going to do a lot more of learning than research. So, let’s focus solely on that for now, and take on research later.</p>
<h2 id="learning-a-causal-model">Learning a Causal Model</h2>
<p>How can I learn a precise causal model from some resource? Well, if they’ve provided the causal graph in the resource itself, great! Else, I would have to use the evidence they provide to build a causal model on my own. And, to do it well, I would have to generate alternative causal models and eliminate them using the evidence, till I narrow down the correct model.</p>
<p>Test this out.</p>
<h1 id="release-the-scientific-method">Release the Scientific Method</h1>
<p>The first thing you do with a project is release it. So, let’s release the scientific method. Let’s come up with some dirt-simple version of it and use it on a hundred problems.</p>
<p>What’s the product supposed to be? Get a causal model that can answer as many questions as you can in a particular domain.</p>
<p>Aim: Given some evidence, figure out hypotheses that explain it equally well.</p>
<p>How? For now, just take each observation you have and think of different mini-causal structures that satisfy it. Combine those causal structures into coherent causal models that predict all the evidence. Then, use any experimental evidence to distinguish between the alternatives. This way, you should get to hypotheses with high posterior probabilities.</p>
<p>Here’s the key difference from before: earlier, I thought in terms of constructing entire giant alternative hypotheses, things that differed at every level. However, now that we have locality of causality, we can <em>think locally</em>. Take up parts of the causal model - maybe just a single causal link, or a triplet of variables - and ask how they might be arranged differently.</p>
<p>Thinking locally means thinking in terms of nearby causes and shutting out faraway ones. Once you know about the parents of a variable, you don’t need to care about the ancestors. You have all the information you need. So, instead of asking for abstract general causes of things, ask what happened just before this; ask what happened close to this. Think locally and concretely, not globally and generally.</p>
<p>Go ahead with this informal algorithm and see where you hit roadblocks.</p>
<p>Mission: Look at 100 correlations or observations and construct alternative hypotheses that satisfy the data.</p>
<p>Where can I use this “scientific method”? Wherever you get observations or experimental evidence. It’s up to you.</p>
<p>Time: 1 day.</p>
<h2 id="notes">Notes</h2>
<p>What is the hard part in thinking scientifically? What is the thing that we can’t do by thinking ordinarily but which delivers the most information? Computing the consequences of some model can be hard, I feel. You need to keep your eyes peeled to see how some cause-effect relation works in a new domain, more so if there are several causes at play. Also, you will discover observables that aren’t in the model but need to be, so you have to figure out how they fit.</p>
<h1 id="future-ideas">Future ideas</h1>
<p>What’s the bare minimum we can do to use Bayes Theorem in a domain?</p>
<p>Guess a model for how things work. Then, think hard to guess another way it could be. Look at their differing predictions and observe the actual outcome. How does this help get a model with high posterior probability? By looking at the differing predictions, we get strong evidence one way or another. We will reject one of the two hypotheses and become more confident in the other.</p>
<p>I think we should aim to run experiments next - manipulate some independent variables to see what happens. Always be looking for ways to test your beliefs.</p>
<p>Look for surprises. They are places where your current model is wrong. Note that this is basically a recipe for doing research.</p>
<blockquote>
<p>Surprises are things that you not only didn’t know, but that contradict things you thought you knew. And so they’re the most valuable sort of fact you can get.</p>
<p>– Paul Graham, <a href>The Age of the Essay</a></p>
</blockquote>
<p>How do we “learn” a causal model from some resource? What would that look like? Would we memorize the predictions or the core engine that generates those predictions? I need concrete examples for this.</p>
<p>In cases where the resource provides both the causal model and some tests, you can check for yourself if you can generate predictions correctly. In more vague cases, you would need to build the precise causal model yourself based on the evidence provided.</p>
<p>When you taboo some term (like “causal model”), provide three concrete examples to really drive it in.</p>
<p>Don’t just ask what something is. Also ask what it is not! Look at what could falsify your hypothesis. If you say “if Y, then X”, think of some Y that doesn’t lead to X.</p>
<h1 id="future-practice-ideas">Future practice ideas</h1>
<p>Think only in terms of hypotheses. Every single thing in the world is either a hypothesis, experiment, prediction, or evidence. That’s all. Focus on one particular thing at a time - in one pass, look for hypotheses; in the next, look for experiments; and so on.</p>
<p>Taboo the major words.</p>
<p>Instead of trying to come up with “new” causes, try to explain the phenomena using your base model. Compute the consequences of the base model till you can predict what’s happening at this level. If the base model is accurate, then somehow it must be making these outcomes occur. Find out how.</p>
<p>Come up with sanity checks for your hypotheses, evidence, predictions, etc. Example: is this a hypothesis or just a prediction? In short, look at the hypothesis that says “I have a hypothesis here” and see whether it stands up to your experiments. Also, what would falsify this hypothesis? What does this predict will <em>not</em> happen?</p>
<p>We get in trouble, I think, when we try to create hypotheses without looking at some concrete evidence. Why? Because it’s easy to just add words that seem like they explain everything but really don’t. Remember, your causal model is only as good as the evidence you have. It’s only the evidence that will make your model precise and let you predict the outcome of different states. In any case, if some part of a hypothesis doesn’t deal with any evidence, then it has no business being there. This is test-driven development, in other words. Get the evidence, show that your current model fails to predict it, and then postulate some extra cause. So, the key is in finding experiments where your current model doesn’t predict correctly.</p>
<p>Remember that a causal model is a state-transition function. Focus on the states and how they change into one another. Don’t simply deal with meaningful-sounding words. When you ask “why”, don’t answer with a cause. See the prediction made aka the final state B. Now, posit a previous state A and a causal model that narrowly transforms A into B (and transforms the initial state into A).</p>
<p>Right now, “state-transition function” is just a buzzword. I don’t know what exactly the states are and how you’re supposed to describe the transition. So, I need to look at some concrete causal models and see how they do it. I suspect they will describe the states using certain variables.</p>
<p>Always remember: science is all about getting highly predictive causal models.</p>
<p>Give me three concrete domains in which to “practice science” aka build causal models.</p>
<p>Where do you plan to use the scientific method in the future? What chunks will you be using? Practice those chunks.</p>
<p>How do I get feedback on my practice? Some measurement - maybe number of reps - number of reps of what?</p>
<p>It’s not about the number of reps. It’s about the number of <em>reaches</em>. Big difference! You have to actually do something you’re not good at.</p>
<p>Have Fun Failure. You should fail about 80% of the time.</p>
<p>Practice noticing confusion and noticing surprise. Also, learn to notice naive realism.</p>
<p>Much of the time, the scientific thinking you’re doing is parallelizable. So, don’t try to go through to the end before you start the next pass. Stop at some convenient point and go to the next step so that you have a short cycle with quick feedback.</p>
<h1 id="practice-tips">Practice Tips</h1>
<p>Grep for <code>\&lt;\(because\|so\|why\|how\|reason\)\&gt;</code>. Also, <code>yet</code>; and <code>since</code>.</p>
<p>Give explicit criteria for labeling somebody - “take on a utility function”, or “explicit utility function”, or “exactly measures our personal contribution”.</p>
<p>The hardest part seems to be dealing with the mess of paragraphs and keeping everything straight in my head and rewriting things so that they are neat and succinct. Working around my cognitive limitations, in other words.</p>
<p>Taboo “often”, “sometimes”, “usually”, “many”, etc. Be precise. Ask for narrow predictions - “you become stupid after hours of work” - exactly how stupid, after how long?</p>
<p>For each independent variable, ask yourself if you can manipulate it. For each dependent variable, ask yourself it you can measure it. Taboo it, in other words.</p>
<p>For each independent variable, ask which dependent variables it might affect.</p>
<p>It’s not that the independent variables “cause” the dependent variables to change. It’s just that they let you <em>predict</em> the values of the dependent variables.</p>
<p>Every cause is a prediction for the cause before it. You can always ask why to go higher in the causal chain. Basically, you need to go up till you can constrain all the important variables.</p>
<p>If you have to add a lot of corner-cases and details to your hypotheses, you should probably go a level deeper and find a more powerful, general hypothesis (like with stuff and signalling).</p>
<h1 id="how-to-learn-a-causal-model">How to learn a causal model</h1>
<p>Maybe take some resource, maybe a book chapter or essay, and condense it till you have the shortest amount of words that can still make the same predictions as the original.</p>
<p>Basically, how do we test whether we’ve extracted an accurate causal model? We make sure it can precisely explain all the correlations we observed before. So, make a list up front of the observed correlations in some particular resource. Identify the variables you care about. What can you observe? These are your dependent variables. What can you manipulate? These are your independent variables.</p>
<h1 id="mysterious-answers-to-mysterious-questions">Mysterious Answers to Mysterious Questions</h1>
<p>Let’s see if my understanding of causal models as Causal Bayesian Networks can satisfy the requirements of a good hypothesis stated in Eliezer’s Sequence.</p>
<h2 id="anticipated-consequences">Anticipated consequences</h2>
<p>Anticipated consequences are all about talking in terms of the variables. If a tree falls in a forest and no one is around to hear it, you expect the vibrations-in-the-air variable to change and you expect no brain to have any auditory-processing. There is no confusion at all once you think in terms of the variables.</p>
<p>What was wrong with the “hypothesis” that phlogiston caused fire? He says there were no advance predictions. Why is that? Well, you can’t observe or manipulate phlogiston, and you can’t observe or manipulate any of its parent causes either. So, it tells you nothing at all.</p>
<p>What about Wulky Wilkinsen’s “post-utopian” work? Can’t we say “post-utopian” style causes your books to show “colonial alienation”? But, we can’t observe or manipulate either of those variables, nor any of their parent causes.</p>
<p>The lesson is to always talk in terms of variables that you can observe or manipulate. Further, you must specify precisely what effects you expect a cause to have (and thus what observed effects would falsify your belief). If a “cause” doesn’t precisely control what values the “effect” will have, then that causal link is useless.</p>
<p>What about the theory that elan vital causes aliveness in living beings? Again, you can’t observe or manipulate elan vital. And you can’t predict precisely which configurations of matter will possess “aliveness”.</p>
<p>Whenever you predict one outcome, the other possible outcomes will falsify your hypothesis.</p>
<p>Failure to consider the obvious next question: why? If you say A caused B, ask why A came about in the first place. Also, ask how A leads to B - what are the intermediate steps?</p>
<p>Also, when you don’t know the cause behind some variable, its behaviour will seem chaotic and unpredictable to you. However, once you figure out the cause, it will be absolutely clear.</p>
<h1 id="collecting-models">Collecting models</h1>
<h2 id="pgs-inequality-and-risk">PG’s Inequality and Risk</h2>
<p>Only two ways to reduce economic inequality - give money to the poor or take it from the rich.</p>
<p>[Translation: give money to poor -&gt; wealth of poor; take it from the rich -&gt; wealth of rich; wealth of poor, wealth of rich -&gt; economic inequality]</p>
<p>If you want to give money to the poor, you have to get it from somewhere; you can’t get it from the poor, so you have to get it from the rich.</p>
<p>[Translation: get money from rich -&gt; give money to poor; get money from poor -&gt; give money to poor (not much money here)]</p>
<p>Therefore, giving money to the poor means taking it away from the rich, and vice-versa.</p>
<p>[because there are no other causal links from get money from rich or to give money to poor.]</p>
<p>If you help the poor become more productive, they would become richer, but the rich wouldn’t become poorer.</p>
<p>[Translation: do stuff (education, etc.) -&gt; productivity of poor -&gt; wealth of poor]</p>
<p>However, making the poor more productive won’t reduce economic inequality, because it makes the rich richer too. Why? Because if there are more rich poor people, there are more workers and customers for the rich people.</p>
<p>[Translation: productivity of poor -&gt; more workers -&gt; wealth of rich; wealth of poor -&gt; customers -&gt; wealth of rich;]</p>
<h2 id="steve-yegges-the-emacs-problem">Steve Yegge’s The Emacs Problem</h2>
<p>When you write in Lisp, you don’t need to have configuration files that need special-processing. You can write them in Lisp, and use the full power of the language.</p>
<p>Why do people rave about the power of separating code and data? Because they’re using languages that can’t do a good job of representing code as data. (why can’t those languages do that?)</p>
<p>[Translating the above into variables: language -&gt; how well they represent code as data -&gt; do you feel like raving about the power of separating code and data.</p>
<p>He says that most current languages can’t do a good job here, and so that means their users will rave about the power of separating code and data. But why? It can’t be that if your product doesn’t do a good job of something you will rave about the opposite (or can it)? I think we need to specify some more variables between the not-good-job bit and the raving bit. Maybe it’s to do with the commitment and consistency effect - where you start valuing something more just because you’re doing it (though I’m not sure of the precise relationship).]</p>
<p>Why does he say people really want to represent code as data? Because the half-languages for configuration are all creeping towards Turing-completeness.</p>
<p>[Translation: how expressive you want the configuration language to be (A) -&gt; Turing-completeness of configuration language (B); A -&gt; representing code as data or not.]</p>
<h2 id="steve-yegges-practicing-programming">Steve Yegge’s Practicing Programming</h2>
<p>Don’t read this blog if someone is insisting that you read it. Wait until you really think you want to get better at programming. Why? Homework just seems to kill the desire to learn. (why?)</p>
<p>[Translation: homework -&gt; read blog, desire to learn; desire to learn -&gt; read blog; desire to learn, read blog -&gt; how much you learn;]</p>
<p>Merely doing your job everyday doesn’t qualify as real practice. Because you have to set aside some time once in a while and do focused practice in order to get better at something.</p>
<p>[Translation: how you do your job -&gt; time, focussed practice -&gt; performance]</p>
<p>Why are the great engineers as good as they are? Because they practice all the time.</p>
<p>[Translation: how much they practice -&gt; skill level of the great engineers]</p>
<h2 id="defining-property-by-paul-graham">Defining Property by Paul Graham</h2>
<p>People are enjoying music and movies without paying for them. The record labels and the movie studios argue that they own the music and that thus people are stealing the music and movies.</p>
<p>[pay -&gt; get goods and services “steal” -&gt; get goods and services “own music”, pay -&gt; should get money from it (how much?) “own music” and people “steal” -&gt; you won’t get much money You aren’t getting much money, but you “own” the music; therefore, people are “stealing”; But, another possibility is that you don’t “own” the music. ]</p>
<p>Thinking of treating smells as property sounds ridiculous to PG. Why? Because it “won’t work” to treat smells as property. Why?</p>
<p>When could we charge for smells?</p>
<p>If it works to treat something as property, you may count it as property.</p>
<p>Hunter gatherers didn’t treat land as property the way we do. (why?)</p>
<p>The definition of property changes very slowly (why?). So, people think it has a single, unchanging definition.</p>
<p>With the arrival of networks, data moves much faster and cheaper (how?).</p>
<p>Wishful thinking and short-term greed -&gt; labels and studios are accusing us all of stealing (as opposed to accepting it and doing something else with the new technology; but will any business owner really do that?)</p>
<p>driven by bonuses, not equity; therefore, try to extract money from stuff they do already.</p>
<p>are you saying that if they were driven by equity, they would behave otherwise? What about newspaper owners and stuff?</p>
<p>When people can charge for content without “warping society” to do it, we should allow them to charge for it.</p>
<p>The crazy legal measures that the labels and studios have been taking seem like warping society. What newspapers and magazines are doing don’t.</p>
<p>if you’re using a definition of property that doesn’t work you would be lobbying for laws that would break the internet, etc.</p>
<p>if you have working democracies and multiple sovereign countries, people can’t easily buy laws making the definition of property whatever they want it to be; not so with a single, autocratic government.</p>
<p>No single point of attack for people trying to warp the law -&gt; people running the US don’t like it; but it’s in our interest. Why? Because private property is an extremely useful idea - arguably one of our greatest inventions. (but exactly how useful is it?)</p>
<p>So far, each new definition of private property has brought more material wealth. (why?)</p>
<p>seems reasonable to suppose that new ones will too - why? Because things that have happened regularly before will probably continue</p>
<p>if just a few powerful people were too lazy to upgrade, we would have to keep running an obsolete version, which would be a disaster (how?)</p>
<hr />
<p>My analysis: You treat something as private property when it is rival and excludable (why should it be rival?). However, you can enact laws to artificially make something excludable - like in the case of piracy laws - even when the service is no longer intrinsically excludable (music and movies after data transfer became cheap). So, now what? Should you allow artificial exclusion or not? What are the costs and benefits?</p>

<div class="info">Created: August 18, 2015</div>
<div class="info">Last modified: October  6, 2015</div>
<div class="info">Status: in-progress</div>
<div class="info"><b>Tags</b>: scientific method</div>

<!-- <div id="sequence-navigation" style="text-align: right"> -->
<!--   <p>Part of <a href="./sequences.html"><i>No Sequence</i></a> -->

<!--   <p>Previous post: "<a href="">Start of Sequence</a>" -->

<!--   <p>Next post: "<a href="">Head of Sequence</a>" -->
<!-- </div> -->

<br />
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'spkrationalitytrainingground'; // required: replace example with your forum shortname
    var disqus_identifier = '/Scientific-Method.html';
    var disqus_title = 'Scientific Method';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
	var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
