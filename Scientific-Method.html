<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel="icon" type="image/png" href="./images/favicon-32x32.png" sizes="32x32" />
	<link rel="icon" type="image/png" href="./images/favicon-16x16.png" sizes="16x16" />
        <title>Scientific Method - SPK's Rationality Essays</title>
        <link rel="stylesheet" type="text/css" href="./css/default.css" />
        <link rel="stylesheet" type="text/css" href="./css/highlight.css" />

	<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script> -->
	<!-- <script type="text/javascript" src="/js/header-links.js"></script> -->

	<!-- Google Analytics stuff -->
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-51321929-1', 'pradeep90.github.io');
	  ga('send', 'pageview');

	</script>

    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="./">Rationality Essays</a>
            </div>
            <div id="navigation">
                <a href="./">Home</a>
                <!-- <a href="/sequences.html">Sequences</a> -->
                <a href="./notes.html">Notes</a>
                <!-- <a href="/about.html">About</a> -->
                <a href="./archive.html">Archive</a>
            </div>
        </div>

        <div id="content">
          <h1 id="post-title">Scientific Method</h1>

            <!-- <center><img src="https://fbcdn-sphotos-d-a.akamaihd.net/hphotos-ak-prn1/t31.0-8/p600x600/10257116_10202295769100492_2438594605053717342_o.jpg" height="400" width="300" class="sujeet-pic" alt="Sujeet pic" /></center> -->

<p><strong>Questions</strong>: How can we think scientifically?</p>
<p>Instead of trying to find the perfect description of the scientific method, let’s start with a simple, inefficient process and improve it based on feedback. Judge each version only using empirical evidence; don’t theorize idly.</p>
<hr />
<h1 id="aim-obtain-a-good-model">Aim: Obtain a good model</h1>
<p>We are uncertain about the outcomes of various scenarios. We need to predict what will happen, so that we can make good decisions. We have questions we want to answer, problems we want to solve. So, we use a model of the domain to help us answer those questions.</p>
<p>The better our model, the better our predictions will be. Wait. In what sense will our predictions be better? Well, it is a matter of induction. We humans believe that if we process the evidence we have by using Bayes Theorem, we will get the most accurate predictions overall. Yes, a mythical hypothesis that made exactly the right predictions for everything you see would be great to have, but you don’t know what it is in advance. So, it doesn’t help you make future predictions. The best you can do is use Bayes Theorem constantly.</p>
<p>So, our one and only aim is to use Bayes Theorem to get a model with high posterior probability.</p>
<h1 id="goal-of-this-essay">Goal of this essay</h1>
<p>Right now, the term “causal model” is a black box to me. I don’t understand exactly how it works inside. But I need to. I want to get a complete understanding of how causal models work.</p>
<p>First, I want to know about causal models (aka hypotheses) and predictions. What does a causal model look like (and what does it not look like)? What do predictions look like (ditto)? How does a model help you make predictions? How can you find out which experiments it talks about? For how many experiments does it make predictions?</p>
<p>Next, I want to know about alternative hypotheses. How do models differ from one another? How would a model differ from an improved version of it? How do independent and dependent variables enter the picture? What do scientific experiments look like?</p>
<p>Most importantly, I want to figure out a process by which to get better hypotheses - the scientific method, in other words. Instead of trying to get it right on the first try, I want to refine the process over time using empirical evidence.</p>
<hr />
<p>After my process description epiphany, let’s revisit the scientific method. And let’s build it up iteratively!</p>
<h1 id="causal-model-finally">Causal Model, finally</h1>
<p>Here’s my model about how causal models work.</p>
<h2 id="hierarchy-of-variables">Hierarchy of variables</h2>
<p>In some field, we have instruments for observation and manipulation. Call the things we can observe as dependent variables, and the things we can manipulate as independent variables. Note that when you don’t manipulate its value, an independent variable X would be set by the value of some other independent variable Y. So, in that model, you would treat X as a dependent variable.</p>
<p>A causal model tells you (perhaps incompletely) what values the dependent variables will take for some configuration of the independent variables.</p>
<p>This much seems implied by the form of Bayes Theorem, which asks you make predictions for any configuration of the system, i.e., predict the value of a dependent variable for some configuration of independent variables. If your model didn’t make any predictions for some scenario, then it would be held to make a random prediction, and thus most likely penalized in its posterior probability.</p>
<p>One of the main things that a model will do, is group the variables. It will assert which dependent variables will change for a change in an independent variable. So, I think you will end up with a hierarchy of independent variables, with dependent variables forming the leaves.</p>
<p>This tells us how to split the system into parts, model the parts, and glue them together.</p>
<p>Can a model omit some dependent variables? A complete model would talk about every variable for every configuration. A partial model, though, could just handle a few configurations of the independent variables. Also, it could talk only about a small group of variables - basically, one or more independent variables, and some dependent variables that they affect. That is, I hypothesize, essentially the smallest possible causal model.</p>
<p>Note that you could postulate some hidden variables that you can’t observe right now. However, at least in theory, you should be able to create tools to observe them.</p>
<h2 id="layers-of-abstraction">Layers of Abstraction</h2>
<p>Now, how do we deal with layers of abstraction? Maybe you get different layers of abstraction when you have different instruments for observing or manipulating the system. Really? Can’t you have lower-level instruments but still model the system at a higher-level, based on its regularities?</p>
<p>For example, binary code is the lowest level of abstraction we use in a computer (you could go into NAND gates or raw atoms, but let’s stop it here). How do we build abstractions of assembly language and successions of higher-level languages? We sacrifice a bit of inefficiency to capture common patterns and make it easier to write bigger programs. We remove duplication, in other words.</p>
<p>Why do we create abstractions? So that we can make useful predictions. For example, you can analyze binary code to come to perfectly legitimate conclusions about the behaviour of a program, but it would be tedious and error-prone. So, whenever you have a theoretical model of some system, but it’s too painful to reason about, you abstract it so that it becomes easier to see the consequences you care about.</p>
<p>What does an abstraction layer look like? Maybe the dependent and independent variables will just represent a clump of lower-level variables, and we can simply use the same hierarchy of variables idea as above. So, we need to create higher-level dependent variables such that the value we observe here is made up of the values of some lower-level dependent variables, but using a more convenient tool. Similarly, we need to create higher-level independent variables whose values we can change using a convenient tool, which would in turn change the values of some lower-level independent variables.</p>
<p>How exactly, though? And how can you manipulate the independent variables or observe the dependent variables if you don’t have high-level tools? If you’re going to design the tools, how will you design them?</p>
<p>Perhaps I can figure out the abstraction if I taboo the important terms.</p>
<h2 id="asking-how-and-why">Asking “how” and “why”</h2>
<p>When we ask “why” a model makes a certain prediction, we really want to know the values of dependent variables that come between the independent variable and the dependent variable. We want to know how it happens. We want to make the chain of reasoning more detailed.</p>
<p>To be precise, when we ask why X causes Y, we want to get a detailed chain of reasoning between X and Y. When we ask why X came about, we want to know what caused X in the first place. So, the first question is really “how” and the second one is “why”.</p>
<p>Make sure it handles changed conditions. If you say variable A causes variable B, ensure that for every value of A, you can determine the value of B. This is one of the main advantages of a cause - once you know the value of the independent variable, you don’t care about any of its ancestors or other variables.</p>
<p>Importantly, vary the other independent variables too. Example: food makes snails move faster. What if we have the smell of food, but not the food itself?</p>
<p>Also, try different ways of manipulating the independent variable. For example, to get aspirin to the brain (or whatever), directly take aspirin pills, or dissolve it in water and drink it, or inject it, or something.</p>
<p>Remember that time is a key independent variable.</p>
<p>Test the causal link in other scenarios. For example, if you say natural selection has made some gene more prevalent in some populations, check whether it increases the inclusive genetic fitness of those humans; otherwise natural selection won’t increase its relative frequency in the next generation.</p>
<p>Why do you predict this particular outcome? How come X leads to Y, and not Z? Why would an electrical field change the foraging behaviour of an insect?</p>
<h2 id="sine-qua-non">Sine qua non</h2>
<p>What is the smallest thing that can still be called a causal model? Well, that would be a single causal link.</p>
<h2 id="further-notes">Further notes</h2>
<p>Note: I need to handle feedback loops sometime. For now, we’ll just go with the hierarchy of variables.</p>
<p>I was stymied by the apparent impenetrability of the “models” I saw all around because they used symbols to represent previously-specified sub-models. That’s why it felt like they didn’t follow the model above.</p>
<h2 id="testing-my-hypothesis">Testing my hypothesis</h2>
<p>So, my above model suggests that you cannot have a causal model that doesn’t deal with a hierarchy of variables and layers of abstractions.</p>
<p>Specifically, what do we predict from the hierarchy-of-variables model? That a model will predict what will happen for some (or all) configurations of the independent variables in some domain. And that it will specify a hierarchy by grouping related variables. Sometimes, it may only talk about a few of the independent variables and the variables dependent on them.</p>
<p>What do we predict from the layers-of-abstraction model? That a model will talk about dependent and independent variables, just like above, but that they will represent lower-level dependent and independent variables respectively.</p>
<p>Let’s look at 10 hypotheses I have so far.</p>
<h2 id="probabilistic-models">Probabilistic Models</h2>
<p>I think Bayesian Networks work by starting with a hypothesis and then creating new hypotheses based on the evidence. Every piece of information received shifts the belief strengths of the links. The network essentially represents a new hypothesis at each point.</p>
<p>The way I was imagining hypotheses was that you have a space of hypotheses, each of them making different predictions, and that you update their posterior probabilities using the evidence. In science, for example, you create experiments that test the differing predictions of two or more hypotheses, and thus eliminate at least one of them.</p>
<p>So, are we saying that every hypothesis - every causal model - will be in the form of a Bayesian belief network? Well, yes, it will have the tree structure, but it will be fixed. You won’t change the network or update the parameters based on new evidence. If it can’t predict some evidence, its posterior probability will go down. That’s all.</p>
<p>Note that the variables in the tree need not all be observable. You could postulate some hidden variables to make the math work right.</p>
<h2 id="testing-further">Testing further</h2>
<p>I need to check whether the prose examples of hypotheses conform to my idea of a causal tree. I should be able to easily convert prose hypotheses into causal trees.</p>
<p>Also, I need to check whether the predictions they make are in the form of independent and dependent variables.</p>
<p>Let’s do that for 10 concrete prose hypotheses.</p>
<p>Later, we can work on alternative hypotheses (which I suspect are different causal structures with maybe extra dummy variables) and experimentation.</p>
<h1 id="prose-is-king">Prose is King?</h1>
<p>Results: I think prose really is a succinct way of expressing causes. Sure, you may be more precise with a causal tree, but it really is already very compressed in prose form.</p>
<p>To avoid duplicating effort, I suspect I must aim to make the prose form work better, instead of overthrowing it and installing a new form in place. For one, most of the world’s hypotheses seem to be expressed in prose form. (What about programs? What about math?)</p>
<p>In short, if the causal tree format is the bee’s knees, I want to know how well I can approximate it using prose, because that seems to be the only thing that scales. Plus, human minds have lots of limitations, and prose really may have lasted this long because it is best suited for our brains. Also, good luck describing a complicated causal tree without graphing software. (Wait. Test: How exactly do you describe a complicated causal tree using prose, then?)</p>
<p>Another test is: how do you describe a cause when there are multiple independent variables causing a dependent variable? Like, acceleration of a body depends on its mass and the net force applied to it.</p>
<p>Test whether the above model is expressive enough to cover the workings of a state machine.</p>
<p>Test your model of the scientific method on Mysterious Answers to Mysterious Questions.</p>
<h1 id="learning">Learning</h1>
<p>What do I need the scientific method for right now? I want to learn precise causal models from resources. Also, of course, I want to do research on my own by coming up with alternative hypotheses and experimenting.</p>
<p>What does it mean to “learn” a precise causal model? What would I actually end up doing?</p>
<p>Well, at the end, I must have each link in the causal tree. So, “learning” would seem to be about analyzing and acquiring causal links from the resource. If the resource (book chapter or essay) already presents them explicitly, I just have to copy them. Else, I might have to extract them from the text.</p>
<p>So, one task is to get the causal model from the resource. However, it probably also provides some evidence supporting the model. So, update the model on the evidence using Bayes Theorem.</p>
<h1 id="structure-learning">Structure Learning</h1>
<p>One form of “cause” that scientists talk about is some independent variable that changes one or more dependent variables when you manipulate it, keeping everything else constant. Ok. But what happens when other things are not constant? What happens when you change some of the other independent variables? Rather, if you figure out the isolated effect of each independent variable, how do you put together those effects?</p>
<p>For one, we get to know that the independent variable does have some effect on our dependent variables. It may have well have been that changing the variable does nothing, like when changing the colour of paint on a car does pretty much nothing to make it move faster.</p>
<p>Also, note that a causal link from A to B only tells you what effect A will have on B. I also want to know what effect A has on other variables. Figure that out too.</p>
<p>This basically helps you learn the structure of the causal model. You still have to figure out the exact parameters for each causal link, but you know how the model looks.</p>
<p>Test my idea that the variables in each causal link will be based on the tools you have. Get concrete examples of variables.</p>
<h1 id="summarizing">Summarizing</h1>
<p>What about summarizing? Actually, what is summarizing? If you need each causal link in the tree, how can you compress it even further? I need to look at concrete examples of uncompressed and compressed causal models. How do they differ? Is it to do with a layer of abstraction? Are you perhaps encapsulating some parts of the model? I mean, it can’t literally be about having fewer causal links, can it? Because we’re assuming that each causal link is from an independent variable to an dependent variable. So, you have to account for the value of every variable. How can you do that with fewer causal links?</p>
<p>Maybe you summarize by abstracting common links. That is probably the same as using higher-level variables. You start to see the patterns. However, be careful to specify all the possible values of the abstract variables. Be precise.</p>
<p>I suspect that each piece of advice you get from a book is just an abstract causal link, hopefully backed by controlled experiments. However, you usually don’t know exactly how the different pieces of advice will combine. That’s why you need domain expertise to figure out how complex scenarios play out. This holds for every piece of advice ever - just having evidence from controlled experiments is not enough. You need to know how they combine.</p>
<p>What does a controlled experiment really tell you? I think it just hints at the causal structure, plus a bit about the strength of the causal link.</p>
<p>Your diary summaries are examples of succinct but predictive models. Study them. They probably will have very few, abstract causal links. To test this, look at them and see if they form abstract causal links.</p>
<h1 id="variables-vs-process-descriptions">Variables vs Process Descriptions</h1>
<p>I somehow feel uncomfortable with this idea of causal links between variables. It seems unsatisfactory to me.</p>
<p>What I really want is a description of the underlying process that reality is using to generate what we see. I want to know the program that reality is running. That is what programs are - descriptions of processes. And, I think, that is what hypotheses are too.</p>
<p>The idea of isolating all the variables (independent or dependent) and looking at their relationships seems too low-level to me, like I’m missing the forest for the trees. I want to know the deep process that generates those surface phenomena. Plus, the variables seem quite fragile; they seem to be based on your current tools for observation or manipulation. I want to go beyond current tools. I want to know “how the universe works on such a deep level that you know exactly what to do to make the universe do what you want”. I want an in-depth understanding of the domain, dammit.</p>
<p>I believe that is what I did instinctively when I summarized book chapters or PG essays - I came up with some simple, sweeping model that could explain all of the observations and more.</p>
<p>You need to use your model of the process to say how the system will proceed given the initial state. That is all. Wait. Also, you need to infer what happened earlier using the evidence.</p>
<p>The domain of programming really helps cement this intuition, because you can’t get away with simplistic relationships between variables. You absolutely <em>have</em> to talk about the program in its vast complexity (?). It defies easy summarization. You can see the difference in predictive power between a person who knows the program inside-out and somebody who is just making a few surface relationships. This is the power of reductionism! Once you know the actual program being executed, you can see everything! There is no question of probabilities or anything. You know damn well exactly what is going to happen at each point.</p>
<p>This is why I feel queasy about using probabilities within a hypothesis. That’s the ultimate sign that you don’t understand the domain too well - you’re basically guessing at what will happen (and will thus get a lower posterior probability than someone who makes sure predictions). If you know the exact model that underpins a domain, you will be able to predict exactly what will happen, no two ways about it.</p>
<p>Maybe we can have probabilities to represent our confidence in different hypotheses (their prior probabilities), because we don’t know which hypothesis reality is using, but within the hypothesis, we should be sure of what we expect.</p>
<p>In short, a tree belief network is just not expressive enough, I think. You need a better language with which to describe processes.</p>
<h2 id="questions">Questions</h2>
<p>How will you make predictions about experiments if you don’t talk about the variables?</p>
<h1 id="do-some-scholarship-dude">Do some Scholarship, dude</h1>
<p>Eliezer already covered all this in his Epistemology sequence. There’s a well-understood field that studies the area of causal models - in a very rigorous, mathematical way.</p>
<h1 id="scientific-method-v1.0">Scientific Method v1.0</h1>
<p>Decide on a basic process of learning and use it on a hundred resources. In two days.</p>
<p>Actually do deliberate practice. Follow its principles.</p>
<p>Cure for despondency - fun failure. Work on hard projects rarely ever goes in vain. Plus, you get a powerful sense of agency.</p>
<h1 id="bayesian-rationality-vs-traditional-rationality">Bayesian Rationality vs Traditional Rationality</h1>
<p>What questions can you answer with your “scientific method” that you couldn’t answer earlier? That is the only test of your success.</p>
<p>I want to show some real progress with my understanding of the scientific method. The best way to do is to do things that people find it hard to do right now.</p>
<p>The purported advantages of Bayesian Rationality over Traditional Rationality are: handling confusion, researching with speed, formulating good hypotheses, and reasoning well based on scanty evidence. So, when people use traditional techniques, they have trouble in these areas. So, if I can understand the newer techniques and apply them here, that would demonstrate a clear win.</p>
<p>Let’s list them.</p>
<p>Where are people confused? We generally get trapped in questions regarding naive realism, I think; what we think is true seems to us to be actually true. We also find it hard to think reductionistically. We get confused by words, failing to see the actual predictions being made by some sentence. We accept mysterious explanations that explain nothing. We fail to update cached thoughts - we carry on thinking something is true even after circumstances change.</p>
<p>Where are people slow to come to the correct hypothesis? We are slow to discard hypotheses proven to be wrong. We allow ourselves too much time to get to the answers. We don’t notice surprises. We don’t practice all these skills and thus either miss a move at the right time or take too long.</p>
<p>Where do people formulate poor hypotheses? We rush to propose solutions and don’t consider alternatives. We don’t use external hypotheses, instead relying on our hidden mental processes without knowing it.</p>
<p>Where are people inefficient in using evidence? We make imprecise hypotheses - we don’t learn hypotheses that tell us exactly what will happen; we just have vague hunches. We fail to be empirical - we build castles in the air. We don’t study the existing research. We don’t actually change our minds - we fall prey to politics, etc. We don’t try to eliminate hypotheses by focussing on differing predictions.</p>
<p>What other mistakes do we make? Well, each sequence by Eliezer addresses some. Also, look at essays by PG for more examples.</p>
<hr />
<p>How do we exploit these weaknesses? Well, list concrete examples of the above and show that your method gives obviously superior results.</p>
<p>Mainly, ask which mistakes costs people a lot. Where do they pay the most for their ineffective strategies? That is where you can gain the most.</p>
<p>What techniques do people currently use (consciously or otherwise)? Mark the techniques that seem to make the least sense from a Bayesian perspective. Prioritize techniques that people would be unlikely to question if they didn’t know about modern rationality. Come up with avenues for attacking them.</p>
<p>Figure out one specific line of attack and focus all your energy on it.</p>
<p>Ask why people have continued to use the sub-par techniques. Why haven’t they upgraded so far? If these newfangled techniques really are so great, why hasn’t someone used them to achieve unbelievable things?</p>
<h1 id="future-ideas">Future ideas</h1>
<p>What’s the bare minimum we can do to use Bayes Theorem in a domain?</p>
<p>Guess a model for how things work. Then, think hard to guess another way it could be. Look at their differing predictions and observe the actual outcome. How does this help get a model with high posterior probability? By looking at the differing predictions, we get strong evidence one way or another. We will reject one of the two hypotheses and become more confident in the other.</p>
<p>I think we should aim to run experiments next - manipulate some independent variables to see what happens. Always be looking for ways to test your beliefs.</p>
<p>Look for surprises. They are places where your current model is wrong. Note that this is basically a recipe for doing research.</p>
<blockquote>
<p>Surprises are things that you not only didn’t know, but that contradict things you thought you knew. And so they’re the most valuable sort of fact you can get.</p>
<p>– Paul Graham, <a href>The Age of the Essay</a></p>
</blockquote>
<p>How do we “learn” a causal model from some resource? What would that look like? Would we memorize the predictions or the core engine that generates those predictions? I need concrete examples for this.</p>
<p>In cases where the resource provides both the causal model and some tests, you can check for yourself if you can generate predictions correctly. In more vague cases, you would need to build the precise causal model yourself based on the evidence provided.</p>
<p>When you taboo some term (like “causal model”), provide three concrete examples to really drive it in.</p>
<p>Don’t just ask what something is. Also ask what it is not! Look at what could falsify your hypothesis. If you say “if Y, then X”, think of some Y that doesn’t lead to X.</p>
<h1 id="how-to-learn-a-causal-model">How to learn a causal model</h1>
<p>Maybe take some resource, maybe a book chapter or essay, and condense it till you have the shortest amount of words that can still make the same predictions as the original.</p>
<h1 id="satisfying-work">Satisfying Work</h1>
<p>Do I have satisfying work for my scientific method missions? Why not?</p>
<p>I need to have a clear goal, step-by-step instructions (so that it’s work, not problem-solving), and continuous feedback.</p>
<h1 id="notes">Notes</h1>
<p>Identify the variables you care about. What can you observe? These are your dependent variables. What can you manipulate? These are your independent variables. Your job is now to find out what will happen for different values of the independent variables.</p>
<p>How do we improve our models? Remember, you have to predict the existing evidence as well as the previous model, and then some. Maybe you can think of this as a branching out - the old model plus two or more different changes.</p>
<p>Note that we usually employ our minds at some step when using causal models. If we knew the subject well enough, we would be able to describe it to a computer (like stock-market analysis programs that choose which stocks to buy, according to our specifications). Ideally, we want to capture the model in explicit terms, so that we can sub out the work to computers. But, sometimes, we may be forced to use the poorly-understood capabilities of our own brain. Like in Psychology where we judge how angry a person seems upon getting hit on the head - we can’t quite tell a computer to do that as accurately.</p>
<h2 id="posterior-probability">Posterior probability</h2>
<p>I was confused about our actual aim. Did we want to get a hypothesis with high predictive power (one that makes accurate, narrow predictions for a lot of experiments) or one with high posterior probability (one that has a lot of evidence backing it)?</p>
<p>Well, how would you find out if it has high predictive power? Only by testing its predictions in a variety of situations. Which would be counted as evidence in updating the posterior probability. Actually, no. To compute the posterior probability according to Bayes Theorem, you need to know the other hypotheses in play, whereas you can compute predictive power by looking at one hypothesis alone. But, predictive power only calculates the quality of your predictions on the few experiments you have observed. It tells you nothing about the other experiments.</p>
<p>I got confused by this vague concept of “predictive power”. It seems like it makes sense, but it actually doesn’t.</p>
<p>You want to know how much to believe a model. And the way to do that is to use Bayes Theorem.</p>
<h1 id="the-scientific-method-v1.0">The Scientific Method v1.0</h1>
<p>Let’s theorize about causal models based only on hardcore empirical evidence. We’ll look at causal models of different shades of accuracy - some that are mathematically precise, others that are vague and hand-waving. We’ll talk about consequences, alternative hypotheses, differing predictions, experiments, and other such scientific things by looking at concrete examples. Let’s not build castles in the air.</p>
<p>Mission: Get three concrete examples of “causal models”, along with three experiments each.</p>
<p>How will I know I’ve done it right? You should be able to use the models to make predictions for the experiments.</p>
<p>Okay. Go.</p>
<h1 id="say-no-to-definitions">Say No to Definitions</h1>
<p>Definitions aren’t causal models. “A generous person is someone who shares his wealth with others”. Well, say John shared $5 equally with his four friends when he was a kid. Is he a “generous person”? Well, according to the definition, yes. But, after ten years, will he share the $5000 he gets in a lottery?</p>
<p>The definition doesn’t help you make future predictions. If you do make predictions, it would be because of the evidence you saw (him sharing $5 as a kid), which is quite weak evidence, especially when it comes to what he will do for big amounts of money when he is much older. The definition is nothing but a label - “generous” - and just knowing the label doesn’t help you make narrow predictions.</p>
<p>Basically, when should you agree that a definition applies to a person? If John shared $5 with his friends when he was a kid, does that make him a “generous person” and thus likely to share even $5000? Or would you wait for more evidence? Why should you wait? Isn’t the definition clear? The definition is only as good as the criteria you use to apply it.</p>
<p>John shared $5 with his friends. Ok, as per the definition, he now has the label “generous person”. Big deal. So what? The word “generous” doesn’t mean anything by itself. We only care about the predictions that it allows us to make.</p>
<p>To assure yourself of this, let’s say someone argues that the definition is not “air-tight” enough. They say we should label someone “generous” only after they have done a hundred deeds of wealth-sharing. Ok, assume John shares $5 everyday, does that make him “generous”? Now, they say it must be significant percentage of his wealth.</p>
<p>What if he does that on a hundred (or a thousand) occasions - somehow replenishing his wealth afterwards - but then one day doesn’t share even when his close friend is in dire need? Is he still “generous”? More pertinently, what do you predict he will do tomorrow when another friend is in need? Will you say that he won’t help the friend? But, he is “generous” according to the definition, right? Or, will you say that he will help the friend? But, he might have turned cold and therefore stopped helping anyone.</p>
<p>Anyway, the lesson is: don’t argue using definitions.</p>
<p>Then, what do you argue using?</p>
<p>What is it that definitions don’t have? Well, they don’t let you make predictions about specific experiments.</p>
<h1 id="collecting-models">Collecting models</h1>
<h2 id="pgs-inequality-and-risk">PG’s Inequality and Risk</h2>
<p>Only two ways to reduce economic inequality - give money to the poor or take it from the rich.</p>
<p>[Translation: give money to poor -&gt; wealth of poor; take it from the rich -&gt; wealth of rich; wealth of poor, wealth of rich -&gt; economic inequality]</p>
<p>If you want to give money to the poor, you have to get it from somewhere; you can’t get it from the poor, so you have to get it from the rich.</p>
<p>[Translation: get money from rich -&gt; give money to poor; get money from poor -&gt; give money to poor (not much money here)]</p>
<p>Therefore, giving money to the poor means taking it away from the rich, and vice-versa.</p>
<p>[because there are no other causal links from get money from rich or to give money to poor.]</p>
<p>If you help the poor become more productive, they would become richer, but the rich wouldn’t become poorer.</p>
<p>[Translation: do stuff (education, etc.) -&gt; productivity of poor -&gt; wealth of poor]</p>
<p>However, making the poor more productive won’t reduce economic inequality, because it makes the rich richer too. Why? Because if there are more rich poor people, there are more workers and customers for the rich people.</p>
<p>[Translation: productivity of poor -&gt; more workers -&gt; wealth of rich; wealth of poor -&gt; customers -&gt; wealth of rich;]</p>
<h2 id="steve-yegges-the-emacs-problem">Steve Yegge’s The Emacs Problem</h2>
<p>When you write in Lisp, you don’t need to have configuration files that need special-processing. You can write them in Lisp, and use the full power of the language.</p>
<p>Why do people rave about the power of separating code and data? Because they’re using languages that can’t do a good job of representing code as data. (why can’t those languages do that?)</p>
<p>[Translating the above into variables: language -&gt; how well they represent code as data -&gt; do you feel like raving about the power of separating code and data.</p>
<p>He says that most current languages can’t do a good job here, and so that means their users will rave about the power of separating code and data. But why? It can’t be that if your product doesn’t do a good job of something you will rave about the opposite (or can it)? I think we need to specify some more variables between the not-good-job bit and the raving bit. Maybe it’s to do with the commitment and consistency effect - where you start valuing something more just because you’re doing it (though I’m not sure of the precise relationship).]</p>
<p>Why does he say people really want to represent code as data? Because the half-languages for configuration are all creeping towards Turing-completeness.</p>
<p>[Translation: how expressive you want the configuration language to be (A) -&gt; Turing-completeness of configuration language (B); A -&gt; representing code as data or not.]</p>
<h2 id="steve-yegges-practicing-programming">Steve Yegge’s Practicing Programming</h2>
<p>Don’t read this blog if someone is insisting that you read it. Wait until you really think you want to get better at programming. Why? Homework just seems to kill the desire to learn. (why?)</p>
<p>[Translation: homework -&gt; read blog, desire to learn; desire to learn -&gt; read blog; desire to learn, read blog -&gt; how much you learn;]</p>
<p>Merely doing your job everyday doesn’t qualify as real practice. Because you have to set aside some time once in a while and do focused practice in order to get better at something.</p>
<p>[Translation: how you do your job -&gt; time, focussed practice -&gt; performance]</p>
<p>Why are the great engineers as good as they are? Because they practice all the time.</p>
<p>[Translation: how much they practice -&gt; skill level of the great engineers]</p>
<h2 id="defining-property-by-paul-graham">Defining Property by Paul Graham</h2>
<p>People are enjoying music and movies without paying for them. The record labels and the movie studios argue that they own the music and that thus people are stealing the music and movies.</p>
<p>[pay -&gt; get goods and services “steal” -&gt; get goods and services “own music”, pay -&gt; should get money from it (how much?) “own music” and people “steal” -&gt; you won’t get much money You aren’t getting much money, but you “own” the music; therefore, people are “stealing”; But, another possibility is that you don’t “own” the music. ]</p>
<p>Thinking of treating smells as property sounds ridiculous to PG. Why? Because it “won’t work” to treat smells as property. Why?</p>
<p>When could we charge for smells?</p>
<p>If it works to treat something as property, you may count it as property.</p>
<p>Hunter gatherers didn’t treat land as property the way we do. (why?)</p>
<p>The definition of property changes very slowly (why?). So, people think it has a single, unchanging definition.</p>
<p>With the arrival of networks, data moves much faster and cheaper (how?).</p>
<p>Wishful thinking and short-term greed -&gt; labels and studios are accusing us all of stealing (as opposed to accepting it and doing something else with the new technology; but will any business owner really do that?)</p>
<p>driven by bonuses, not equity; therefore, try to extract money from stuff they do already.</p>
<p>are you saying that if they were driven by equity, they would behave otherwise? What about newspaper owners and stuff?</p>
<p>When people can charge for content without “warping society” to do it, we should allow them to charge for it.</p>
<p>The crazy legal measures that the labels and studios have been taking seem like warping society. What newspapers and magazines are doing don’t.</p>
<p>if you’re using a definition of property that doesn’t work you would be lobbying for laws that would break the internet, etc.</p>
<p>if you have working democracies and multiple sovereign countries, people can’t easily buy laws making the definition of property whatever they want it to be; not so with a single, autocratic government.</p>
<p>No single point of attack for people trying to warp the law -&gt; people running the US don’t like it; but it’s in our interest. Why? Because private property is an extremely useful idea - arguably one of our greatest inventions. (but exactly how useful is it?)</p>
<p>So far, each new definition of private property has brought more material wealth. (why?)</p>
<p>seems reasonable to suppose that new ones will too - why? Because things that have happened regularly before will probably continue</p>
<p>if just a few powerful people were too lazy to upgrade, we would have to keep running an obsolete version, which would be a disaster (how?)</p>
<hr />
<p>My analysis: You treat something as private property when it is rival and excludable (why should it be rival?). However, you can enact laws to artificially make something excludable - like in the case of piracy laws - even when the service is no longer intrinsically excludable (music and movies after data transfer became cheap). So, now what? Should you allow artificial exclusion or not? What are the costs and benefits?</p>

<div class="info">Created: August 18, 2015</div>
<div class="info">Last modified: September 27, 2015</div>
<div class="info">Status: in-progress</div>
<div class="info"><b>Tags</b>: scientific method</div>

<!-- <div id="sequence-navigation" style="text-align: right"> -->
<!--   <p>Part of <a href="./sequences.html"><i>No Sequence</i></a> -->

<!--   <p>Previous post: "<a href="">Start of Sequence</a>" -->

<!--   <p>Next post: "<a href="">Head of Sequence</a>" -->
<!-- </div> -->

<br />
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'spkrationalitytrainingground'; // required: replace example with your forum shortname
    var disqus_identifier = '/Scientific-Method.html';
    var disqus_title = 'Scientific Method';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
	var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
