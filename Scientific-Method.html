<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel="icon" type="image/png" href="./images/favicon-32x32.png" sizes="32x32" />
	<link rel="icon" type="image/png" href="./images/favicon-16x16.png" sizes="16x16" />
        <title>Scientific Method - SPK's Rationality Essays</title>
        <link rel="stylesheet" type="text/css" href="./css/default.css" />
        <link rel="stylesheet" type="text/css" href="./css/highlight.css" />

	<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script> -->
	<!-- <script type="text/javascript" src="/js/header-links.js"></script> -->

	<!-- Google Analytics stuff -->
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-51321929-1', 'pradeep90.github.io');
	  ga('send', 'pageview');

	</script>

    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="./">Rationality Essays</a>
            </div>
            <div id="navigation">
                <a href="./">Home</a>
                <!-- <a href="/sequences.html">Sequences</a> -->
                <a href="./notes.html">Notes</a>
                <!-- <a href="/about.html">About</a> -->
                <a href="./archive.html">Archive</a>
            </div>
        </div>

        <div id="content">
          <h1 id="post-title">Scientific Method</h1>

            <!-- <center><img src="https://fbcdn-sphotos-d-a.akamaihd.net/hphotos-ak-prn1/t31.0-8/p600x600/10257116_10202295769100492_2438594605053717342_o.jpg" height="400" width="300" class="sujeet-pic" alt="Sujeet pic" /></center> -->

<p><strong>Questions</strong>: How can we think scientifically?</p>
<p>Instead of trying to find the perfect description of the scientific method, let’s start with a simple, inefficient process and improve it based on feedback. Judge each version only using empirical evidence; don’t theorize idly.</p>
<hr />
<h1 id="todo-summary">TODO: Summary</h1>
<h2 id="causal-models">Causal Models</h2>
<p>I want to get a causal model with high posterior probability. Causal models are causal Bayesian networks. We use locality of causality (temporal and spatial) to factorize and simplify our uncertainty about the world.</p>
<p>Use observed correlations and experimental evidence to pin down the causal structure. You need to include every observable in your model, else you will be penalized by Bayes Rule. See nothing but causal models, experiments, precise predictions, and outcomes. Think in terms of anticipated consequences - what are the causes and effects? Exercise all the different values of the cause to see what effects you get. Ask how some cause leads to its effect; also ask why the cause came about in the first place.</p>
<p>Summarizing is about abstracting some important causal links. Controlled experiments help you figure out the active ingredients in some system. However, you need further evidence to know how the ingredients combine. I feel causal models aren’t as expressive as a process description of the system (a program).</p>
<h2 id="goals">Goals</h2>
<p>Goals: Explain in your own words precisely what a causal model is. How can you falsify a causal model? By positing alternatives?</p>
<p>Next, what is the scientific method? How do you get to a good causal model when doing <em>original research</em>? How do you get to a good causal model when you’re <em>learning</em>? In which domains can I get good feedback about the predictive power of my model? How is scientific thinking different from ordinary thinking? Where exactly will you behave distinctly?</p>
<p>The way I see it, science is all about generating alternative hypotheses that explain the current evidence equally well, and using further evidence to narrow it down. Fundamental belief of a scientist: how can I test or falsify this hypothesis? That is, generate alternative hypotheses that explain the current evidence equally well.</p>
<p>When I’m completely ignorant about a topic, I would have a chance to guess alternative hypotheses based on very little evidence, which is something I want to train for. Otherwise, I have too much evidence to really come up with alternatives. I think I have trouble coming up with alternative hypotheses when I have too much implicit evidence about the domain. I suspect I can get practice examples containing little evidence from textbooks and journals in unfamiliar sciences. You can test how good your alternative hypotheses are by seeing how many causal links you got right.</p>
<p>However, we aren’t working in a complete vacuum. We have background knowledge about the domain. We should use them in formulating detailed models.</p>
<p>Problem statement: Given existing evidence, come up with hypotheses that explain it equally well.</p>
<h2 id="minimum-viable-product">Minimum Viable Product</h2>
<p>What is the bare minimum I can do to start using the scientific method? Generate alternative hypotheses for some given evidence?</p>
<p>Collect concrete examples of causal models, alternative hypotheses, and experiments so that you can refine your understanding.</p>
<p>Finally got a good handle on alternative hypotheses (I think). Think locally!</p>
<h2 id="ideas-for-practice">Ideas for practice</h2>
<p>Look for surprises. Use the experiments in some domain to test your grasp of the model. Taboo the major words. Think only in terms of models and variables.</p>
<p>Seek to explain phenomena using the base model of the domain.</p>
<p>Only accept a causal model insofar as your evidence uniquely supports it. Keep the equally supported alternative hypotheses in mind at all times.</p>
<p>Focus on maximizing the number of <em>reaches</em>, not just mere repetitions.</p>
<p>Think in terms of the variables. Don’t deal in abstract concepts. Ask for precise predictions: “A often leads to B” - exactly how often? Specify the exact effect of some cause.</p>
<hr />
<h1 id="todo-aim-obtain-a-good-model">TODO: Aim: Obtain a good model</h1>
<p>So, our one and only aim is to use Bayes Theorem to get a model with high posterior probability.</p>
<h1 id="todo-what-ive-learned-so-far">TODO: What I’ve learned so far</h1>
<h2 id="diffs">Diffs</h2>
<p>How has my understanding of the scientific method improved over the last month?</p>
<p>The main leap so far is the notion of a causal model, in terms of a Causal Bayesian Network. It’s no longer a black box to me. I have a good idea of the pieces inside.</p>
<p>Also, I no longer talk about the whole state of the world. We assume the temporal and spatial locality of causality, so we can break the world into chunks and deal with the chunks independently. So, exploit your knowledge of which things happen close together to simplify your model.</p>
<p>One more thing I learned was to identify correlations first, and then posit causal explanations.</p>
<p>I’m convinced that you need to answer “how” by bringing in as many variables as you can between cause and effect. Otherwise, your model can’t answer questions about those variables and will thus be marked down by Bayes Theorem.</p>
<p>Ah! You’re not done when you just include a few variables in your model. You need to accommodate every variable that you can observe or manipulate. Also, you must be able to answer low-level questions after tabooing the abstract words.</p>
<p>Also, you need to answer “why” for every top-level variable - what causes it to be so?</p>
<h2 id="to-do">To-do</h2>
<p>What do I still need to do? I need to resume collecting concrete examples of causal models, differing predictions, experiments, etc. so that I can test my understanding. If Causal Bayesian Networks are truly capable of expressing any model, then you should be able to use them to describe all the scientific models around you, big or small.</p>
<p>How will we get differing predictions if we just build one causal model from the data? Or, maybe we posit alternative causal models, with varying causal structures and parameter values. Test this by looking at alternative hypotheses from the scientific world - do they fit the pattern of different causal structures governing the same variables?</p>
<p>I don’t fully understand what a causal link actually means. What can’t it be?</p>
<p>Now that we deal in causal models, I’m not sure what it means to extend a model. If it is about adding new causal links to constrain new variables, that’s fine, I guess.</p>
<p>Tests that remain: Can a causal model in the above style forbid outcomes and otherwise focus your uncertainty, as required by Mysterious Answers to Mysterious Questions? How does it help you ask questions like “what can’t it be”?</p>
<p>How would you go about trying to test or falsify a causal model? For example, take my beliefs about the world. How to test them efficaciously? If you posit that A causes B, then if you intervene at A, then B should take the predicted value. Otherwise, if you’re just observing A, then B should be independent of its non-effects given A.</p>
<p>Also, I need to test the causal model idea on multivalued variables.</p>
<p>I’m still not sure about latent variables. I suspect that they come in when you’ve not really understood the domain well, because if you’ve captured the system in detail, you won’t need any extraneous variables. Reductionism means that you can explain stuff in terms of smaller stuff. All virtual or latent variables should just be labels for some configuration of stuff.</p>
<p>I’m uncertain about using causal models to help in designing programs or art or whatever. I don’t know if they scale well to such complex endeavours. Perhaps a formal system (or language) is more suited to the task? How so?</p>
<h2 id="remember-this">Remember this</h2>
<p>See nothing but causal models, experiments, outcomes, and predictions.</p>
<p>I must obtain precise causal models.</p>
<p>Think in terms of anticipated consequences. In terms of causes, what that means is look at the current state and ask what effects you expect to see, as per your causal model. You’re not allowed to make predictions about the future without talking about the causes that will take the world from now to then.</p>
<p>Play around with a bunch of concrete causal models. See what happens when you have a bunch of causes for some variable - how do their conditional probabilities interact? Maybe get software for this (R, perhaps?). Check out UNBBayes or SamIAm simulation software.</p>
<h1 id="todo-goals-revisited">TODO: Goals, revisited</h1>
<p>Explain precisely what a causal model is. Show me some examples. Talk about the implications of a causal link from A to B. Specify exactly what evidence you need to posit a causal link. There’s the causal Markov assumption - A causes B means that, given A, any other X will be uncorrelated with B. You could set A, and then try to set everything else, B should not change.</p>
<p>How do you falsify a causal model? I think you test whether the necessary conditions for each causal link are satisfied.</p>
<p>Talk about the exact process you need to use to get from zero to a good causal model (whatever that is). What is the scientific method that I’m supposed to be using here? It’s so vague right now. I need clear step-by-step actions.</p>
<p>Where does scientific thinking differ from ordinary thinking? Is it mainly in seeking out differing predictions and trusting only the experimental results? Also, how does Bayesian thinking differ from Traditional Rationality? Now, how can we exploit these differences to test our understanding of causal models?</p>
<p>Most importantly, how is my understanding of the scientific method falsifiable right now? How can I test it so that the world will come out one way if it is correct and another way if it is wrong? This, I think, is the fundamental thought process of a scientist: how can I falsify or test my beliefs? Practice it.</p>
<p>Remember, my aim is not to prove to others that the scientific method can be very useful. It is to test for <em>myself</em> whether the scientific method is as powerful as I think it is. I really don’t know. I get the feeling that it can be very useful as a problem-solving tool, but in the end that’s just a hunch. I need to find out for sure.</p>
<p>For that, I must learn how to formulate causal models, as taught in the domain of causality, and test my understanding on real-world problems. Only when I can solve real problems as well or better than current standards can I say that the scientific method, as I have understood it, is powerful.</p>
<p>If the causal model you get at the end is the best hypothesis among all the others, then every other hypothesis must be wrong somehow. Make a list of all the wrong hypotheses ever and show how you could have done better.</p>
<h1 id="release-the-scientific-method">Release the Scientific Method</h1>
<p>The first thing you do with a project is release it. So, let’s release the scientific method. Let’s come up with some dirt-simple version of it and use it on a hundred problems.</p>
<p>What’s the product supposed to be? Get a causal model that can answer as many questions as you can in a particular domain.</p>
<p>Aim: Given some evidence, figure out hypotheses that explain it equally well.</p>
<p>How? For now, just take each observation you have and think of different mini-causal structures that satisfy it. Combine those causal structures into coherent causal models that predict all the evidence. Then, use any experimental evidence to distinguish between the alternatives. This way, you should get to hypotheses with high posterior probabilities.</p>
<p>Here’s the key difference from before: earlier, I thought in terms of constructing entire giant alternative hypotheses, things that differed at every level. However, now that we have locality of causality, we can <em>think locally</em>. Take up parts of the causal model - maybe just a single causal link, or a triplet of variables - and ask how they might be arranged differently.</p>
<p>Thinking locally means thinking in terms of nearby causes and shutting out faraway ones. Once you know about the parents of a variable, you don’t need to care about the ancestors. You have all the information you need. So, instead of asking for abstract general causes of things, ask what happened just before this; ask what happened close to this. Think locally and concretely, not globally and generally.</p>
<p>Go ahead with this informal algorithm and see where you hit roadblocks.</p>
<h2 id="notes">Notes</h2>
<p>Resources I want to use to understand causality: Judea Pearl’s Causality; Targeted Learning; a university web page with lecture slides and lab assignments (link coming soon).</p>
<p>Why am I finding it hard to “practice the scientific method” right now? Because I don’t have a clear step-by-step plan to follow. I don’t know what exactly I’m supposed to do.</p>
<p>Ok. Science is about generating alternative hypotheses that explain the existing evidence equally well and using further evidence to distinguish between them. So, let’s design a basic practice plan. Step one is to collect evidence - correlations, experimental evidence, or just plain observations. Step two is to identify the variables. Step three is to come up with alternative models for each piece of evidence. Step four is to note down where they make differing predictions, i.e., variables for which they posit different causes. Step five is to combine the mini-models to get several complete models.</p>
<p>Enumerate the places where some variable occurs in the real world. For example, exerting self-control deplete willpower - well, list 20 actions that make you exert self-control.</p>
<p>Keep track of the refuted hypotheses - those are what people believe. You can then easily point out the differing predictions.</p>
<p>Cut through with every move you make. Your every action should result in either acquiring a new correlation or coming up with a new causal model for some evidence or coming up with a differing prediction between hypotheses. If not, don’t do it.</p>
<p>When positing a cause, check if you can manipulate the supposed cause to get the desired effect.</p>
<p>If causal analysis is so powerful, why aren’t more people benefiting? I think it’s because of naive realism. Don’t underestimate how recent and counter-intuitive scientific, empirical thinking is. Because you have to explain the millenia of darkness before then.</p>
<h2 id="practice-problems">Practice Problems</h2>
<p>Why am I looking for dozens of small problems for practice? Why not take on one single problem at a time, no matter how trivial it may seem at the start, and analyze it in depth using the scientific method? If it works out well, I can move on to more complex problems. I would have a trail of solved problems behind me, boosting my morale.</p>
<p>Get into the habit of solving one problem at a time, no matter how trivial. You can always scale it up. Wrap up each problem before moving to the next.</p>
<p>Maybe start The Great Scientific Method Project - take up one resource or topic every day and extract the relevant, detailed causal models from it and run experiments, if possible.</p>
<h2 id="refinements-to-the-scientific-method">Refinements to the Scientific Method</h2>
<p>Look at the other effects of some cause. I don’t know if this will be useful because if we’re interested in some variable it affects, we will investigate the immediate causes anyway. Or maybe I need to look at whether some causal link holds up in other scenarios.</p>
<h2 id="other-skills-i-need-to-learn">Other Skills I need to Learn</h2>
<p>The skill of not flinching away from thoughts. I somehow manage to not-think about inconvenient thoughts - about how I could be going wrong at the moment, or how I could be doing something better. I need to be more aware of my thoughts processes, as Harry Potter suggests.</p>
<p>Another skill is the game of Follow the Improbability. It’s what Harry Potter used in one of the later chapters of HPMOR. I don’t fully know how to use it, but I suspect that it is very useful.</p>
<p>How do I get feedback on my practice? Some measurement - maybe number of reps - number of reps of what?</p>
<p>Practice noticing confusion and noticing surprise. Also, learn to notice naive realism.</p>
<h1 id="lessons-from-locality-of-causality">Lessons from Locality of Causality</h1>
<p>Always think in terms of the immediate causes. Instead of talking about grand differences between hypotheses, just zoom in on one variable for which they posit different immediate causes. That’s all it takes. Locality of causality says that if some variable comes out differently according to two hypotheses, then the difference must be because of its parents; the rest of the model doesn’t matter. So, exercise the parent causes that are different and you will get evidence one way or another.</p>
<p>The dual of that is to think in terms of immediate effects. But you can’t really isolate the effects on its direct children, can you? The effects will propagate to all the descendants, which doesn’t simplify your task in any way. Thinking in terms of immediate causes is useful because you can cut the causal graph off at the parents.</p>
<p>Corollary: Don’t think in terms of faraway causes. Keep it up close and personal.</p>
<p>Corollary: Alternative hypotheses are nothing but different immediate causes. So, to formulate an alternative hypothesis, just ask which variable’s immediate causes you are going to change. It’s not magic. Think of possible factors and choose subsets to get distinct hypotheses.</p>
<p>So, the central question is: what are the possible immediate causes for this variable? What happened seconds before this? What happened a few metres around this?</p>
<p>Basically, ignore the path by which the world got here. Just look at the previous state and make all your predictions. It doesn’t matter how the switch got flipped; once you know it’s flipped, you don’t care.</p>
<p>Could that be the essential difference between scientific and unscientific thinkers? Is it that we humans naturally posit long and hazy connections between things instead of looking at short, specific, immediate causes? (I think I just made a long and hazy connection here, instead of looking at the immediate causes.)</p>
<p>This state-based thinking leads to a dramatic reduction in complexity, I think. This could give us a huge advantage over algorithms that throw away the state-transition information. Instead of dealing with a large web where pretty much everything causes everything, we just look at causes and effects within a small locality in time and space.</p>
<p>Also, don’t accept any variable without knowing its causes. Otherwise, unless it’s some huge thing that doesn’t really change, you’re flying blind.</p>
<p>Test for “A causes B”: Manipulate A directly. B should change. Also, manipulate other things but keep A (and other immediate causes of B) constant. B shouldn’t change.</p>
<p>Taboo the variables. For example, what does “self-control” really imply? What tasks demand that of you? Does concentration require self-control? Does some physical activity require it?</p>
<p>When considering whether A can cause B, ask about the possible known causes of B. If some other factor unrelated to A is known to determine B, then A cannot cause B, directly or indirectly. The same goes when asking whether something can cause both A and B.</p>
<p>When someone poses a new hypothesis, ask what factors they say <em>won’t</em> affect some variable (directly). For example, the virtue theory of willpower says that time or action won’t affect willpower, whereas the willpower as muscle theory says that actions will affect willpower but virtue probably won’t. This gives us easy distinguishing tests.</p>
<p>So, don’t talk about what affects X. Talk about what <em>doesn’t</em> affect X - the things that are not direct causes.</p>
<p>An experiment basically tells you that the intervention A is a cause of the dependent variable B. So, barring independent variables that come between A and B, no matter what else we change, if you change A, then B will change accordingly.</p>
<p>Keep your variables narrow. For example, willpower available for tasks of type A need not be the same as that for tasks of type B. It just so happens that it is.</p>
<p>Make sure that your variables are observable or manipulable. For example, I thought “does the hypothesis constrain a variable” was a good enough variable. But, later I realized that I had no test for whether that variable was true or false. I couldn’t really observe its value.</p>
<h1 id="where-to-go-from-here">Where to go from here</h1>
<p>One idea is to take unfamiliar journals or textbooks and practice extracting a causal model from them.</p>
<p>Another is to work on PG essays and LW posts. Also, I can take up further technical books like those on deliberate practice, cognitive psychology, and neuroscience.</p>
<p>Instead of asking which problems the scientific method can solve, I need to ask which problems I want solved. It doesn’t have to be a grand unified list of all important problems ever. I can just start with three problems I want solved. Note that these don’t have to be unsolved problems - I can look at old solved problems and ask what methods of thinking would have helped me solve them.</p>
<p>Now that we know of locality of causality, we no longer need big, honking case studies. We can zoom in on narrow examples to practice the above skills. So, don’t look for large-scale experiments; even just one small experiment here and there can be enough.</p>
<h2 id="what-skills-do-i-want-to-practice">What skills do I want to practice?</h2>
<p>Generating alternative hypotheses for some particular variable, given some evidence. The problem statement becomes: given an amount of evidence, what different causal models can you come up with?</p>
<p>Also, making predictions using a given causal model, and noticing where they don’t match with reality.</p>
<p>One more core skill is to use non-experimental evidence to eliminate hypotheses. You don’t always have the luxury of running interventions, let alone randomized controlled trials.</p>
<p>Next, of course, is the skill of running experiments, hopefully ones that give you maximum information.</p>
<p>One skill is to list variables of interest - anything that might cause, be caused, or in any other way be correlated with the others.</p>
<p>Most important of all, connect your models to reality. You form models using experimental evidence, cool. But, now, test it against real life.</p>
<p>Another skill is to enumerate the instances of a class. You may say that “stress” causes decreased “willpower”, but you should be able to predict that when someone is worried about giving a presentation, they might stuff their face with sugary cookies before the event.</p>
<p>Better yet, come up with a test that tells you whether some particular instance is part of a class. In short, each variable is just an interface and you calculate its value by asking whether some instance satisfies that interface. But the question remains, what does this “interface” look like? Is it nothing but the causes of that variable? For example, stress may decrease your success at some willpower challenge, but what constitutes a willpower challenge?</p>
<h2 id="truly-confused">Truly Confused</h2>
<p>Manufactured alternatives somehow seem lame to me because I already have evidence that rules them out. That’s why I feel it’s pointless to construct them. However, in more complicated scenarios, where I don’t have nearly enough evidence, I will need to create fine-grained models.</p>
<p>I have the luxury of too much evidence. That’s why I don’t see the point in creating alternative models. I will be pushed only when I am lacking evidence. I must <em>genuinely not know</em> what the right answer is. That’s when I will hunt down alternative models with zeal - the answer could be any one of them!</p>
<h2 id="ignorance-is-bliss">Ignorance is Bliss</h2>
<p>The key problem is that I need to get as little evidence as possible from the domain, but in general, the main way people present evidence is by showing the correct hypothesis itself. Yes, that encodes within in it all the evidence seen, but it ruins the exercise for me.</p>
<p>Lack of evidence forces me to generate truly plausible alternatives. So, how do I get some evidence from the domain without peeking at the final answer itself?</p>
<p>What kind of evidence do you expect to find in real-world scientific research? Mimic it using the final causal model. How?</p>
<h2 id="reflect-real-world-science">Reflect real-world science</h2>
<p>I want to practice solving problems similar to those that I would face in the real world. The worth of my training is decided by how well it equips me for real-world problems. I suspected that these problems would require me to think up alternative hypotheses and conduct experiments, so that’s why I was struggling to find out practice exercises for that.</p>
<p>However, I now wonder, what are these real-world problems that I’m so confident the scientific method will help me with? Why exactly do we need the scientific method? Yes, it’s all very well to say that anywhere you’re uncertain, you need to use science to reduce your ignorance. But, where exactly is that?</p>
<p>Name three concrete problems you want to solve.</p>
<p>For one, I want to understand precisely how motivation works - why we procrastinate, what we can do to avoid it, etc. Also, I seek to know exactly how to increase any particular skill. I also want to learn how to write powerful programs without too much trouble.</p>
<p>Basically, I want to solve various problems in life, for myself and for others. And for that, I believe that I would need to figure out the truth about those things aka get a good causal model of them.</p>
<p>The thing is, for research problems in psychology or the natural sciences, you need a lot of evidence. In psychology, you need to test your theories on a wide variety of people before you can be reasonably confident. In physics, you usually need heavy equipment to test your ideas. So, I can’t hope to do original research in these areas, not without joining some university. The best I can aim for is to gather the technical resources laid out by the researchers and using it to build an accurate causal model in my head.</p>
<p>So, there are two kinds of problems: those I must solve by doing original research, and those I can solve by learning from others’ work.</p>
<p>Ok. Name five concrete problems of each type.</p>
<p>The problems I mentioned earlier were of the scholarship type - I had to learn a precise model using existing research. Other examples include sleep schedule (how can I wake up early everyday?), writing (how can I write more engagingly?), self-esteem (how can I feel better about myself?), etc.</p>
<p>Problems where I would have to obtain evidence myself: writing a program, designing a plan for some project, etc. Basically, where can I run experiments or observe things on my own? Social interactions, personal health, programming, writing, math problems, beliefs about the world, etc. As I’m learning a model from some resource and trying to apply it to my life, I need to test how well I’ve understood it.</p>
<p>How are people solving these problems in the real world? How can the scientific method help me learn or create good models?</p>
<p>For now, we can assume that I’m going to do a lot more of learning than research. So, let’s focus solely on that for now, and take on research later.</p>
<h2 id="computing-consequences-is-easy">Computing consequences is easy?</h2>
<p>I used to think that the hard part of science was computing the consequences of existing ideas. But, now that we think in terms of variables and causal models, does that hold anymore?</p>
<p>If we believe A causes B, then whenever we see A, we expect to see B. It’s as simple as that. Because of locality of causality, when we’re curious about the value of some variable, all we do is ask about its immediate causes. Nothing else matters.</p>
<p>In effect, once you know the causal model and can observe the values of each variable, you don’t have to travel across long chains of reasoning to compute some answer. You just have to deal with the immediate causes of some variable. In case some of them are not directly observable, you travel a bit further up the causal chain till you get something you can observe. This means that, if you can observe much of the system, a causal model vastly simplifies the work of reasoning. Each prediction is just a single step of deduction, not some great complicated calculation.</p>
<p>Still, keep an eye out for this. If reasoning is really as easy as I’ve suggested above, I should be able to solve problems much more rapidly using causal thinking. (The same arguments hold for functional programming too.)</p>
<p>The main test for this comes, I think, when you’re building a new layer of abstraction, like say chemistry on top of the laws of physics. However, it doesn’t have to be complicated. You still take one variable at a time and ask which variables could have caused it, as per the laws of physics. You still keep thinking in terms of immediate causes.</p>
<h2 id="todo-lessons-from-the-willpower-study">TODO: Lessons from the Willpower Study</h2>
<p>Plus, how to go backward from the interesting variables.</p>
<h2 id="lessons">Lessons</h2>
<p>Look at the inverse of the variable. Ask what causes X, but then also ask what causes not-X.</p>
<p>Similarly, ask what happens when the alleged cause is turned off. If you do X, then Y happens. What if you do not-X?</p>
<h2 id="programming">Programming</h2>
<p>Programming is different and powerful because you can intervene cheaply. Modifying the source code of a program or even just giving it different inputs is easy. So, the main differences that come about between scientific thinking in the real world and in programming would be because of the ease of intervention in the latter.</p>
<h1 id="practice-tips">Practice tips</h1>
<p>Think only in terms of hypotheses. Every single thing in the world is either a hypothesis, experiment, prediction, or evidence. That’s all. Focus on one particular thing at a time - in one pass, look for hypotheses; in the next, look for experiments; and so on.</p>
<p>If some part of a hypothesis doesn’t deal with any evidence, then it has no business being there. This is test-driven development, in other words. Get the evidence, show that your current model fails to predict it, and then postulate some extra cause. So, the key is in finding experiments where your current model doesn’t predict correctly.</p>
<p>It’s not about the number of reps. It’s about the number of <em>reaches</em>. Big difference! You have to actually do something you’re not good at.</p>
<p>Have Fun Failure. You should fail about 80% of the time.</p>
<p>Much of the time, the scientific thinking you’re doing is parallelizable. So, don’t try to go through to the end before you start the next pass. Stop at some convenient point and go to the next step so that you have a short cycle with quick feedback.</p>
<p>Ask: What would falsify your hypothesis?</p>
<p>Taboo “often”, “sometimes”, “usually”, “many”, etc. Be precise. Ask for narrow predictions - “you become stupid after hours of work” - exactly how stupid, after how long?</p>
<p>For each independent variable, ask yourself if you can manipulate it. For each dependent variable, ask yourself it you can measure it. Taboo it, in other words.</p>
<p>For each independent variable, ask which dependent variables it might affect.</p>
<p>It’s not that the independent variables “cause” the dependent variables to change. It’s just that they let you <em>predict</em> the values of the dependent variables.</p>
<p>If you have to add a lot of corner-cases and details to your hypotheses, you should probably go a level deeper and find a more powerful, general hypothesis (like with stuff and signalling).</p>
<h2 id="surprises">Surprises</h2>
<p>Look for surprises. They are places where your current model is wrong. Note that this is basically a recipe for doing research.</p>
<blockquote>
<p>Surprises are things that you not only didn’t know, but that contradict things you thought you knew. And so they’re the most valuable sort of fact you can get.</p>
<p>– Paul Graham, <a href>The Age of the Essay</a></p>
</blockquote>
<p>How can we find surprises?</p>
<h1 id="causal-diagram-vs-process-description">Causal Diagram vs Process Description</h1>
<p>I somehow feel uncomfortable with this idea of causal links between variables. It seems unsatisfactory to me.</p>
<p>What I really want is a description of the underlying process that reality is using to generate what we see. I want to know the program that reality is running. That is what programs are - descriptions of processes. And that is, I think, what hypotheses are too.</p>
<p>The idea of isolating all the variables (independent or dependent) and looking at their relationships seems too low-level to me, like I’m missing the forest for the trees. I want to know the deep process that generates those surface phenomena. Plus, the variables seem quite fragile; they seem to be based on your current tools for observation or manipulation. I want to go beyond current tools. I want to know “how the universe works on such a deep level that you know exactly what to do to make the universe do what you want”. I want an in-depth understanding of the domain, dammit.</p>
<p>I believe that is what I did instinctively when I summarized book chapters or PG essays - I came up with some simple, sweeping model that could explain all of the observations and more.</p>
<p>You need to use your model of the process to say how the system will proceed given the initial state. That is all. Wait. Also, you need to infer what happened earlier using the evidence.</p>
<p>The domain of programming really helps cement this intuition, because you can’t get away with simplistic relationships between variables. You absolutely <em>have</em> to talk about the program in its vast complexity (?). It defies easy summarization. You can see the difference in predictive power between a person who knows the program inside-out and somebody who is just making a few surface relationships. This is the power of reductionism! Once you know the actual program being executed, you can see everything! There is no question of probabilities or anything. You know damn well exactly what is going to happen at each point.</p>
<p>This is why I feel queasy about using probabilities within a hypothesis. That’s the ultimate sign that you don’t understand the domain too well - you’re basically guessing at what will happen (and will thus get a lower posterior probability than someone who makes sure predictions). If you know the exact model that underpins a domain, you will be able to predict exactly what will happen, no two ways about it.</p>
<p>Maybe we can have probabilities to represent our confidence in different hypotheses (their prior probabilities), because we don’t know which hypothesis reality is using, but within the hypothesis, we should be sure of what we expect.</p>
<p>In short, a tree belief network is just not expressive enough, I think. You need a better language with which to describe processes.</p>
<h1 id="mysterious-answers-to-mysterious-questions">Mysterious Answers to Mysterious Questions</h1>
<p>Let’s see if my understanding of causal models as Causal Bayesian Networks can satisfy the requirements of a good hypothesis stated in Eliezer’s Sequence.</p>
<h2 id="anticipated-consequences">Anticipated consequences</h2>
<p>Anticipated consequences are all about talking in terms of the variables. If a tree falls in a forest and no one is around to hear it, you expect the vibrations-in-the-air variable to change and you expect no brain to have any auditory-processing. There is no confusion at all once you think in terms of the variables.</p>
<p>What was wrong with the “hypothesis” that phlogiston caused fire? He says there were no advance predictions. Why is that? Well, you can’t observe or manipulate phlogiston, and you can’t observe or manipulate any of its parent causes either. So, it tells you nothing at all.</p>
<p>What about Wulky Wilkinsen’s “post-utopian” work? Can’t we say “post-utopian” style causes your books to show “colonial alienation”? But, we can’t observe or manipulate either of those variables, nor any of their parent causes.</p>
<p>The lesson is to always talk in terms of variables that you can observe or manipulate. Further, you must specify precisely what effects you expect a cause to have (and thus what observed effects would falsify your belief). If a “cause” doesn’t precisely control what values the “effect” will have, then that causal link is useless.</p>
<p>What about the theory that elan vital causes aliveness in living beings? Again, you can’t observe or manipulate elan vital. And you can’t predict precisely which configurations of matter will possess “aliveness”.</p>
<p>Whenever you predict one outcome, the other possible outcomes will falsify your hypothesis.</p>
<p>Failure to consider the obvious next question: why? If you say A caused B, ask why A came about in the first place. Also, ask how A leads to B - what are the intermediate steps?</p>
<p>Also, when you don’t know the cause behind some variable, its behaviour will seem chaotic and unpredictable to you. However, once you figure out the cause, it will be absolutely clear.</p>
<h1 id="high-confidence">High Confidence</h1>
<p>Having a narrow overall confidence level means that you will make much more useful predictions. You will be thinking technically - you will say this <em>will</em> happen and that <em>won’t</em>. Also, it means that you’re pretty much sure of what will happen.</p>
<p>Yes, the future is uncertain and you don’t know for sure that something won’t come along and turn everything upside down. But the point is, you have no good reason to believe that. On average, your beliefs will be continue to be held by the future evidence. If you have a 99% belief in some hypothesis, then <refer to math> with 90% chance you expect to be promoted to 99.66% belief and with 10% chance you expect to be demoted to 93.06% belief, i.e., a large chance of a small increase or a small chance of a large decrease. But, on average, you still expect to be around 99% confident in this belief.</p>
<p>No, you cannot say it’s good to be pessimistic and we should try to hedge our bets and whatnot. This is probability theory. If you had extra information of any sort, it would already be incorporated in your final confidence levels. If you knew that tomorrow you would find an unpredicted result, you would already reduce your confidence levels, the same way you would buy a stock today itself if you suspected it would skyrocket tomorrow. So, if after updating on all the evidence using Bayes Theorem, you get to a narrow confidence distribution among your hypotheses, it means you’ve hit the jackpot (assuming you’ve meticulously looked at <em>all</em> the information you have). You have no particular reason to fear becoming falsified tomorrow, just as you have no particular reason to rejoice becoming even further supported tomorrow. That is what narrow, falsifiable hypotheses help you achieve.</p>
<p>And narrow hypotheses help you achieve this at speed. The narrower the predictions, the more each piece of evidence will redistribute your confidence in your hypotheses.</p>
<h1 id="notes-about-the-scientific-method-sequence">Notes about the Scientific Method Sequence</h1>
<p>Confusion: when we think that some part of a hypothesis constrains variables, when it actually doesn’t. It doesn’t tell us what will not happen. Anything can happen. It is unfalsifiable and useless. But, the danger is that it feels useful. It feels like it’s paying some rent. So, we don’t feel the need to go out and replace it. Test: We won’t feel surprised by any particular outcome? (examples of confusion?) What causes this? Can that make it go away? Is the answer taboo? (taboo -&gt; confusion -&gt; replacement hypothesis; So, if you’re confused, you won’t seek out alternative hypotheses. You will <em>feel</em> like you have got predictive power in that area; you will feel you understand it (?). At least, you won’t feel like changing your mind.)</p>
<p>confusion = #variables for whom you can’t say what won’t happen. No. confusion = can’t make predictions (since you don’t constrain variables), can’t learn from experience (? if you had falsifiable beliefs, you could learn over time. Here, you can’t. Better to be wrong than confused), problem feels like it can’t be solved or feels like it has been solved (? if you feel it can’t be solved, you won’t try to solve it. Note: if someone else does it in front of you, things will change (Servo example). if you feel you have already solved, you won’t pay attention to discrepancies.). confusion =&gt; can’t or won’t change your mind.</p>
<p>replacement hypothesis = do you look at other hypotheses? can you change your mind?</p>
<p>TODO: Notice surprises.</p>
<p>Aim to falsify your hypothesis as quickly as possible. Come up with alternative hypotheses and use differing predictions to distinguish between them. This is the heart of the scientific method. Either run experiments to test the differences or just use observations to do. (narrow hypotheses, differing predictions -&gt; more predictive power - lose quickly and win big; also, require very few pieces of evidence -&gt; efficient)</p>
<p>Key Question: What else could it be?</p>
<p>Where do we not try to look at differing predictions? Where are we inefficient? Give me three real-life examples of distinguishing between hypotheses.</p>
<p>One way to do this would be to just test one hypothesis in every scenario, especially in cases where it rules out most of the possibilities. But if it gets the right answer a few times, should you accept it? If not, why not?</p>
<p>Eventually, get to causal models and your best method for solving problems. Show how to use it to solve real, everyday problems. How is it superior to existing methods? (causal models -&gt; narrow hypotheses, low complexity, differing predictions, already tabooed, efficiency, etc.)</p>
<p>Confusion, speed, efficiency, and formulation. To remedy confusion, use taboo and ensure that you constrain variables. To gain speed, make narrower predictions and notice surprises. To formulate better hypotheses, keep it simple and use causal models. To use scanty evidence efficiently, do empirical scholarship and use differing predictions to distinguish between hypotheses.</p>
<p>Surprising discovery: Unfalsifiable beliefs get confirmed by every outcome. So, your confidence in them grows over time, no matter what! Take the Fifth Column example. You’ll become more and more confident in a useless belief, and then use that to justify your preferred actions. Conspiracy theories rely on this for their sustenance.</p>
<h2 id="skills-so-far">Skills so far</h2>
<p>What I want:</p>
<p>Smoke out hypotheses that don’t forbid anything. That is, hypotheses for whom no outcome will falsify them. How? Take plausible-sounding hypotheses that can explain every outcome in hindsight.</p>
<p>Demand narrow predictions. Spot hypotheses that make falsifiable yet vague predictions.</p>
<p>Take confusing ideas, or ones that you think you understand. Then, taboo adjectives, verbs, and nouns. You must get falsifiable predictions at the end.</p>
<p>Everything boils down to a question of fact. You’re not entitled to your own opinion.</p>
<p>Basically, how do people avoid having to change their mind? They hide behind words and “personal opinions” (which they express in words, but not narrow predictions, and thus are safe from falsification). Or they conveniently explain every outcome in hindsight. Or they make vague predictions that are hard to falsify.</p>
<h1 id="road-ahead-november-2015">Road Ahead (November 2015)</h1>
<p>Focus purely on learning as of now. After you have a handle on it, move on to research. Remember, one thing at a time.</p>
<p>Aim to think deeply. Don’t bother “practicing” if you aren’t doing it with zero distractions and full concentration.</p>
<h2 id="textbook-for-learning-practice">Textbook for learning practice</h2>
<p>NCERT Class XI Biology <a href="http://ncertbooks.prashanthellina.com/class_11.Biology.Biology/index.html">textbook</a>. Important questions for each <a href="http://schools.aglasem.com/58639">chapter</a>.</p>
<p>One way to practice: Look at the exercise questions and list the variables of interest. Then, read the chapter to build a causal model with just those variables. Finally, without referring to the chapter, use your causal model to answer the questions. See what you missed and why and update your learning algorithm to catch it next time. Rinse and repeat till your causal model can answer each question with ease. When you’re satisfied, test your model against the Important Questions database.</p>
<h2 id="other-textbooks">Other textbooks</h2>
<p>Check out Principles of Economics as a textbook with lots of practice problems and technical exams.</p>
<p>Thermodynamics is a solid, mathematical, scientific subject with lots of hard, technical solved problems.</p>
<p>Decision Theory is mathematical and yet concept-oriented, I think. It has solved problems too.</p>
<h2 id="neuroscience">Neuroscience</h2>
<p>Wikiversity <a href="https://en.wikiversity.org/wiki/Fundamentals_of_Neuroscience">course</a>.</p>
<p>MIT OCW <a href="http://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-01-introduction-to-neuroscience-fall-2007/recitations/">course</a>.</p>
<p>What looks like a tough technical <a href="http://www.cns.caltech.edu/bi150/">Caltech course</a>.</p>

<div class="info">Created: August 18, 2015</div>
<div class="info">Last modified: November  5, 2015</div>
<div class="info">Status: in-progress</div>
<div class="info"><b>Tags</b>: scientific method</div>

<!-- <div id="sequence-navigation" style="text-align: right"> -->
<!--   <p>Part of <a href="./sequences.html"><i>No Sequence</i></a> -->

<!--   <p>Previous post: "<a href="">Start of Sequence</a>" -->

<!--   <p>Next post: "<a href="">Head of Sequence</a>" -->
<!-- </div> -->

<br />
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'spkrationalitytrainingground'; // required: replace example with your forum shortname
    var disqus_identifier = '/Scientific-Method.html';
    var disqus_title = 'Scientific Method';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
	var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
